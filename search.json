[{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"iteratively-fitted-models","dir":"Articles","previous_headings":"","what":"Iteratively Fitted Models","title":"Fitting and tuning Iteratively Fitted Models","text":"Introductory remark: vignette, assumed reader familiar main concepts modeltuner package, particular classes “model”, “multimodel”, “cv” related functions methods. case, reading introductory vignette “introduction modeltuner examples” (vignette(modeltuner)) first recommended. speak iteratively fitted model (IFM) output model fitting function just single model, rather sequence models increasing structural complexity. Examples gradient boosting (implemented package xgboost) Lasso regression elastic nets (available package glmnet). sequence models begins simple model (often constant model) ends model possibly seriously overfits training data. Within sequence, training error typically decreases successively, test error decreases early iterations, point stagnates starts increasing . use term iterations refer element models sequence, although properly speaking, actual fitting process need iterative. two cases mentioned , gradient boosting regularized linear models, fitting process actually iterative. analysis tools introduced vignette, availability predictions iteration crucial, training test error can computed iteration.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"the-bias-variance-trade-off","dir":"Articles","previous_headings":"Iteratively Fitted Models","what":"The bias-variance trade-off","title":"Fitting and tuning Iteratively Fitted Models","text":"working IFMs, one key tasks consists finding appropriate iteration model, one simple time excessively ()fit training data. short, strive good compromise situation bias-variance trade-. simple model suffers bias, model approximates training data closely disadvantage large variance.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"a-single-model","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"A single model","title":"Fitting and tuning Iteratively Fitted Models","text":"example uses simulated data generated function simuldat(), included modeltuner. can define xgboost model terms formula data function fm_xgb(): model() creates object class “model”:","code":"library(modeltuner) options(cv_verbose = FALSE, width = 100)  library(magrittr, warn.conflicts = FALSE)   # for pipe operator  # Simulated data set set.seed(123) d <- simuldat() fm0 <- fm_xgb(Y ~ ., d) fm0 ## Fitted model of class 'fm_xgb'  ##   formula:     Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g - 1 ##   data:        d (500 rows) ##   call:        fm_xgb(formula = Y ~ ., data = d) ##   nfeatures:   30 ##   iterations:  100 ##   pref_iter:   100 # Model m0 <- model(fm0, label = \"xgb\")"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"evaluation-log-of-a-model","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > A single model","what":"Evaluation log of a model","title":"Fitting and tuning Iteratively Fitted Models","text":"model’s evaluation_log() consists sequence training errors, provide indication good balance oversimplifying overfitting found.  Note also applied evaluation_log() fitted model fm0.","code":"# evaluation log of an object of class \"model\" evaluation_log(m0) ## 'evaluation_log', 1 model: ##  ## Model 'xgb': ##   model class: fm_xgb ##  iter train_rmse test_rmse ##     1     3.5772        NA ##    21     0.3939        NA ##    41     0.1484        NA ##    60     0.0671        NA ##    80     0.0268        NA ##   100     0.0123        NA plot(evaluation_log(m0)) ## Warning: Removed 100 rows containing missing values (`geom_point()`). ## Warning: Removed 100 rows containing missing values (`geom_line()`)."},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"cross-validation","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > A single model","what":"Cross-validation","title":"Fitting and tuning Iteratively Fitted Models","text":"Running cross validation cv() yields cross-validated model, class “cv”. evaluation log now includes training test error.  plot, vertical line marks iteration minimal test error. default, iteration considered preferred one. example, iteration 63 preferred. cv_performance() returns training test error recorded iteration:","code":"# evaluation log of an object of class \"cv\" cvm <- cv(m0) evaluation_log(cvm) ## 'evaluation_log', 1 cross-validated model: ##  ## Model 'xgb': ##   model class: fm_xgb ##  iter train_rmse test_rmse criterion ##     1     3.5736      3.77           ##    15     0.5281      2.11           ##    30     0.2326      2.05           ##    44     0.1239      2.03           ##    59     0.0650      2.03           ##    63     0.0542      2.03       min ##    73     0.0361      2.03 plot(evaluation_log(cvm)) cv_performance(cvm) ## --- Performance table --- ## Metric: rmse ##     train_rmse test_rmse iteration time_cv ## xgb   0.054174    2.0271        63   0.986"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"back-to-model-and-fitted-model","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > A single model","what":"Back to model and fitted model","title":"Fitting and tuning Iteratively Fitted Models","text":"now take step back, extracting model object cvm, information best (preferred) iteration attached resulting model object: final line output , best iteration according cross-validation results reported. Apart , m1 identical original model object m0. Finally, fitting model, thus converting “model” object fitted model, nrounds argument adjusted according preference resulting cross-validation: Note number rounds fixed nrounds=63 fitting call.","code":"# back to model m1 <- extract_model(cvm) # or: tune(cvm) m1 ## --- A \"model\" object --- ##   label:          xgb ##   model class:    fm_xgb ##   formula:        Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g - 1 ##   data:           data.frame [500 x 12], input as: 'data = d' ##   response_type:  continuous ##   call:           fm_xgb(formula = Y ~ ., data = data) ##   fit:            Object of class 'fm_xgb' ## Preferred iteration from cv:  iter=63 # back to fitted model fm1 <- fit(m1) ## set_pref_iter(), model 'xgb', modifications made in call: ##   pref_iter=63, nrounds=63, early_stopping_rounds=NULL getCall(fm1) ## fm_xgb(formula = Y ~ ., data = d, nrounds = 63L, pref_iter = 63L,  ##     early_stopping_rounds = NULL)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"tuning-nrounds-with-tune","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > A single model","what":"Tuning nrounds with tune()","title":"Fitting and tuning Iteratively Fitted Models","text":"Applying tune() IFM without arguments triggers cross-validation returns adjusted model (model fitted) “tuned” number rounds: Repeated executions result varying choices nrounds, new cross-validation groups (folds) randomly generated execution, leading different evaluation log.","code":"tune(m0)  # executes m0 %>% cv %>% extract_model tune(fm0) # executes fm0 %>% model %>% cv %>% extract_model %>% fit"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"default-metric-for-xgboost-models","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"Default metric for xgboost models","title":"Fitting and tuning Iteratively Fitted Models","text":"“cv” objects based model created fm_xgb() differ model class way metric selected default. currently model type standard choice, rmse continuous response logLoss binary case. xgboost model eval_metric. specified explicitly user, metric set depending argument objective call xgb.train() fm_xgb(). example, objective=\"reg:linear\" rmse default eval_metric, objective=\"binary:logistic\" chooses logloss. modeltuner, eval_metric taken default metric resulting “cv” object. example, consider model using eval_metric “mphe” (mean pseudo-Huber error). default eval_metric objective=\"reg:pseudohubererror\". values metric “mphe” (evaluation log) read return value xgb.train() xgb.cv() - actually don’t necessarily need R function mphe() evaluating metric modeltuner implementation. cv_performance() can still executed available metric: case doubt default metric model, one may use function default_metric(). identifies metric function used default:","code":"data(diamonds, package = \"ggplot2\") set.seed(1) diamonds <- diamonds[sample(nrow(diamonds), 5000), ] xgb_phe <- model(fm_xgb(log(price) ~ . , diamonds, objective = \"reg:pseudohubererror\"),                  base_score = median(log(diamonds$price)),             label = \"xgb_pseudohuber\") cv_phe <- cv(xgb_phe) cv_performance(cv_phe) ## --- Performance table --- ## Metric: mphe ##                 train_mphe test_mphe iteration time_cv ## xgb_pseudohuber  0.0010635 0.0062366        99   5.004 cv_performance(cv_phe, metric = \"mae\") ## --- Performance table --- ## Metric: mae ##                 train_mae test_mae iteration time_cv ## xgb_pseudohuber  0.033856  0.08174        99   5.004 default_metric(xgb_phe)  # no metric function, only a name (values read from xgboost output) ## $mphe ## NULL default_metric(m1)       # metric available, only its name ## $rmse ## function (actual, predicted, w = NULL, ...)  ## { ##     sqrt(mse(actual = actual, predicted = predicted, w = w, ...)) ## } ## <bytecode: 0x55dbb66ecfe0> ## <environment: namespace:MetricsWeighted>"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"hyperparameter-tuning","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"Hyperparameter tuning","title":"Fitting and tuning Iteratively Fitted Models","text":"section, investigate effect modifying value parameter max_depth model m0. multimodel defined expanding max_depth 1 6:","code":"# Generate a multimodel mm_depth <- multimodel(m0, prefix = \"xgb_depth\", max_depth = 1:6,                         nrounds = 200)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"cross-validation-1","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Hyperparameter tuning","what":"Cross-validation","title":"Fitting and tuning Iteratively Fitted Models","text":"cv() runs separate cross-validations 6 models, using identical folds . printed output lists details first 3 models default. order get display details 6 models output, use argument n print() (output shown): function extract_pref_iter() extracts preferred iterations “cv” object:","code":"cvmm_depth <- cv(mm_depth) cvmm_depth ## --- A \"cv\" object containing 6 validated models --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  500 ##   Number of test sets:     10 ##   Size of test sets:       50 ##   Size of training sets:  450 ##  ## Models: ##  ## 'xgb_depth1': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## 'xgb_depth2': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## 'xgb_depth3': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## and 3 models more, labelled: ##   'xgb_depth4', 'xgb_depth5', 'xgb_depth6' ##  ##  ## Parameter table: ##            max_depth nrounds ## xgb_depth1         1     200 ## xgb_depth2         2     200 ## xgb_depth3         3     200 ## ... 3 rows omitted (nrow=6) ##  ## Preferred iterations: ##   model 'xgb_depth1':  min (iter=144) ##   model 'xgb_depth2':  min (iter=151) ##   model 'xgb_depth3':  min (iter=91) ## ... and 3 lines more. print(cvmm_depth, n = 6) extract_pref_iter(cvmm_depth) ## Preferred iterations: ##   model 'xgb_depth1':  min (iter=144) ##   model 'xgb_depth2':  min (iter=151) ##   model 'xgb_depth3':  min (iter=91) ##   model 'xgb_depth4':  min (iter=117) ##   model 'xgb_depth5':  min (iter=99) ##   model 'xgb_depth6':  min (iter=67)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"cv_performance-and-evaluation_log","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Hyperparameter tuning","what":"cv_performance() and evaluation_log()","title":"Fitting and tuning Iteratively Fitted Models","text":"output functions (printed plotted) extends seen single model multiple model case:   plot performance table can enhanced setting xvar=max_depth:  plot shows values max_depth>2 improve predictive performance unseen data, increasingly overfit training data.","code":"plot(cv_performance(cvmm_depth)) plot(evaluation_log(cvmm_depth)) plot(cv_performance(cvmm_depth), xvar = \"max_depth\")"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"tuning-and-extracting-a-model-or-fitted-model-from-a-cv-object","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Hyperparameter tuning","what":"Tuning and extracting a model or fitted model from a “cv” object","title":"Fitting and tuning Iteratively Fitted Models","text":"Applying tune() cvmm_depth pick best-performing model (lowest test error) return .","code":"m_tuned <- tune(cvmm_depth) fm_tuned <- fit(m_tuned) ## set_pref_iter(), model 'xgb_depth2', modifications made in call: ##   pref_iter=151, nrounds=151, early_stopping_rounds=NULL getCall(fm_tuned) ## fm_xgb(formula = Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 +  ##     X9 + X10 + g, data = data, nrounds = 151L, early_stopping_rounds = NULL,  ##     pref_iter = 151L, max_depth = 2L)"},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"basics-on-preference-criteria","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Preference criteria for iterations","what":"Basics on preference criteria","title":"Fitting and tuning Iteratively Fitted Models","text":"far, assumed throughout preferred model one minimal test error. Depending current application goals, choices may desirable. example, users may want stable models sense expect fitting model different data sets yields results differ much. example multimodel mm , model max_depth=2 lowest test error, still analyst may favor choosing max_depth=1, exhibits less overfitting. modeltuner offers various alternative preference/selection criteria. default criterion, used examples far, choose criterion, use argument iter cv(). call cv(mm) also written ","code":"crit_min() ## Preference criterion for an iteratively fitted model: ##   criterion:     crit_min() ##   label suffix:  \"min\" ##   Selects the iteration with minimal test error. cvm <- cv(m0, iter = crit_min()) # same as: cvm <- cv(m0)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"alternative-criteria","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Preference criteria for iterations > Basics on preference criteria","what":"Alternative criteria","title":"Fitting and tuning Iteratively Fitted Models","text":"Two criteria avoid selecting heavily overfitting model crit_se() crit_overfit(). explained printed output : available criteria ","code":"crit_se(factor = 2)         # default: factor=1 ## Preference criterion for an iteratively fitted model: ##   criterion:     crit_se(2) ##   label suffix:  \"2se\" ##   Selects the first iteration where test error does not exceed ##     the minimal test error by more than 2 standard errors. crit_overfit(ratio = 0.8)  # default: ratio=0.9 ## Preference criterion for an iteratively fitted model: ##   criterion:     crit_overfit(0.8) ##   label suffix:  \"overfit0.8\" ##   Selects the iteration with minimal test error among those where ##   the ratio of training and test error does not fall below 0.8. crit_first() crit_last() crit_iter(20) # fixed iteration number"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"specifying-a-criterion-in-cv","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Preference criteria for iterations","what":"Specifying a criterion in cv()","title":"Fitting and tuning Iteratively Fitted Models","text":"now cross-validate model m0 , thereby claiming ratio training test error remains 0.75. choosing criterion iter = crit_overfit(0.75), thus ensuring predictive performances compared models sharing similar degree overfitting.  consequence different choice preference criterion, earlier iteration (iteration 3) selected cvm1 default iter = crit_min(), iteration 63 preferred.","code":"# cv() cvm_ovf075 <- cv(m0, iter = crit_overfit(0.75)) cvm_ovf075 ## --- A \"cv\" object containing 1 validated model --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  500 ##   Number of test sets:     10 ##   Size of test sets:       50 ##   Size of training sets:  450 ##  ## Model: ##  ## 'xgb': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g - 1 ##   metric:       rmse ##  ## Preferred iterations: ##   model 'xgb':  overfit0.75 (iter=3) plot(evaluation_log(cvm_ovf075))"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"back-to-model-and-fitted-model-1","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Preference criteria for iterations","what":"Back to model and fitted model","title":"Fitting and tuning Iteratively Fitted Models","text":"preferred iteration transformed back model fitted model exactly shown crit_min() case:","code":"m_tuned_ovf075 <- extract_model(cvm_ovf075) fm_tuned_ovf075 <- fit(m_tuned_ovf075) ## set_pref_iter(), model 'xgb', modifications made in call: ##   pref_iter=3, nrounds=3, early_stopping_rounds=NULL getCall(fm_tuned_ovf075) ## fm_xgb(formula = Y ~ ., data = d, nrounds = 3L, pref_iter = 3L,  ##     early_stopping_rounds = NULL)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"multimodel-case","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"Multimodel case","title":"Fitting and tuning Iteratively Fitted Models","text":"now straightforward repeat tuning xgboost’s hyperparameter max_step preference iter = crit_overfit(0.75).   contrast hyperparameter tuning based crit_min(), max_depth=2 turned choice, tune(cvmm_ovf075) picks max_depth=1, reflects stronger reluctance complex overfitting models expressed iter=crit_overfit(0.75):","code":"cvmm_ovf075 <- cv(mm_depth, iter = crit_overfit(0.75)) extract_pref_iter(cvmm_ovf075) ## Preferred iterations: ##   model 'xgb_depth1':  overfit0.75 (iter=112) ##   model 'xgb_depth2':  overfit0.75 (iter=20) ##   model 'xgb_depth3':  overfit0.75 (iter=9) ##   model 'xgb_depth4':  overfit0.75 (iter=5) ##   model 'xgb_depth5':  overfit0.75 (iter=3) ##   model 'xgb_depth6':  overfit0.75 (iter=3) plot(cv_performance(cvmm_ovf075), xvar = \"max_depth\") plot(evaluation_log(cvmm_ovf075)) + ggplot2::theme(legend.position = \"bottom\") tune(cvmm_ovf075) ## --- A \"model\" object --- ##   label:          xgb_depth1 ##   model class:    fm_xgb ##   formula:        Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   data:           data.frame [500 x 12], input as: 'data = d' ##   response_type:  continuous ##   call:           fm_xgb(formula = Y ~ ., data = data, nrounds = 200, max_depth = 1L) ## Preferred iteration from cv:  iter=112"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"multiple-preference-criteria","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"Multiple preference criteria","title":"Fitting and tuning Iteratively Fitted Models","text":"cv() accepts multiple preference criteria. just enclose list criteria crit_list(...) c(...). example uses model maximal tree depth 2, three preference criteria given.  cross-validated model cvm_depth2 includes three preference criteria. Let’s call first primary criterion. picture evaluation_log , iteration corresponding primary criterion shown solid line, criteria dotted line. printed output evaluation log, primary criterion marked asterisk: role primary criterion cv_performance() returns training test error iteration. true related functions, cv_predict() plot.cv().","code":"m_depth2 <- update(m0, nround = 200, max_depth = 2, label = \"xgb_depth2\") cvm_depth2 <- cv(m_depth2, iter = c(crit_min(), crit_overfit(.7), crit_last())) cvm_depth2 ## --- A \"cv\" object containing 1 validated model --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  500 ##   Number of test sets:     10 ##   Size of test sets:       50 ##   Size of training sets:  450 ##  ## Model: ##  ## 'xgb_depth2': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## Preferred iterations: ##   model 'xgb_depth2':  min (iter=100), overfit0.7 (iter=28), last (iter=110) plot(evaluation_log(cvm_depth2)) evaluation_log(cvm_depth2) ## 'evaluation_log', 1 cross-validated model: ##  ## Model 'xgb_depth2': ##   model class: fm_xgb ##  iter train_rmse test_rmse  criterion ##     1      3.805      3.85            ##    23      1.548      2.09            ##    28      1.449      2.06 overfit0.7 ##    45      1.231      1.95            ##    66      1.063      1.89            ##    88      0.937      1.88            ##   100      0.878      1.86 min*       ##   110      0.834      1.86 last # cv_performance cv_performance(cvm_depth2) ## --- Performance table --- ## Metric: rmse ##            train_rmse test_rmse iteration time_cv ## xgb_depth2    0.87816    1.8584       100   0.553"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"changing-the-primary-criterion-set_pref_iter","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Multiple preference criteria","what":"Changing the primary criterion: set_pref_iter()","title":"Fitting and tuning Iteratively Fitted Models","text":"primary preference criterion “cv” object can changed function set_pref_iter().  set_pref_iter() useful specify criterion previously included cross-validation. criterion chosen, results available: Note difference: cv_performance() non-default metric=\"medae\" available cvm_depth2_modif1 cvm_depth2_modif2. reason cross-validation predictions iterations selected original “cv” object cvm_depth2 (.e. iterations 100, 28, 110) stored object, case iteration 50. order obtain predictions iteration 50, need re-run cross validation, including crit_iter(50) list criteria (also set keep_fits=TRUE cv() - see section “Evaluation log alternative metric” ).","code":"cvm_depth2_modif1 <- set_pref_iter(cvm_depth2, iter = crit_overfit(0.7)) plot(evaluation_log(cvm_depth2_modif1)) extract_pref_iter(cvm_depth2_modif1) ## Preferred iterations: ##   model 'xgb_depth2':  overfit0.7 (iter=28), min (iter=100), last (iter=110) cv_performance(cvm_depth2_modif1) ## --- Performance table --- ## Metric: rmse ##            train_rmse test_rmse iteration time_cv ## xgb_depth2     1.4493    2.0601        28   0.553 # cv_performance() with different metric: cv_performance(cvm_depth2_modif1, metric = \"medae\") ## --- Performance table --- ## Metric: medae ##            train_medae test_medae iteration time_cv ## xgb_depth2     0.95277     1.3459        28   0.553 # set_pref_iter with criteria not stated before in cv(..., iter = ) cvm_depth2_modif2 <- set_pref_iter(cvm_depth2, crit_iter(50)) cv_performance(cvm_depth2_modif2)  # available ## --- Performance table --- ## Metric: rmse ##            train_rmse test_rmse iteration time_cv ## xgb_depth2      1.183    1.9289        50   0.553 # cv_performance() with different metric: cv_performance(cvm_depth2_modif2, metric = \"medae\") # required predictions are not available ## --- Performance table --- ## Metric: medae ##            train_medae test_medae iteration time_cv ## xgb_depth2          NA         NA        50   0.553"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"expand_pref_iter","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Multiple preference criteria","what":"expand_pref_iter()","title":"Fitting and tuning Iteratively Fitted Models","text":"Next, introduce function expand_pref_iter(), converts “cv” object single cross-validated model multiple criteria “cv” object several (essentially identical) models, different preference criteria.  different structures cvm_depth2 cvm_depth2_modif3 also becomes obvious comparing respective output extract_pref_iter():","code":"cvm_depth2_modif3 <- expand_pref_iter(cvm_depth2) cvm_depth2_modif3 ## --- A \"cv\" object containing 3 validated models --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  500 ##   Number of test sets:     10 ##   Size of test sets:       50 ##   Size of training sets:  450 ##  ## Models: ##  ## 'xgb_depth2_min': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## 'xgb_depth2_overfit0.7': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## 'xgb_depth2_last': ##   model class:  fm_xgb ##   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + g ##   metric:       rmse ##  ## Preferred iterations: ##   model 'xgb_depth2_min':         min (iter=100) ##   model 'xgb_depth2_overfit0.7':  overfit0.7 (iter=28) ##   model 'xgb_depth2_last':        last (iter=110) cv_performance(cvm_depth2_modif3) ## --- Performance table --- ## Metric: rmse ##                       train_rmse test_rmse iteration time_cv ## xgb_depth2_min           0.87816    1.8584       100   0.553 ## xgb_depth2_overfit0.7    1.44932    2.0601        28   0.553 ## xgb_depth2_last          0.83375    1.8593       110   0.553 plot(evaluation_log(cvm_depth2_modif3)) extract_pref_iter(cvm_depth2) ## Preferred iterations: ##   model 'xgb_depth2':  min (iter=100), overfit0.7 (iter=28), last (iter=110) extract_pref_iter(cvm_depth2_modif3) ## Preferred iterations: ##   model 'xgb_depth2_min':         min (iter=100) ##   model 'xgb_depth2_overfit0.7':  overfit0.7 (iter=28) ##   model 'xgb_depth2_last':        last (iter=110)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"evaluation-log-for-an-alternative-metric-and-set_metric","dir":"Articles","previous_headings":"Boosted trees: fm_xgb()","what":"Evaluation log for an alternative metric and set_metric()","title":"Fitting and tuning Iteratively Fitted Models","text":"object cv_phe generated (section “Default metric xgboost models”), evaluation log summarizes training test errors iterations using default metric, usual. , default metric mphe, mean pseudo-Huber error:  performance expressed alternative metric (primary preferred iteration) obtained computation performance table different metric requires predictions preferred iterations. contrast, calculation evaluation log non-default metric requires predictions iterations. consequence, following call won’t produce useful output (result full NAs): computation evaluation log alternative metric required, one can execute cross-validation setting keep_fits = TRUE cv(). saves fits obtained cross-validation part result, calculation predictions iterations possible, thus avoiding re-run cross-validation.","code":"evaluation_log(cv_phe) %>% plot cv_performance(cv_phe, metric = \"mae\") ## --- Performance table --- ## Metric: mae ##                 train_mae test_mae iteration time_cv ## xgb_pseudohuber  0.033856  0.08174        99   5.004 evaluation_log(cv_phe, metric = \"mae\") cv_phe_fits <- cv(xgb_phe, keep_fits = TRUE,                    folds = cv_phe$folds) # use same folds as in cv_phe evaluation_log(cv_phe_fits, metric = \"mae\") %>% plot"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"set_metric","dir":"Articles","previous_headings":"Boosted trees: fm_xgb() > Evaluation log for an alternative metric and set_metric()","what":"set_metric()","title":"Fitting and tuning Iteratively Fitted Models","text":"function set_metric() changes default metric “cv” object, thereby computing evaluation log model metric. also re-evaluates preference criteria preferred iterations may different original “cv” object. set_metric() re-run cross-validation, requires fits attached input “cv”.","code":"cv_phe_mae <- set_metric(cv_phe_fits, \"mae\") cv_phe_mae ## --- A \"cv\" object containing 1 validated model --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  5000 ##   Number of test sets:      10 ##   Size of test sets:       500 ##   Size of training sets:  4500 ##  ## Model: ##  ## 'xgb_pseudohuber': ##   model class:  fm_xgb ##   formula:      log(price) ~ carat + cut + color + clarity + depth + table + x + y +  ##                     z - 1 ##   metric:       mae ##  ## Preferred iterations: ##   model 'xgb_pseudohuber':  min (iter=100) cv_performance(cv_phe_mae) ## --- Performance table --- ## Metric: mae ##                 train_mae test_mae iteration time_cv ## xgb_pseudohuber  0.033588 0.081736       100   4.989 evaluation_log(cv_phe_mae) ## 'evaluation_log', 1 cross-validated model: ##  ## Model 'xgb_pseudohuber': ##   model class: fm_xgb ##  iter train_mae test_mae criterion ##     1    0.3180   0.3220           ##    21    0.0681   0.0918           ##    41    0.0536   0.0850           ##    60    0.0454   0.0831           ##    80    0.0388   0.0821           ##   100    0.0336   0.0817       min"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"elastic-net-fm_glmnet","dir":"Articles","previous_headings":"","what":"Elastic net: fm_glmnet()","title":"Fitting and tuning Iteratively Fitted Models","text":"shorter section second class iteratively fitted models, use simulated data . code generates model \\[Y = \\beta_1 \\cdot X_1 + \\beta_2\\cdot X_2 + \\ldots + \\beta_{30}\\cdot X_{30} + residual\\] \\(X_i\\) residuals standard normal \\(\\beta_i=1/(4i)\\) \\(\\). beta coefficient decreasing \\(\\), expect many significant effect response \\(Y\\). fit Lasso model, run cross-validation including criteria crit_min() crit_se(). usage features related preference criteria selection iterations exactly xgboost case.  application cv(), cv_performance() evaluation_log() follows logic xgboost model:","code":"n <- 500; p <- 30 set.seed(1) x <- matrix(rnorm(n*(p)), n) beta <- 1/(4*seq(p)) d <- data.frame(y = x%*%beta + rnorm(n), x) rm(x) fitted_glmnet <- fm_glmnet(y ~., d)  # glmnet() with default alpha=1: LASSO plot(fitted_glmnet)  # similar to plot method for class 'glmnet', but a ggplot model_glmnet <- model(fitted_glmnet, label = \"glmnet\") cv_glmnet <- cv(model_glmnet, iter = c(crit_min(), crit_overfit(.95))) cv_glmnet ## --- A \"cv\" object containing 1 validated model --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  500 ##   Number of test sets:     10 ##   Size of test sets:       50 ##   Size of training sets:  450 ##  ## Model: ##  ## 'glmnet': ##   model class:  fm_glmnet ##   formula:      y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 +  ##                     X14 + X15 + X16 + X17 + X18 + X19 + X20 + X21 + X22 + X23 + X24 +  ##                     X25 + X26 + X27 + X28 + X29 + X30 - 1 ##   metric:       rmse ##  ## Preferred iterations: ##   model 'glmnet':  min (iter=19), overfit0.95 (iter=19) # performance table of cv_glmnet: cv_performance(cv_glmnet) ## --- Performance table --- ## Metric: rmse ##        train_rmse test_rmse iteration time_cv ## glmnet    0.97368   0.99584        19   0.215 # Plot the evaluation log: evaluation_log(cv_glmnet) %>% plot(zeroline = FALSE)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/ifm.html","id":"set_pref_iter-and-expand_pref_iter","dir":"Articles","previous_headings":"Elastic net: fm_glmnet()","what":"set_pref_iter() and expand_pref_iter()","title":"Fitting and tuning Iteratively Fitted Models","text":", usage functions similar shown section xgboost models.","code":"set_pref_iter(cv_glmnet, crit_se()) %>% cv_performance # different iteration ## --- Performance table --- ## Metric: rmse ##        train_rmse test_rmse   lambda iteration time_cv ## glmnet    0.97368   0.99584 0.042681        19   0.215 expand_pref_iter(cv_glmnet) %>% cv_performance ## --- Performance table --- ## Metric: rmse ##                    train_rmse test_rmse iteration time_cv ## glmnet_min            0.97368   0.99584        19   0.215 ## glmnet_overfit0.95    0.97368   0.99584        19   0.215"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"basics","dir":"Articles","previous_headings":"","what":"Basics","title":"An introduction to modeltuner with examples","text":"package modeltuner offers toolkit model evaluation, model comparison hyperparameter tuning based cross-validation. applies models continuous binary response generated formula interface. addition, includes functionalities conveniently fitting tuning xgboost glmnet models.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"the-formula-interface","dir":"Articles","previous_headings":"Basics","what":"The formula interface","title":"An introduction to modeltuner with examples","text":"modeltuner designed model classes based model-fitting functions using formula interface combination data argument. Examples model-fitting functions matching requirement : package stats: lm(), glm(), loess(), nls() package robustbase: lmrob(), glmrob(), nlrob() package MASS: rlm(), lqs() package mgcv: gam() package rpart: rpart() package quantreg: rq() package lme4: lmer(), glmer() modeltuner adds functions list essentially formula-based wrappers functions supporting formula interface: fm_smoothing_spline() uses stats::smooth.spline(), fm_knn() uses RANN::nn2() (nearest-neighbor), fm_xgb() uses xgboost::xgb.train() fm_glmnet() uses glmnet::glmnet() package offers particularly attractive tools handling called iteratively fitted models (IFM) . model, fitting process returns just one single model (model parameterization), rather range models (model parameterizations) increasing structural complexity. Prominent examples –currently instances implemented package– gradient boosting (implemented package xgboost) Lasso regression elastic nets (available package glmnet). Refer dedicated vignette (vignette(\"ifm\")) overview functionalities.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"fitted-models-and-objects-of-class-model","dir":"Articles","previous_headings":"Basics","what":"Fitted models and objects of class “model”","title":"An introduction to modeltuner with examples","text":"use term fitted model output model-fitting function, lm(). modeltuner, models alternatively represented objects class “model”. “model” object necessarily contain model fit, includes information needed refit model, notably model fitting call complete data. model label used identify printed output graphics, particular several models compared. default label \"model\", recommended attribute informative label model create. Note generic setting data=data model generating call model_lm_cars printed output . convenient cross-validation, model generating call repeatedly adjusted executed internally, using data stored “model” object. similar generic setting weights=weights imposed case weighted model. order obtain fitted model corresponding given “model” object, use fit(). sense, fit() reverse operation model(). fit(mod_lm_cars) essentially executes call mod_lm_cars$call using data mod_lm_cars$data.","code":"fm_lm_cars <- lm(dist ~ speed, cars)        # fitted model mod_lm_cars <- model(fm_lm_cars, label = \"lm_cars\") # 'model' object mod_lm_cars ## --- A \"model\" object --- ##   label:          lm_cars ##   model class:    lm ##   formula:        dist ~ speed ##   data:           data.frame [50 x 2], input as: 'data = cars' ##   response_type:  continuous ##   call:           lm(formula = dist ~ speed, data = data) ##   fit:            Object of class 'lm' class(mod_lm_cars) ## [1] \"model_lm\" \"model\" fit(mod_lm_cars)    # back to fitted models ##  ## Call: ## lm(formula = dist ~ speed, data = cars) ##  ## Coefficients: ## (Intercept)        speed   ##     -17.579        3.932 all.equal(fm_lm_cars, fit(mod_lm_cars)) ## [1] TRUE"},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"folds","dir":"Articles","previous_headings":"Basics > Cross validation","what":"Folds","title":"An introduction to modeltuner with examples","text":"function make_folds() generates set groups cross validation, sometimes called “folds”. output essentially consists list integer vectors defining test sets. complement test set used corresponding training set. Using argument nfold create 5-fold cross-validation: Setting nfold=p value p 0 1 also possible. Instead cross-validation, evokes simple hold-validation, model fitted proportion \\((1-p) \\cdot 100\\%\\) data remaining \\(p \\cdot 100\\%\\) used evaluation.","code":"make_folds(cars)              # 10-fold CV, the default ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  50 ##   Number of test sets:    10 ##   Size of test sets:       5 ##   Size of training sets:  45 str(make_folds(cars)) ## List of 10 ##  $ : int [1:5] 15 18 31 34 36 ##  $ : int [1:5] 16 33 39 40 45 ##  $ : int [1:5] 11 24 25 42 47 ##  $ : int [1:5] 6 10 21 30 49 ##  $ : int [1:5] 3 4 13 28 38 ##  $ : int [1:5] 2 7 29 43 50 ##  $ : int [1:5] 14 20 22 23 48 ##  $ : int [1:5] 8 9 27 32 35 ##  $ : int [1:5] 1 5 12 17 44 ##  $ : int [1:5] 19 26 37 41 46 ##  - attr(*, \"class\")= chr [1:2] \"folds\" \"list\" ##  - attr(*, \"type\")= chr \"complete\" ##  - attr(*, \"n\")= int 50 ##  - attr(*, \"stratified\")= logi FALSE make_folds(cars, nfold = 5) ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  50 ##   Number of test sets:     5 ##   Size of test sets:      10 ##   Size of training sets:  40 make_folds(cars, nfold = 0.3) # Simple hold-out validation with 30% of cases in test set ## Validation procedure: Simple Hold-out Validation ##   Number of obs in data:  50 ##   Number of test sets:     1 ##   Size of test set:       15 ##   Size of training set:   35"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"execute-a-cross-validation-cv","dir":"Articles","previous_headings":"Basics > Cross validation","what":"Execute a cross-validation: cv()","title":"An introduction to modeltuner with examples","text":"make_folds() used inside cv(), core function executing cross-validation. default, 10-fold CV performed, can customized using arguments nfold folds, cv() can also applied directly fitted model: cv(fm_lm_cars) executes fm_lm_cars %>% model %>% cv, thus skipping model step. method used case cv.default().","code":"# Executing a cross validation: cv() cv_cars <- cv(mod_lm_cars) cv_cars ## --- A \"cv\" object containing 1 validated model --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:  50 ##   Number of test sets:    10 ##   Size of test sets:       5 ##   Size of training sets:  45 ##  ## Model: ##  ## 'lm_cars': ##   model class:  lm ##   formula:      dist ~ speed ##   metric:       rmse"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"evaluate-a-cross-validation-cv_performance","dir":"Articles","previous_headings":"Basics > Cross validation","what":"Evaluate a cross-validation: cv_performance()","title":"An introduction to modeltuner with examples","text":"evaluate “cv” object, use cv_performance(): -called “shortcut methods” cv_perrormance() trigger several steps workflow sketched . Examples cv_performance.model() cv_performance.default(). cv_performance.model(x) executes x %>% cv %>% cv_performance: method cv_performance.default applied fitted model executes x %>% model %>% cv %>% cv_performance: drawback shortcut methods potentially useful interim results cross-validation (“cv” object) stored. useful know result last execution cv() can recovered time last_cv().","code":"cv_performance(cv_cars) ## --- Performance table --- ## Metric: rmse ##         train_rmse test_rmse time_cv ## lm_cars     15.013    14.812    0.02 cv_performance(cv_cars, metric = \"medae\") # alternative metric, see ?metrics ## --- Performance table --- ## Metric: medae ##         train_medae test_medae time_cv ## lm_cars      9.9791     10.739    0.02 cv_performance(mod_lm_cars) ## --- Performance table --- ## Metric: rmse ##         train_rmse test_rmse time_cv ## lm_cars     15.002    14.395   0.012 cv_performance(fm_lm_cars)     # cv_performance.default - applied to a fitted model ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## model      14.99    14.815   0.012"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"saving-the-model-fits","dir":"Articles","previous_headings":"Basics > Cross validation","what":"Saving the model fits","title":"An introduction to modeltuner with examples","text":"default, model fits cross validation saved. , set keep_fits = TRUE cv(): Keep fitted models cross-validation: extract_fits() can now used obtain model fits “cv” object. Besides model fits, resulting table also column containing folds. now extract fitted coefficients 10 models follows:","code":"cv_cars_fits <- cv(mod_lm_cars, keep_fits = T) (cars_fits <- extract_fits(cv_cars_fits)) ##       folds lm_cars ## 1  <int>[5]    <lm> ## 2  <int>[5]    <lm> ## 3  <int>[5]    <lm> ## 4  <int>[5]    <lm> ## 5  <int>[5]    <lm> ## 6  <int>[5]    <lm> ## 7  <int>[5]    <lm> ## 8  <int>[5]    <lm> ## 9  <int>[5]    <lm> ## 10 <int>[5]    <lm> sapply(cars_fits$lm_cars, coef) ##                   [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7]       [,8] ## (Intercept) -16.434962 -18.297725 -21.183227 -13.892332 -17.339967 -18.314134 -17.175287 -19.644122 ## speed         3.916652   4.000578   4.265483   3.634229   3.916122   3.969363   3.847343   3.999979 ##                   [,9]      [,10] ## (Intercept) -14.096414 -19.856576 ## speed         3.731144   4.068375"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"multimodels","dir":"Articles","previous_headings":"Basics","what":"Multimodels","title":"An introduction to modeltuner with examples","text":"multimodel combines several models one object. order create multimodel, fit two alternative models cars data. Alternative model 1: LOESS (locally weighted polynomial regression) stats::loess(): (control setting loess() necessary predictions outside range training data) Alternative model 2: regression tree rpart::rpart(): three models combined multimodel method c.model(): models response can combined multimodel. Graphical illustration fits three models:","code":"fm_loess_cars <- loess(dist ~ speed, cars,         control = loess.control(surface = \"direct\")) fm_rpart_cars <- rpart::rpart(dist ~ speed, cars) mm_cars <- c(  # method c.model(): argument names are used as model labels   lm = model(fm_lm_cars),    loess = model(fm_loess_cars),    rpart = model(fm_rpart_cars)) mm_cars ## --- A \"multimodel\" object containing 3 models --- ##  ## 'lm': ##   model class:  lm ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         lm(formula = dist ~ speed, data = data) ##  ## 'loess': ##   model class:  loess ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         loess(formula = dist ~ speed, data = data, control = loess.control(surface = \"direct\")) ##  ## 'rpart': ##   model class:  rpart ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         rpart::rpart(formula = dist ~ speed, data = data) library(ggplot2, warn.conflicts = F) speed_seq <- seq(0, 30, .1)  # grid of data points along range of 'speed' preds_mm <- predict(mm_cars, data.frame(speed = speed_seq)) # predictions for grid data preds_mm <- data.frame(  # reshape for ggplot   speed = rep(speed_seq, 3),   model = rep(label(mm_cars), each = length(speed_seq)),    dist = as.vector(preds_mm)) ggplot(preds_mm, aes(speed, dist, color = model)) +   geom_point(data = cars, color = 8) +   geom_line(lwd = 1) +   ggtitle(\"cars data: comparison of model fits\")"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"cross-validate-a-multimodel","dir":"Articles","previous_headings":"Basics","what":"Cross-validate a multimodel","title":"An introduction to modeltuner with examples","text":"cv() cv_performance() applied multimodel exactly model. set folds thereby used three cross-validations. output cv(), object class “cv”, plot() method producing scatter plot response versus predicted values using --sample predictions resulting cross-validation.","code":"cv_cars <- cv(mm_cars) cv_performance(cv_cars) ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## lm        15.021    14.228   0.012 ## loess     14.277    14.529   0.015 ## rpart     16.513    15.948   0.026 plot(cv_cars)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"find-the-best-fitting-model-tune","dir":"Articles","previous_headings":"Basics","what":"Find the best-fitting model: tune()","title":"An introduction to modeltuner with examples","text":"tune() applied “cv” object extracts best fitting model according test performance. applied multimodel, tune() cross-validate multimodel return best-fitting model. Different runs cv() use different folds consequently yield varying results, “best” model picked tune() can vary, . order impose given set folds, use parameter folds cv():","code":"# tune: pick the best model tune(cv_cars) ## --- A \"model\" object --- ##   label:          lm ##   model class:    lm ##   formula:        dist ~ speed ##   data:           data.frame [50 x 2], input as: 'data = cars' ##   response_type:  continuous ##   call:           lm(formula = dist ~ speed, data = data) ##   fit:            Object of class 'lm' tune(cv_cars) %>% fit  # back to fitted model ##  ## Call: ## lm(formula = dist ~ speed, data = cars) ##  ## Coefficients: ## (Intercept)        speed   ##     -17.579        3.932 cv(mm_cars, folds = cv_cars$folds) %>% cv_performance  # Same results as cv_performance(cv_cars) ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## lm        15.021    14.228   0.012 ## loess     14.277    14.529   0.015 ## rpart     16.513    15.948   0.026 cv(mm_cars) %>% cv_performance   # Slightly different results ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## lm        15.040    14.754   0.012 ## loess     14.319    14.995   0.015 ## rpart     16.237    16.812   0.026"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"manipulation-of-multimodels-and-related-objects","dir":"Articles","previous_headings":"Basics","what":"Manipulation of multimodels and related objects","title":"An introduction to modeltuner with examples","text":"modeltuner package comes number generic utility functions helpful inspection basic manipulations object classes “model”, “multimodel”, “cv”, “performance” (output cv_performance()) . presented section.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"number-of-models-and-model-labels-n_model-label","dir":"Articles","previous_headings":"Basics > Manipulation of multimodels and related objects","what":"Number of models and model labels: n_model(), label()","title":"An introduction to modeltuner with examples","text":"Query number models mm_cars labels: Modify model labels: label<- set_labels() parameter allows changing part labels:","code":"n_model(mm_cars) ## [1] 3 label(mm_cars) ## [1] \"lm\"    \"loess\" \"rpart\" set_label(mm_cars, c(\"m1\", \"m2\", \"m3\"))  # or:  label(mm_cars) <- c(\"m1\", \"m2\", \"m3\") ## --- A \"multimodel\" object containing 3 models --- ##  ## 'm1': ##   model class:  lm ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         lm(formula = dist ~ speed, data = data) ##  ## 'm2': ##   model class:  loess ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         loess(formula = dist ~ speed, data = data, control = loess.control(surface = \"direct\")) ##  ## 'm3': ##   model class:  rpart ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         rpart::rpart(formula = dist ~ speed, data = data) set_label(mm_cars, which = 3, \"tree\")    # changes only the third label (result not shown)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"subsetting-a-multimodel-or-cv-object-with-subset","dir":"Articles","previous_headings":"Basics > Manipulation of multimodels and related objects","what":"Subsetting a multimodel or “cv” object with subset()","title":"An introduction to modeltuner with examples","text":"subset.multimodel() subsets multimodel. selection can made integer, character (giving model labels) logical (appropriate length) vector. methods subset.cv() subset.performance() work analogously.","code":"subset(mm_cars, c(1, 3))  # i is integer ## --- A \"multimodel\" object containing 2 models --- ##  ## 'lm': ##   model class:  lm ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         lm(formula = dist ~ speed, data = data) ##  ## 'rpart': ##   model class:  rpart ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         rpart::rpart(formula = dist ~ speed, data = data) subset(mm_cars, c(\"lm\", \"rpart\")) # i is character - same result as above subset(mm_cars, c(T, F, T))       # i is logical - same result as above"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"extraction-of-a-model-from-a-multimodel-or-cv-object-extract_model","dir":"Articles","previous_headings":"Basics > Manipulation of multimodels and related objects","what":"Extraction of a model from a multimodel or “cv” object: extract_model()","title":"An introduction to modeltuner with examples","text":"subset.cv() yields another “cv” object, extract_model() extracts single model “cv” object multimodel, returning object class “model”. Note also function extract_multimodel(), extracts multimodel “cv” object.","code":"# extract the first model extract_model(cv_cars, 1)  # i (second argument) is integer ## --- A \"model\" object --- ##   label:          lm ##   model class:    lm ##   formula:        dist ~ speed ##   data:           data.frame [50 x 2], input as: 'data = cars' ##   response_type:  continuous ##   call:           lm(formula = dist ~ speed, data = data) ##   fit:            Object of class 'lm' extract_model(cv_cars, \"lm\")       # i is character - same result as above extract_model(cv_cars, c(T, F, F)) # i is logical - same result as above"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"sort-the-models-sort_models","dir":"Articles","previous_headings":"Basics > Manipulation of multimodels and related objects","what":"Sort the models: sort_models()","title":"An introduction to modeltuner with examples","text":"Sorting performance execution time also possible: n_model(), label(), label<-, set_label(), subset(), extract_model(), sort_model() specific methods classes “model”, “multimodel”, “cv” “performance”. help topics detailed information.","code":"# sort models sort_models(mm_cars, c(1, 3, 2)) ## --- A \"multimodel\" object containing 3 models --- ##  ## 'lm': ##   model class:  lm ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         lm(formula = dist ~ speed, data = data) ##  ## 'rpart': ##   model class:  rpart ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         rpart::rpart(formula = dist ~ speed, data = data) ##  ## 'loess': ##   model class:  loess ##   formula:      dist ~ speed ##   data:         data.frame [50 x 2], input as: 'data = cars' ##   call:         loess(formula = dist ~ speed, data = data, control = loess.control(surface = \"direct\")) sort_models(mm_cars, c(1, 3))  # same as above (omitted index 2 is appended) cv_performance(cv_cars) %>% sort_models(by = \"test\") # not for multimodels ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## lm        15.021    14.228   0.012 ## loess     14.277    14.529   0.015 ## rpart     16.513    15.948   0.026 cv_performance(cv_cars) %>% sort_models(by = \"time\") # not for multimodels ## --- Performance table --- ## Metric: rmse ##       train_rmse test_rmse time_cv ## lm        15.021    14.228   0.012 ## loess     14.277    14.529   0.015 ## rpart     16.513    15.948   0.026"},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"motivating-example-parameter-k-in-k-nearest-neighbor","dir":"Articles","previous_headings":"Hyperparameter tuning","what":"Motivating example: Parameter k in k-nearest-neighbor","title":"An introduction to modeltuner with examples","text":"now use function fm_knn() (modeltuner package) fit k-nearest model mycycle data package MASS. parameter k, number neighbors, equals 5 default. Illustration model fit:","code":"data(mcycle, package = \"MASS\")  fm_mcycle <- fm_knn(accel ~ times, data = mcycle) # function from modeltuner; k=5 by default fm_mcycle ## k-nearest neighbors model (class 'fm_knn') ##   formula:      accel ~ times - 1 ##   data:         mcycle ##   k:            5 ##   n:            133 ##   standardize:  TRUE ##   weighted:     FALSE # First create a grid along the range of 'times' (used for graphs) preddat <- data.frame(times = with(mcycle, seq(min(times), max(times), length.out = 100))) preddat$accel <- predict(fm_mcycle, preddat) ggplot(preddat, aes(times, accel)) +   geom_hline(yintercept = 0, lty = 3) +   geom_line(col = 2, lwd = 1) +   geom_point(data = mcycle, col = 4, alpha = 0.5)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"create-a-multimodel-with-multimodel","dir":"Articles","previous_headings":"Hyperparameter tuning > Motivating example: Parameter k in k-nearest-neighbor","what":"Create a multimodel with multimodel()","title":"An introduction to modeltuner with examples","text":"Next, multimodel generated contains 25 “fm_knn”-models different choices parameter k: opposed multimodel obtained joining several model c(...), multimodel generated multimodel() parameter table displayed multimodel printed, see output . multimodel mm_cycle cross-validated: Note column(s) parameter table, k example, included output cv_performance().","code":"kk <- 1:25 knn_mcycle <- multimodel(fm_mcycle, k = kk, prefix = \"knn_mcycle\") knn_mcycle ## --- A \"multimodel\" object containing 25 models --- ##  ## 'knn_mcycle1': ##   model class:  fm_knn ##   formula:      accel ~ times ##   data:         data.frame [133 x 2], input as: 'data = mcycle' ##   call:         fm_knn(formula = accel ~ times, data = data, k = 1L) ##  ## 'knn_mcycle2': ##   model class:  fm_knn ##   formula:      accel ~ times ##   data:         data.frame [133 x 2], input as: 'data = mcycle' ##   call:         fm_knn(formula = accel ~ times, data = data, k = 2L) ##  ## 'knn_mcycle3': ##   model class:  fm_knn ##   formula:      accel ~ times ##   data:         data.frame [133 x 2], input as: 'data = mcycle' ##   call:         fm_knn(formula = accel ~ times, data = data, k = 3L) ##  ## and 22 models more, labelled: ##   'knn_mcycle4', 'knn_mcycle5', 'knn_mcycle6', 'knn_mcycle7', 'knn_mcycle8', 'knn_mcycle9',  ##   'knn_mcycle10', 'knn_mcycle11', 'knn_mcycle12', 'knn_mcycle13', 'knn_mcycle14', 'knn_mcycle15',  ##   'knn_mcycle16', 'knn_mcycle17', 'knn_mcycle18', 'knn_mcycle19', 'knn_mcycle20', 'knn_mcycle21',  ##   'knn_mcycle22', 'knn_mcycle23', 'knn_mcycle24', 'knn_mcycle25' ##  ##  ## Parameter table: ##               k ## knn_mcycle1   1 ## knn_mcycle2   2 ## knn_mcycle3   3 ## ... 22 rows omitted (nrow=25) cv_mcycle <- cv(knn_mcycle) # Uses same folds for all models cv_performance(cv_mcycle) ## --- Performance table --- ## Metric: rmse ##               k train_rmse test_rmse time_cv ## knn_mcycle1   1     17.622    33.649   0.023 ## knn_mcycle2   2     18.214    27.984   0.023 ## knn_mcycle3   3     19.671    26.292   0.022 ## knn_mcycle4   4     20.202    25.751   0.023 ## knn_mcycle5   5     20.397    25.726   0.022 ## knn_mcycle6   6     20.868    25.071   0.022 ## knn_mcycle7   7     21.178    25.116   0.023 ## knn_mcycle8   8     21.358    24.644   0.023 ## knn_mcycle9   9     21.781    24.611   0.023 ## knn_mcycle10 10     22.027    24.691   0.023 ## knn_mcycle11 11     22.177    24.594   0.023 ## knn_mcycle12 12     22.297    24.691   0.024 ## knn_mcycle13 13     22.479    24.654   0.025 ## knn_mcycle14 14     22.618    24.437   0.025 ## knn_mcycle15 15     22.865    24.689   0.031 ## knn_mcycle16 16     23.080    24.658   0.023 ## knn_mcycle17 17     23.290    24.732   0.023 ## knn_mcycle18 18     23.518    25.060   0.023 ## knn_mcycle19 19     23.816    25.436   0.024 ## knn_mcycle20 20     24.136    25.404   0.024 ## knn_mcycle21 21     24.391    25.546   0.023 ## knn_mcycle22 22     24.699    26.009   0.024 ## knn_mcycle23 23     25.031    26.311   0.024 ## knn_mcycle24 24     25.520    26.664   0.024 ## knn_mcycle25 25     25.932    27.045   0.026"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"plot-a-performance-table","dir":"Articles","previous_headings":"Hyperparameter tuning > Motivating example: Parameter k in k-nearest-neighbor","what":"Plot a performance table","title":"An introduction to modeltuner with examples","text":"output cv_performance() performance table, class “performance”. plot() method displays bar chart default.  vertical dotted line identifies best-fitting model (w.r.t. test error), .e. model tune() pick. horizontal dotted line shows test error model. example, visual appearance plot can improved setting parameter xvar:  Note training error 1-nearest neighbor model larger zero. due presence bindings mcycle$times. Without bindings, curve representing training error start value zero. next plot compares model fits custom selection four values k:","code":"cv_performance(cv_mcycle) %>% plot cv_performance(cv_mcycle) %>% plot(xvar = \"k\") # xvar a column of the performance table preds <- predict(subset(knn_mcycle, c(1, 5, 10, 25)), preddat) data.frame(   model = factor(rep(colnames(preds), each = nrow(preds)),                   levels = paste0(\"knn_mcycle\", c(1, 5, 10, 25))),   times = preddat$times,    accel = as.vector(preds)) %>%    ggplot(aes(times, accel)) +   facet_wrap(~ model) +   geom_hline(yintercept = 0, lty = 3) +   geom_line(col = 2, lwd = 1) +   geom_point(data = mcycle, col = 4, alpha = 0.5)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"plot-methods-for-multi-model-and-cv","dir":"Articles","previous_headings":"Hyperparameter tuning > Motivating example: Parameter k in k-nearest-neighbor","what":"Plot methods for (multi-)model and “cv”:","title":"An introduction to modeltuner with examples","text":"methods plot.model(), plot.multimodel() plot.cv() generate scatter plots (ggplots) actual responses versus predictions. plot.model() uses (-sample) predictions single model fit, plot.cv() displays --sample predictions resulting cross-validation.  Plotting multimodel “cv” object including several models creates type plot one panel/facet model.","code":"i <- 1  # 1-nearest neighbor gridExtra::arrangeGrob(   plot(subset(knn_mcycle, i)) + # fits the model and plots response vs. fitted     ggtitle(\"plot.model: in-sample fit of 1-NN\"),    plot(subset(cv_mcycle, i)) +  # plots response vs. cv-fits     ggtitle(\"plot.cv: out-of-sample fit\"),    nrow = 1) %>% plot"},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"starting-from-the-cv-object","dir":"Articles","previous_headings":"Hyperparameter tuning > tune() a parameter","what":"Starting from the cv object:","title":"An introduction to modeltuner with examples","text":"tune() generic function, method tune.cv() simply selects best model according test error, thus returning “model” object:","code":"tune(cv_mcycle)          # Selects the best model according to test error ## --- A \"model\" object --- ##   label:          knn_mcycle14 ##   model class:    fm_knn ##   formula:        accel ~ times ##   data:           data.frame [133 x 2], input as: 'data = mcycle' ##   response_type:  continuous ##   call:           fm_knn(formula = accel ~ times, data = data, k = 14L) tune(cv_mcycle) %>% fit  # Back to non-modeltuner world (fitted model) ## k-nearest neighbors model (class 'fm_knn') ##   formula:      accel ~ times - 1 ##   data:         data ##   k:            14 ##   n:            133 ##   standardize:  TRUE ##   weighted:     FALSE"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"shortcut-methods-tune-model-and-tune-default","dir":"Articles","previous_headings":"Hyperparameter tuning > tune() a parameter","what":"“Shortcut methods” tune.model() and tune.default()","title":"An introduction to modeltuner with examples","text":"tune.model() takes object class “model” returns “tuned” version. code line mod_mcycle %>% tune(k = 1:25) executes mod_mcycle %>% multimodel(k = 1:25) %>% cv %>% tune. Likewise, tune.default() takes fitted model returns fitted model (result shown). runs fm_mcycle %>% model %>% multimodel(k = 1:20) %>% cv %>% tune %>% fit","code":"mod_mcycle <- model(fm_mcycle) mod_mcycle %>% tune(k = 1:25)   # \"Dots\" in tune(x, ...) are passed to multimodel() ## --- A \"model\" object --- ##   label:          model9 ##   model class:    fm_knn ##   formula:        accel ~ times ##   data:           data.frame [133 x 2], input as: 'data = mcycle' ##   response_type:  continuous ##   call:           fm_knn(formula = accel ~ times, data = data, k = 9L) fm_mcycle %>% tune(k = 1:25)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"binary-response","dir":"Articles","previous_headings":"","what":"Binary response","title":"An introduction to modeltuner with examples","text":"now fit glm kyphosis data package rpart:","code":"library(rpart, warn.conflicts = FALSE) data(kyphosis, package = \"rpart\") head(kyphosis) ##   Kyphosis Age Number Start ## 1   absent  71      3     5 ## 2   absent 158      3    14 ## 3  present 128      4     5 ## 4   absent   2      5     1 ## 5   absent   1      4    15 ## 6   absent   1      2    16 table(kyphosis$Kyphosis) ##  ##  absent present  ##      64      17 # glm model (fitted model) glmmod <- glm(Kyphosis == \"present\" ~ ., kyphosis, family = \"binomial\") summary(glmmod) ##  ## Call: ## glm(formula = Kyphosis == \"present\" ~ ., family = \"binomial\",  ##     data = kyphosis) ##  ## Coefficients: ##              Estimate Std. Error z value Pr(>|z|)    ## (Intercept) -2.036934   1.449575  -1.405  0.15996    ## Age          0.010930   0.006446   1.696  0.08996 .  ## Number       0.410601   0.224861   1.826  0.06785 .  ## Start       -0.206510   0.067699  -3.050  0.00229 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## (Dispersion parameter for binomial family taken to be 1) ##  ##     Null deviance: 83.234  on 80  degrees of freedom ## Residual deviance: 61.380  on 77  degrees of freedom ## AIC: 69.38 ##  ## Number of Fisher Scoring iterations: 5"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"model-object","dir":"Articles","previous_headings":"Binary response","what":"model object","title":"An introduction to modeltuner with examples","text":"modeltuner, binary response expected values 0 1. case, response_type “binary” (otherwise “continuous”), cv_performance() use logLoss metric default (contrast rmse continuous response). See ?metrics ?default_metric information.","code":"mod1_kyph <- model(glmmod, label = \"glm\") mod1_kyph ## --- A \"model\" object --- ##   label:          glm ##   model class:    glm ##   formula:        Kyphosis == \"present\" ~ Age + Number + Start ##   data:           data.frame [81 x 4], input as: 'data = kyphosis' ##   response_type:  binary ##   call:           glm(formula = Kyphosis == \"present\" ~ ., family = \"binomial\", data = data) ##   fit:            Object of classes 'glm', 'lm'"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"cross-validate-and-evaluate-result","dir":"Articles","previous_headings":"Binary response","what":"Cross-validate and evaluate result","title":"An introduction to modeltuner with examples","text":", mod1_kyph cross-validated result evaluated default metric standard metric.","code":"cv_kyph <- cv(mod1_kyph) cv_performance(cv_kyph) ## --- Performance table --- ## Metric: logLoss ##     train_logLoss test_logLoss time_cv ## glm       0.37571      0.44412   0.024 cv_performance(cv_kyph, metric = list(cl_err = classification_error)) ## --- Performance table --- ## Metric: cl_err ##     train_cl_err test_cl_err time_cv ## glm      0.15638     0.22222   0.024"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"plot-of-a-modelmultimodelcv-in-case-of-binary-response","dir":"Articles","previous_headings":"Binary response > Cross-validate and evaluate result","what":"Plot of a model/multimodel/cv in case of binary response:","title":"An introduction to modeltuner with examples","text":"plot.model() plot.cv() generate two separate violin plots predicted values two groups observations response value 0 1:","code":"# plot.(multi)model and plot.cv in binary case gridExtra::arrangeGrob(   plot(mod1_kyph) + ggtitle(\"plot.model: glm model\"),   plot(mod1_kyph %>% cv) + ggtitle(\"plot.cv: glm model\"),   nrow = 1) %>% plot"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"alternative-model-ranger","dir":"Articles","previous_headings":"Binary response","what":"Alternative model: ranger","title":"An introduction to modeltuner with examples","text":"second model kyphosis example, ranger() used fit random forest: plot shows random forest overfits data example:","code":"library(ranger) # without fitting the model... mod2_kyph <- model(\"ranger\", Kyphosis == \"present\" ~ ., kyphosis,                     num.trees = 100, max.depth = 4,                     class = \"ranger\", label = \"ranger\") gridExtra::arrangeGrob(   plot(mod2_kyph) + ggtitle(\"plot.model\"),  # overfits   plot(cv(mod2_kyph)) + ggtitle(\"plot.cv\"),   nrow = 1) %>% plot"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"combine-the-two-models-in-a-multimodel","dir":"Articles","previous_headings":"Binary response","what":"Combine the two models in a multimodel","title":"An introduction to modeltuner with examples","text":"","code":"# cv_performance mm_kyph <- c(mod1_kyph, mod2_kyph) cv_performance(mm_kyph) ## --- Performance table --- ## Metric: logLoss ##        train_logLoss test_logLoss time_cv ## glm          0.37465      0.46969   0.026 ## ranger       2.46928      7.71019   0.065"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"variable-selection-procedures-based-on-cross-validation","dir":"Articles","previous_headings":"","what":"Variable selection procedures based on cross-validation","title":"An introduction to modeltuner with examples","text":"modeltuner package collection functions modify given model adding removing variables formula optionally cross-validate . sake compact formulas printed output, first introduce variable transformation kyphosis redefine model mod1_kyph:","code":"mod1_kyph <- update(mod1_kyph,                      data = transform(kyphosis,                                       kyphosisFlag = Kyphosis == \"present\"),                      formula = kyphosisFlag ~ .)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"combine-all-models-resulting-from-removing-or-adding-one-variable","dir":"Articles","previous_headings":"Variable selection procedures based on cross-validation","what":"Combine all models resulting from removing or adding one variable","title":"An introduction to modeltuner with examples","text":"step_reduce() includes models resulting removing one variable full model, step_extend() includes models resulting adding one variable base model. full model base model defined parameters formula1 formula2. formula1 formula2 given user, actual model taken full model bare intercept model base model. See ?stepwise details. step_reduce() step_extend() return “cv” object argument cv TRUE (default) multimodel cv=FALSE.","code":"step_reduce(mod1_kyph, cv = FALSE)  # remove one variable from full model ## --- A \"multimodel\" object containing 3 models --- ##  ## '-Age': ##   model class:  glm ##   formula:      kyphosisFlag ~ Number + Start ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Number + Start, family = \"binomial\", data = data) ##  ## '-Number': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age + Start ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Age + Start, family = \"binomial\", data = data) ##  ## '-Start': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age + Number ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Age + Number, family = \"binomial\", data = data) ##  ## Parameter table: ##                               formula ## -Age    kyphosisFlag ~ Number + Start ## -Number kyphosisFlag ~ Age + Start    ## -Start  kyphosisFlag ~ Age + Number step_extend(mod1_kyph, cv = FALSE)  # add one variable to base model ## --- A \"multimodel\" object containing 3 models --- ##  ## '+Age': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Age, family = \"binomial\", data = data) ##  ## '+Number': ##   model class:  glm ##   formula:      kyphosisFlag ~ Number ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Number, family = \"binomial\", data = data) ##  ## '+Start': ##   model class:  glm ##   formula:      kyphosisFlag ~ Start ##   data:         data.frame [81 x 5],  ##                 input as: 'data = transform(kyphosis, kyphosisFlag = Kyphosis == \"present\")' ##   call:         glm(formula = kyphosisFlag ~ Start, family = \"binomial\", data = data) ##  ## Parameter table: ##                       formula ## +Age    kyphosisFlag ~ Age    ## +Number kyphosisFlag ~ Number ## +Start  kyphosisFlag ~ Start"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"backward-elimination-and-forward-selection","dir":"Articles","previous_headings":"Variable selection procedures based on cross-validation","what":"Backward elimination and forward selection","title":"An introduction to modeltuner with examples","text":"step_forward() applies step_extend() repeatedly, selecting best model w.r.t. test error step, thus performing forward selection variables. step_backward() applies step_reduce() repeatedly, selecting best model w.r.t. test error step, thus performing backward elimination variables. Backward elimination: Plot performance table backwd:  Forward selection:","code":"(backwd <- step_backward(mod1_kyph)) ## --- A \"cv\" object containing 4 validated models --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:   81 ##   Number of test sets:     10 ##   Size of test sets:       ~8 ##   Size of training sets:  ~73 ##  ## Models: ##  ## 'full': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age + Number + Start ##   metric:       logLoss ##  ## '-Number': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age + Start ##   metric:       logLoss ##  ## '-Age': ##   model class:  glm ##   formula:      kyphosisFlag ~ Start ##   metric:       logLoss ##  ## and 1 model more, labelled: ##   '-Start' ##  ##  ## Parameter table: ##                                     formula ## full    kyphosisFlag ~ Age + Number + Start ## -Number kyphosisFlag ~ Age + Start          ## -Age    kyphosisFlag ~ Start                ## -Start  kyphosisFlag ~ 1 cv_performance(backwd) ## --- Performance table --- ## Metric: logLoss ##                                     formula train_logLoss test_logLoss time_cv ## full    kyphosisFlag ~ Age + Number + Start       0.37638      0.43046   0.032 ## -Number kyphosisFlag ~ Age + Start                0.40207      0.42260   0.021 ## -Age    kyphosisFlag ~ Start                      0.41942      0.43510   0.019 ## -Start  kyphosisFlag ~ 1                          0.51356      0.51815   0.017 backwd %>% cv_performance %>% plot forwd <- step_forward(mod1_kyph)"},{"path":"https://mathiasambuehl.github.io/modeltuner/articles/modeltuner.html","id":"best-subset-model-selection","dir":"Articles","previous_headings":"Variable selection procedures based on cross-validation","what":"Best subset model selection","title":"An introduction to modeltuner with examples","text":"best_subset() combines submodels full model multimodel subjects cv(). desired range model sizes (number regressors) include specified parameter nvars. best_subset() returns either “cv” object (cv=TRUE, default) multimodel, depending parameter cv.","code":"# best subset selection (bestsub <- best_subset(mod1_kyph, nvars = 1:2)) ## --- A \"cv\" object containing 6 validated models --- ##  ## Validation procedure: Complete k-fold Cross-Validation ##   Number of obs in data:   81 ##   Number of test sets:     10 ##   Size of test sets:       ~8 ##   Size of training sets:  ~73 ##  ## Models: ##  ## '+Age': ##   model class:  glm ##   formula:      kyphosisFlag ~ Age ##   metric:       logLoss ##  ## '+Number': ##   model class:  glm ##   formula:      kyphosisFlag ~ Number ##   metric:       logLoss ##  ## '+Start': ##   model class:  glm ##   formula:      kyphosisFlag ~ Start ##   metric:       logLoss ##  ## and 3 models more, labelled: ##   '+Age+Number', '+Age+Start', '+Number+Start' ##  ##  ## Parameter table: ##                                     formula ## +Age          kyphosisFlag ~ Age            ## +Number       kyphosisFlag ~ Number         ## +Start        kyphosisFlag ~ Start          ## ... 3 rows omitted (nrow=6) bestsub %>%    cv_performance %>%   sort_models(by = \"test\") %>%   # sort models by test error   plot +   theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust=1))"},{"path":"https://mathiasambuehl.github.io/modeltuner/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mathias Ambuehl. Author, maintainer, copyright holder.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ambuehl M (2023). modeltuner: toolkit model evaluation, model comparison hyperparameter tuning based cross-validation. R package version 0.0.9, https://mathiasambuehl.github.io/modeltuner/.","code":"@Manual{,   title = {modeltuner: A toolkit for model evaluation, model comparison and hyperparameter tuning based on cross-validation},   author = {Mathias Ambuehl},   year = {2023},   note = {R package version 0.0.9},   url = {https://mathiasambuehl.github.io/modeltuner/}, }"},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/index.html","id":"contents-of-the-package","dir":"","previous_headings":"","what":"Contents of the package","title":"A toolkit for model evaluation, model comparison and hyperparameter tuning based on cross-validation","text":"modeltuner designed evaluation predictive performance statistical models hyperparameter tuning based cross-validation. current version package supports models continuous binary (0/1) response. package also offers particularly attractive tools handling called iteratively fitted models (IFM) . model, fitting process returns just one single model (model parameterization), rather range models (model parameterizations) increasing structural complexity. Prominent examples (currently instances implemented package) gradient boosting (implemented package xgboost) Lasso regression elastic nets (available package glmnet).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A toolkit for model evaluation, model comparison and hyperparameter tuning based on cross-validation","text":"package can installed github executing","code":"devtools::install_github(\"MathiasAmbuehl/modeltuner\")"},{"path":"https://mathiasambuehl.github.io/modeltuner/index.html","id":"dependencies","dir":"","previous_headings":"Installation","what":"Dependencies","title":"A toolkit for model evaluation, model comparison and hyperparameter tuning based on cross-validation","text":"package dependencies available CRAN. packages xgboost (>= 1.5), glmnet, ggplot2, MetricsWeighted, matrixStats, RANN, progress required, lme4, robustbase, mgcv, rpart, quantreg, ranger, magrittr, tibble, MASS gridExtra packages required reproduced examples.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/index.html","id":"where-to-start","dir":"","previous_headings":"","what":"Where to start","title":"A toolkit for model evaluation, model comparison and hyperparameter tuning based on cross-validation","text":"best place start two vignettes included package: vignette(\"modeltuner\") presents basic concepts package (reading text first recommended). vignette(\"ifm\") introduces tools suited developing evaluating iteratively fitted models (XGBoost glmnet models).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/c.cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Add models to a cv object — c.cv","title":"Add models to a cv object — c.cv","text":"Combines cross-validation results different models. “...” arguments can include cvs, models multimodels. cv() applied (multi)models “...”, using folds x. “cv” objects “...” must folds x.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/c.cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add models to a cv object — c.cv","text":"","code":"# S3 method for cv c(x, ..., param = TRUE)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/c.cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add models to a cv object — c.cv","text":"x object class “cv”. ... One several models, multimodels cvs. cv must folds x. param Logical: Keep parameter table? See multimodel.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/c.cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add models to a cv object — c.cv","text":"object class “cv” including models featured x “...”.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/c.cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add models to a cv object — c.cv","text":"","code":"mod1 <- model(lm(mpg ~ cyl, mtcars), label = \"simpleLinear\") mod2 <- model(lm(mpg ~ ., mtcars), label = \"linear\") # Define common folds mtcars_folds <- make_folds(mtcars, nfold = 5) # Cross validate both models separately cv1 <- cv(mod1, folds = mtcars_folds) cv2 <- cv(mod2, folds = mtcars_folds) # Combine the two cv_cars <- c(cv1, cv2) cv_performance(cv_cars) #> --- Performance table --- #> Metric: rmse #>              train_rmse test_rmse time_cv #> simpleLinear     3.0836    3.1810   0.011 #> linear           2.0058    3.5013   0.016  # Add a model to a cv object: c(cv_cars, constant = model(lm(mpg ~ 1, mtcars))) #> --- A “cv” object containing 3 validated models --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:   32 #>   Number of test sets:      5 #>   Size of test sets:       ~6 #>   Size of training sets:  ~26 #>  #> Models: #>  #> ‘simpleLinear’: #>   model class:  lm #>   formula:      mpg ~ cyl #>   metric:       rmse #>  #> ‘linear’: #>   model class:  lm #>   formula:      mpg ~ cyl + disp + hp + drat + wt + qsec + vs +  #>                     am + gear + carb #>   metric:       rmse #>  #> ‘constant’: #>   model class:  lm #>   formula:      mpg ~ 1 #>   metric:       constant.rmse"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/crit_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Preference criteria for iteratively fitted models — crit_iter","title":"Preference criteria for iteratively fitted models — crit_iter","text":"functions passed cv(model, ...) via argument iter case iteratively fitted model (see ifm). default, iter=crit_min(). crit_min() selects iteration minimal test error. crit_last() selects last iteration. crit_first() selects first iteration. crit_iter(iter) selects  iterth iteration. crit_se(factor) selects iteration minimal test error among test error exceed minimal test error factor standard errors. crit_overfit(ratio) selects iteration minimal test error among ratio training test error fall ratio. crit_list(...) combines several criteria, crit_list(crit_min(), crit_se()). Writing c(...) ... number criteria equivalent crit_list(...).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/crit_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preference criteria for iteratively fitted models — crit_iter","text":"","code":"crit_min(label_suffix = \"min\")  crit_last(label_suffix = \"last\")  crit_first(label_suffix = \"first\")  crit_iter(iter, label_suffix = paste0(\"iter\", iter))  crit_se(factor = 1, label_suffix = paste0(factor, \"se\"), warn = TRUE)  crit_overfit(ratio = 0.9, label_suffix = paste0(\"overfit\", ratio), warn = TRUE)  crit_list(...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/crit_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preference criteria for iteratively fitted models — crit_iter","text":"label_suffix Suffix used create label. iter Number iteration factor Factor applied standard error. warn Logical: Whether warn case invalid input. ratio Ratio training test error. ... Enumeration criteria.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/crit_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preference criteria for iteratively fitted models — crit_iter","text":"functions return object inheriting class “def_crit”.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/crit_iter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preference criteria for iteratively fitted models — crit_iter","text":"","code":"crit_min() #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_min() #>   label suffix:  “min” #>   Selects the iteration with minimal test error. crit_last() #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_last() #>   label suffix:  “last” #>   Selects the last iteration. crit_iter(20) #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_iter(20) #>   label suffix:  “iter20” #>   Selects iteration number min{20, # of iterations}. crit_iter(c(10, 20))  #> 2 preference criteria for an iteratively fitted model: #>  #>   criterion:     crit_iter(10) #>   label suffix:  “iter10” #>   Selects iteration number min{10, # of iterations}. #>  #>   criterion:     crit_iter(20) #>   label suffix:  “iter20” #>   Selects iteration number min{20, # of iterations}. crit_se(2) #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_se(2) #>   label suffix:  “2se” #>   Selects the first iteration where test error does not exceed #>     the minimal test error by more than 2 standard errors. crit_overfit() #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_overfit(0.9) #>   label suffix:  “overfit0.9” #>   Selects the iteration with minimal test error among those where #>   the ratio of training and test error does not fall below 0.9. crit_overfit(c(1, .9, .8)) #> 3 preference criteria for an iteratively fitted model: #>  #>   criterion:     crit_overfit(1) #>   label suffix:  “overfit1” #>   Selects the iteration with minimal test error among those where #>   the ratio of training and test error does not fall below 1. #>  #>   criterion:     crit_overfit(0.9) #>   label suffix:  “overfit0.9” #>   Selects the iteration with minimal test error among those where #>   the ratio of training and test error does not fall below 0.9. #>  #>   criterion:     crit_overfit(0.8) #>   label suffix:  “overfit0.8” #>   Selects the iteration with minimal test error among those where #>   the ratio of training and test error does not fall below 0.8.  # combine criteria with either crit_list() or c(): crit_list(crit_first(), crit_last()) #> 2 preference criteria for an iteratively fitted model: #>  #>   criterion:     crit_first() #>   label suffix:  “first” #>   Selects the first iteration. #>  #>   criterion:     crit_last() #>   label suffix:  “last” #>   Selects the last iteration. c(crit_first(), crit_last())    # the same #> 2 preference criteria for an iteratively fitted model: #>  #>   criterion:     crit_first() #>   label suffix:  “first” #>   Selects the first iteration. #>  #>   criterion:     crit_last() #>   label suffix:  “last” #>   Selects the last iteration."},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a cross-validation — cv","title":"Run a cross-validation — cv","text":"cv() executes cross-validation procedure. fold (specified argument nfold folds), original model re-fitted using complement fold training data. Cross-validations multiple models executed using identical folds.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a cross-validation — cv","text":"","code":"cv(x, ...)  # S3 method for model cv(   x,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   ...,   metric = NULL,   iter = getOption(\"cv_iter\"),   param = TRUE,   keep_fits = FALSE,   verbose = getOption(\"cv_verbose\") )  # S3 method for multimodel cv(   x,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   metric = NULL,   iter = getOption(\"cv_iter\"),   param = TRUE,   keep_fits = FALSE,   verbose = getOption(\"cv_verbose\"),   ... )  # S3 method for default cv(   x,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   ...,   metric = NULL,   iter = getOption(\"cv_iter\"),   param = TRUE,   keep_fits = FALSE )  # S3 method for cv print(   x,   what = c(\"class\", \"formula\", \"weights\"),   show_metric = TRUE,   abbreviate = TRUE,   n = getOption(\"print_max_model\"),   width = getOption(\"width\"),   param = TRUE,   ... )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a cross-validation — cv","text":"x model, multimodel fitted model (see sections “Methods”). ... arguments passed internally methods cv_simple(), currently undocumented generic runs cross-validation single model. nfold, folds Passed make_folds. metric metric (see metrics). metric=NULL selects default metric, see default_metric. iter preference criterion, list several criteria. relevant iteratively fitted models (see ifm), ignored otherwise. param Logical. Include parameter table output? See ?multimodel. keep_fits Logical: Keep cross-validation's model fits? verbose Logical: Output information execution progress console? elements multimodel printed? See print.model. show_metric Logical: Whether print cross-validated models' metric. abbreviate Logical. TRUE (default), long formulas calls printed abbreviated mode, usually fit 4 fewer output lines; otherwise printed entirely, matter long . n Integer: Model details printed first n models print.cv(). width Integer: Width printed output.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a cross-validation — cv","text":"output cv() list class “cv” following elements: multimodel: multimodel; folds: folds, defined nfold folds (see make_folds); fits: keep_fits=FALSE (default): NULL; keep_fits=TRUE: list model fits resulting cross-validation, see extract_fits); metric: list: default evaluation metrics, necessarily models; predictions: list matrices dimension \\(n \\times k\\) \\(n\\) number observations model data \\(k\\) number folds; list entries corresponds model; performance: list performance tables (see cv_performance), saved certain model classes; often NULL; timing: execution time cross-validation; extras: list extra results cross-validation, saved certain model classes; often NULL. model x iteratively fitted model (ifm), extras contain cross-validated model's evaluation log information preferred iterations.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run a cross-validation — cv","text":"cross-validations groups (folds) used models. model x processed separately function cv_simple(), generic function internal use. Besides standard method cv_simple.model(), currently specific methods cv_simple() models generated fm_xgb() fm_glmnet().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Run a cross-validation — cv","text":"cv.multimodel(), core method. cv.model(x, ...) corresponds x %>% multimodel %>% cv(...). default method essentially executes x %>% model %>% cv(...) thus expects fitted model x.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a cross-validation — cv","text":"","code":"mm <- multimodel(model(fm_knn(Sepal.Length ~ ., iris)), k = 1:5) cv(mm) #> --- A “cv” object containing 5 validated models --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  150 #>   Number of test sets:     10 #>   Size of test sets:       15 #>   Size of training sets:  135 #>  #> Models: #>  #> ‘model1’: #>   model class:  fm_knn #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   metric:       rmse #>  #> ‘model2’: #>   model class:  fm_knn #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   metric:       rmse #>  #> ‘model3’: #>   model class:  fm_knn #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   metric:       rmse #>  #> and 2 models more, labelled: #>   ‘model4’, ‘model5’ #>  #>  #> Parameter table: #>        k #> model1 1 #> model2 2 #> model3 3 #> ... 2 rows omitted (nrow=5)  mm_cars <- c(simpleLinear = model(lm(mpg ~ cyl, mtcars)),              linear = model(lm(mpg ~ ., mtcars)),              if (require(ranger)) model(ranger(mpg ~ ., mtcars), label = \"forest\")) #> Loading required package: ranger mm_cars #> --- A “multimodel” object containing 3 models --- #>  #> ‘simpleLinear’: #>   model class:  lm #>   formula:      mpg ~ cyl #>   data:         data.frame [32 x 11],  #>                 input as: ‘data = mtcars’ #>   call:         lm(formula = mpg ~ cyl, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      mpg ~ cyl + disp + hp + drat + wt + qsec + vs +  #>                     am + gear + carb #>   data:         data.frame [32 x 11],  #>                 input as: ‘data = mtcars’ #>   call:         lm(formula = mpg ~ ., data = data) #>  #> ‘forest’: #>   model class:  ranger #>   formula:      mpg ~ cyl + disp + hp + drat + wt + qsec + vs +  #>                     am + gear + carb #>   data:         data.frame [32 x 11],  #>                 input as: ‘data = mtcars’ #>   call:         ranger(formula = mpg ~ ., data = data) cv_cars <- cv(mm_cars, nfold = 5) cv_cars #> --- A “cv” object containing 3 validated models --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:   32 #>   Number of test sets:      5 #>   Size of test sets:       ~6 #>   Size of training sets:  ~26 #>  #> Models: #>  #> ‘simpleLinear’: #>   model class:  lm #>   formula:      mpg ~ cyl #>   metric:       rmse #>  #> ‘linear’: #>   model class:  lm #>   formula:      mpg ~ cyl + disp + hp + drat + wt + qsec + vs +  #>                     am + gear + carb #>   metric:       rmse #>  #> ‘forest’: #>   model class:  ranger #>   formula:      mpg ~ cyl + disp + hp + drat + wt + qsec + vs +  #>                     am + gear + carb #>   metric:       rmse cv_performance(cv_cars) #> --- Performance table --- #> Metric: rmse #>              train_rmse test_rmse time_cv #> simpleLinear     3.0484    3.3489   0.006 #> linear           2.0384    3.1289   0.012 #> forest           1.2574    2.4928   0.080  # Non-default metric: cv_performance(cv_cars, metric = \"medae\") #> --- Performance table --- #> Metric: medae #>              train_medae test_medae time_cv #> simpleLinear     1.97499     2.2592   0.006 #> linear           1.39250     2.0610   0.012 #> forest           0.91635     1.6298   0.080"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate train and test errors based on cross-validation. — cv_performance","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"cv_performance returns performance table, summary table training test errors models included main argument x, class “performance”. cv_performance.cv() core method. methods run method preprocessing steps – see section “Methods”. method plot.performance() generates graphical display performance values “performance” object x, bar chart default, alternatively line plot (depending parameter xvar).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"","code":"cv_performance(x, ...)  # S3 method for cv cv_performance(   x,   metric = x$metric[1],   eval_weights = \"default\",   na.rm = FALSE,   param = TRUE,   ... )  # S3 method for model cv_performance(x, metric = NULL, eval_weights = \"default\", na.rm = FALSE, ...)  # S3 method for multimodel cv_performance(x, metric = NULL, eval_weights = \"default\", na.rm = FALSE, ...)  # S3 method for default cv_performance(x, metric = NULL, eval_weights = \"default\", na.rm = FALSE, ...)  # S3 method for performance print(   x,   se = getOption(\"cv_show_se\"),   n = getOption(\"print_max_row\"),   digits = 5,   param = TRUE,   ... )  # S3 method for performance plot(   x,   xvar = \"model\",   errorbars = getOption(\"cv_show_se\"),   plot = TRUE,   size = 2,   lwd = 1,   lwd_errorbars = 0.5,   zeroline = TRUE,   alpha = 0.3,   ... )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"x “cv” object, object another class. ... Passed metric function. metric metric (see metrics), specified either character string (name metric function), named list length 1, list(rmse = rmse). metric=NULL selects default metric, see default_metric. eval_weights Evaluation weights; see “Evaluation weights” “Details” section ?modeltuner. \"eval_weights=default means “use fitting weights” \"eval_weights=NULL means unweighted evaluation. na.rm Logical: Whether NA values excluded computations. param Logical: Keep parameters parameter table output? se Logical: Show standard errors? n Integer: Maximal number rows print. digits Integer: Number digits print. xvar xvar specified (default), bar plot drawn. Alternatively, line plot generated, xvar variable x axis. xvar character string, name numeric variable performance table x. Typically, xvar hyperparameter varying across models. errorbars Logical: Whether add error bars plots. plot Logical: TRUE, ggplot returned, FALSE data.frame. plot() first prepares data.frame draws ggplot using data, limited options customization. want design plot, can set plot=FALSE, use data.frame returned plot() create plot. size Graphic detail: Size point. lwd Graphic detail: Line width interpolating line. lwd_errorbars Graphic detail: Line width errorbars. zeroline Logical: Whether include horizontal reference line level 0. alpha Graphic detail: Opacity bars.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"cv_performance() returns performance table. param_table additional class “performance” additional information stored attributes. row corresponds model. columns train_metric test_metric (e.g., train_rmse test_rmse), se_train_metric se_test_metric, time_cv (execution time cross-validation), possibly columns part parameter table multimodel (see “Details” section multimodel).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"different models “cv” object can different metrics, cv_performance() always reports metric models. metric specified call cv_performance(), metric first model chosen (see default_metric). cv_performance() applied “cv” object including models different default weights (weights given explicitly), cv_performance() use eval_weights=NULL. Details evaluation:  fold, evaluation metric calculated separately sets training test observations, yielding \\(k\\) pairs \\((train\\_err_i, test\\_err_i)\\), \\(=1, \\ldots, k\\), \\(k\\) number folds. cv_performance() reports average \\(train\\_err_i\\), \\(=1, \\ldots, k\\), training error average \\(test\\_err_i\\) test error. case non-NULL eval_weights, weighted averages calculated group weights computed group-wise sums observations weights. Standard errors reported errors printed set se=TRUE printing performance table, case default (see option cv_show_se, cf. modeltuner_options). standard errors reported number folds >1. computation based assumption perfect independence residuals, may thus unreliable. rough guide, standard errors reasonable case model just free parameters many observations, severely underestimate actual uncertainty case models high structural complexity.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"cv_performance.cv() core method described . uses first cross-validated model's metric default metric. cv_performance.model(x, ...) executes x %>% cv %>% cv_performance(...). cv_performance.multimodel(x, ...) executes x %>% cv %>% cv_performance(...). (implicit) default metric default_metric(x). cv_performance.default(x, ...) executes x %>% model %>% cv %>% cv_performance(...), x fitted model.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate train and test errors based on cross-validation. — cv_performance","text":"","code":"# iris data: compare several model approaches mm <- c(   lm = model(lm(Sepal.Length ~., iris)),    lm2 = model(lm(Sepal.Length ~.^2, iris)),    glmnet = model(fm_glmnet(Sepal.Length ~., iris)),    glmnet2 = model(fm_glmnet(Sepal.Length ~.^2, iris)),    fm_xgb = model(fm_xgb(Sepal.Length ~., iris))) cvobj <- cv(mm, nfold = 5)  # performance cvperm <- cv_performance(cvobj) cvperm #> --- Performance table --- #> Metric: rmse #>         train_rmse test_rmse iteration time_cv #> lm         0.29925   0.31159        NA   0.012 #> lm2        0.27921   0.32386        NA   0.012 #> glmnet     0.29932   0.31169        78   0.104 #> glmnet2    0.29160   0.31445        66   0.134 #> fm_xgb     0.14409   0.32774        16   0.071  # Sort by test error sort_models(cvperm, by = \"test\") #> --- Performance table --- #> Metric: rmse #>         train_rmse test_rmse iteration time_cv #> lm         0.29925   0.31159        NA   0.012 #> glmnet     0.29932   0.31169        78   0.104 #> glmnet2    0.29160   0.31445        66   0.134 #> lm2        0.27921   0.32386        NA   0.012 #> fm_xgb     0.14409   0.32774        16   0.071  #' print performance table with estimated standard errors (unreliable!) print(cvperm, se = TRUE) #> --- Performance table --- #> Metric: rmse #>         train_rmse test_rmse se_train_rmse se_test_rmse iteration time_cv #> lm         0.29925   0.31159     0.0115659     0.011896        NA   0.012 #> lm2        0.27921   0.32386     0.0104431     0.013302        NA   0.012 #> glmnet     0.29932   0.31169     0.0115747     0.012163        78   0.104 #> glmnet2    0.29160   0.31445     0.0105450     0.011584        66   0.134 #> fm_xgb     0.14409   0.32774     0.0098339     0.017720        16   0.071 #> The reported standard errors may be inaccurate."},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"cv_predict() extracts --sample predictions “cv” related object, cv_resid() extracts --sample residuals. generic.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"","code":"cv_predict(x, ...)  # S3 method for cv cv_predict(x, simplify = TRUE, ...)  # S3 method for model cv_predict(x, simplify = TRUE, ...)  # S3 method for multimodel cv_predict(x, simplify = TRUE, ...)  # S3 method for default cv_predict(x, simplify = TRUE, ...)  cv_resid(x, ...)  # S3 method for cv cv_resid(x, simplify = TRUE, ...)  # S3 method for model cv_resid(x, ...)  # S3 method for multimodel cv_resid(x, simplify = TRUE, ...)  # S3 method for default cv_resid(x, simplify = TRUE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"x “cv” object object another class. See “Methods”. ... used *.cv methods, passed cv methods. simplify Logical: FALSE, list vectors returned case multiple models, TRUE output converted matrix.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"vector, one model, matrix (simplify=TRUE) list vectors (simplify=FALSE).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"output depend folds used cv(). folds include observations model data, output vector shorter number rows model data.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"cv_predict.cv(x, ...) core method described . cv_predict.model(x, ...) cv_predict.multimodel execute x %>% cv(...) %>% cv_predict. cv_predict.default(x, ...) applied fitted model; executes x %>% model %>% cv(...) %>% cv_predict. cv_resid methods cv_predict.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/cv_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract out-of-sample predictions and residuals from cross-validation — cv_predict","text":"","code":"# Simulate data  set.seed(123) n <- 30 p <- 20 x <- matrix(rnorm(p*n), nrow = n) y <- rowSums(x) + rnorm(n) mymodel <- model(lm(y~x))  # Compare correlation of in-sample and out-of-sample predictions # with response preds <- data.frame(   training = predict(mymodel),    test = drop(cv_predict(mymodel))) cor(response(mymodel), preds) #>      training      test #> [1,] 0.987604 0.8395298"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/default_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the default metric of an object — default_metric","title":"Get the default metric of an object — default_metric","text":"generic function returns default metric model. default metric metric used evaluating model cv_performance(), performance() evaluation_log() metric argument specified. default metric model usually rmse response continuous logLoss binary. exception rule models based fm_xgb(), eval_metric used xgb.train() chosen default. x multimodel “cv” object several models, first model's default metric returned.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/default_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the default metric of an object — default_metric","text":"","code":"default_metric(x)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/default_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the default metric of an object — default_metric","text":"x model, multimodel, fitted model object class “cv”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/default_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the default metric of an object — default_metric","text":"named list length one containing metric function, available.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/default_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the default metric of an object — default_metric","text":"","code":"n <- 100 d <- data.frame(x = rnorm(n), y = rnorm(n)) lm(y~x, d) |> default_metric() #> Error in eval(call$data, environment): object 'd' not found glm(I(y>0)~x, d, family = binomial) |> default_metric() #> Error in eval(call$data, environment): object 'd' not found fm_xgb(y~x, d, nrounds = 10) |> default_metric() #> $rmse #> function (actual, predicted, w = NULL, ...)  #> { #>     sqrt(mse(actual = actual, predicted = predicted, w = w, ...)) #> } #> <bytecode: 0x559ab7a20188> #> <environment: namespace:MetricsWeighted> #>  fm_xgb(y~x, d, nrounds = 10, objective = \"reg:absoluteerror\") |> default_metric() #> $mae #> function (actual, predicted, w = NULL, ...)  #> { #>     stopifnot(length(actual) == length(predicted)) #>     weighted_mean(abs(actual - predicted), w = w, ...) #> } #> <bytecode: 0x559ab6829ae8> #> <environment: namespace:MetricsWeighted> #>  fm_xgb(y~x, d, nrounds = 10, objective = \"reg:pseudohubererror\") |>  default_metric()  # -> there is no function with this name #> $mphe #> NULL #>"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation log — evaluation_log","title":"Evaluation log — evaluation_log","text":"function related concept preferred iterations context iteratively fitted models (IFM). See ifm vignette(\"ifm\") information peculiarities type models. evaluation log essentially collection training test error iterations IFM (related “cv” object). appealing way displaying evaluation log usually plotting , see plot.evaluation_log.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation log — evaluation_log","text":"","code":"evaluation_log(x, ...)  # S3 method for cv evaluation_log(   x,   metric = x$metric[1],   eval_weights = extract_model(x, 1)$weights,   na.rm = FALSE,   ... )  # S3 method for evaluation_log print(   x,   se = getOption(\"cv_show_se\"),   n = getOption(\"print_max_model\"),   n_row = getOption(\"print_rows_evaluation_log\"),   digits = 3,   ... )  # S3 method for fm_xgb evaluation_log(   x,   label = deparse(substitute(x))[[1]],   metric = NULL,   eval_weights = weights(x),   ...,   .data = eval.parent(x$call$data) )  # S3 method for fm_glmnet evaluation_log(   x,   label = deparse(substitute(x))[[1]],   metric = NULL,   eval_weights = weights(x),   ...,   .data = eval.parent(x$call$data) )  # S3 method for model evaluation_log(x, metric = NULL, eval_weights = weights(x), ...)  # S3 method for multimodel evaluation_log(   x,   metric = NULL,   eval_weights = extract_model(x, 1)$weights,   ... )  # S3 method for xgb.Booster evaluation_log(x, label = deparse(substitute(x))[[1]], ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluation log — evaluation_log","text":"x Object class “cv”, “model”, “multimodel” . ... Arguments passed methods. metric metric (see metrics), specified either character string (name metric function), named list length 1, list(rmse = rmse). metric=NULL selects default metric, see default_metric. eval_weights Evaluation weights; see “Evaluation weights” “Details” section ?modeltuner. \"eval_weights=default means “use fitting weights” \"eval_weights=NULL means unweighted evaluation. na.rm Logical: Whether NA values excluded computations. se Logical: Show standard errors? n Integer: Information printed n models . n_row Integer: Evaluation log tables printed selecting n_row rows, approximately equally distributed first last iteration. Iteration corresponding choice according criteria (\"min\" etc.) added. digits Number digits printed. label Model label .data Passing data - internal use.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluation log — evaluation_log","text":"evaluation_log() returns object class “evaluation_log”. x evaluation log, (essentially empty) dummy object returned.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluation log — evaluation_log","text":"evaluation log “model” (fitted model) includes training error , evaluation log cross-validated model (object class “cv”) training test errors. several models metric specified, default_metric first model used. x includes models different weights, evaluation_log() use eval_weights=NULL. Running evaluation_log() non-default metric requires “cv” object created keep_fits=TRUE. Whenever NA predictions na.rm=TRUE, errors calculated based observations non-NA predictions iterations, subset observations used iterations.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/evaluation_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluation log — evaluation_log","text":"","code":"# Evaluation log of a 'fm_xgb' model fitted_xgb <- fm_xgb(Sepal.Length ~ ., iris, max_depth = 2) evaluation_log(fitted_xgb)    # evaluation log of a model has no  #> ‘evaluation_log’, 1 model: #>  #> Model ‘fitted_xgb’: #>   model class: fm_xgb #>  iter train_rmse test_rmse #>     1      3.823        NA #>    21      0.258        NA #>    41      0.227        NA #>    60      0.209        NA #>    80      0.197        NA #>   100      0.188        NA plot(evaluation_log(fitted_xgb)) #> Warning: Removed 100 rows containing missing values (`geom_point()`). #> Warning: Removed 100 rows containing missing values (`geom_line()`).   # Evaluation log of cross-validated 'fm_xgb' model cv_xgb <- cv(model(fitted_xgb, label = \"xgb_depth2\")) evaluation_log(cv_xgb)  #> ‘evaluation_log’, 1 cross-validated model: #>  #> Model ‘xgb_depth2’: #>   model class: fm_xgb #>  iter train_rmse test_rmse criterion #>     1      3.825     3.821           #>     8      0.469     0.497           #>    16      0.268     0.337           #>    23      0.246     0.334           #>    28      0.236     0.332       min #>    31      0.229     0.332           #>    38      0.220     0.335           plot(evaluation_log(cv_xgb))   # Evaluation log of several cross-validated models mydata <- simuldat() fitted_glmnet <- fm_glmnet(Y ~ ., mydata) cv_glmnet <- cv(multimodel(fitted_glmnet, prefix = \"glmnet\", alpha = 0:1)) label(cv_glmnet) <- c(\"ridge\", \"lasso\") evaluation_log(cv_glmnet) #> ‘evaluation_log’, 2 cross-validated models: #>  #> Model ‘ridge’: #>   model class: fm_glmnet #>  iter   lambda train_rmse test_rmse criterion #>     1 1021.414       2.85      2.84           #>    21  158.899       2.83      2.82           #>    41   24.720       2.69      2.70           #>    60    4.220       2.29      2.35           #>    80    0.657       1.94      2.06           #>    95    0.163       1.90      2.04       min #>   100    0.102       1.90      2.04           #>  #> Model ‘lasso’: #>   model class: fm_glmnet #>  iter  lambda train_rmse test_rmse criterion #>     1 1.02141       2.85      2.84           #>    14 0.30475       2.20      2.24           #>    27 0.09093       1.95      2.04           #>    36 0.03936       1.91      2.03       min #>    39 0.02977       1.90      2.03           #>    52 0.00888       1.90      2.04           #>    65 0.00265       1.90      2.04           plot(evaluation_log(cv_glmnet))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/expand_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a formula — expand_formula","title":"Expand a formula — expand_formula","text":"Replicate formula varying parameter values.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/expand_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a formula — expand_formula","text":"","code":"expand_formula(formula, ..., expand = TRUE)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/expand_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a formula — expand_formula","text":"formula formula. ... Named parameters expanded. expand Logical: Expand “...” arguments (default) join element-wise? expand=TRUE, vectors “...” expanded, number models equal product lengths “...” arguments; otherwise, “...” arguments must equal lengths, number models equal common length.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/expand_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a formula — expand_formula","text":"list formulas.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/expand_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a formula — expand_formula","text":"","code":"expand_formula(y ~ ns(x, df = k), k = 1:10) #> [[1]] #> y ~ ns(x, df = 1L) #> <environment: 0x559abbde6638> #>  #> [[2]] #> y ~ ns(x, df = 2L) #> <environment: 0x559abbde6638> #>  #> [[3]] #> y ~ ns(x, df = 3L) #> <environment: 0x559abbde6638> #>  #> [[4]] #> y ~ ns(x, df = 4L) #> <environment: 0x559abbde6638> #>  #> [[5]] #> y ~ ns(x, df = 5L) #> <environment: 0x559abbde6638> #>  #> [[6]] #> y ~ ns(x, df = 6L) #> <environment: 0x559abbde6638> #>  #> [[7]] #> y ~ ns(x, df = 7L) #> <environment: 0x559abbde6638> #>  #> [[8]] #> y ~ ns(x, df = 8L) #> <environment: 0x559abbde6638> #>  #> [[9]] #> y ~ ns(x, df = 9L) #> <environment: 0x559abbde6638> #>  #> [[10]] #> y ~ ns(x, df = 10L) #> <environment: 0x559abbde6638> #>  expand_formula(y ~ I(x^e1) + I(z^e2), e1 = 1:2, e2 = 1:3) #> [[1]] #> y ~ I(x^1L) + I(z^1L) #> <environment: 0x559abbde6638> #>  #> [[2]] #> y ~ I(x^1L) + I(z^2L) #> <environment: 0x559abbde6638> #>  #> [[3]] #> y ~ I(x^1L) + I(z^3L) #> <environment: 0x559abbde6638> #>  #> [[4]] #> y ~ I(x^2L) + I(z^1L) #> <environment: 0x559abbde6638> #>  #> [[5]] #> y ~ I(x^2L) + I(z^2L) #> <environment: 0x559abbde6638> #>  #> [[6]] #> y ~ I(x^2L) + I(z^3L) #> <environment: 0x559abbde6638> #>  expand_formula(y ~ I(x^e1) + I(z^e2), e1 = 1:3, e2 = 1:3, expand = FALSE) #> [[1]] #> y ~ I(x^1L) + I(z^1L) #> <environment: 0x559abbde6638> #>  #> [[2]] #> y ~ I(x^2L) + I(z^2L) #> <environment: 0x559abbde6638> #>  #> [[3]] #> y ~ I(x^3L) + I(z^3L) #> <environment: 0x559abbde6638> #>"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_fits.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","title":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","text":"Extraction model fits possible saved part “cv” object, case default. See argument keep_fits ?cv.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_fits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","text":"","code":"extract_fits(x, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_fits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","text":"x cv-object. ... Currently used.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_fits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","text":"param_table. Besides model fits, also column containing folds.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_fits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the models fitted in a cross-validation from a “cv” object. — extract_fits","text":"","code":"mm <- c(lm =    model(lm(Sepal.Width ~ ., iris)),          if (require(rpart)) model(rpart(Sepal.Width ~ ., iris), label = \"rpart\")) #> Loading required package: rpart mycv <- cv(mm, keep_fits = TRUE) extract_fits(mycv) #>        folds   lm   rpart #> 1  <int>[15] <lm> <rpart> #> 2  <int>[15] <lm> <rpart> #> 3  <int>[15] <lm> <rpart> #> 4  <int>[15] <lm> <rpart> #> 5  <int>[15] <lm> <rpart> #> 6  <int>[15] <lm> <rpart> #> 7  <int>[15] <lm> <rpart> #> 8  <int>[15] <lm> <rpart> #> 9  <int>[15] <lm> <rpart> #> 10 <int>[15] <lm> <rpart>"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Extraction of a model and multimodel — extract_model","title":"Extraction of a model and multimodel — extract_model","text":"extract_model() extracts model “multimodel” “cv” object. extract_multimodel() extracts multimodel “cv” object.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extraction of a model and multimodel — extract_model","text":"","code":"extract_model(x, which, ...)  # S3 method for multimodel extract_model(x, which, use_cv_info = TRUE, ...)  # S3 method for cv extract_model(x, which, use_cv_info = TRUE, ...)  extract_multimodel(x, ...)  # S3 method for cv extract_multimodel(x, use_cv_info = TRUE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extraction of a model and multimodel — extract_model","text":"x “multimodel” “cv” object. Selection one model: integer value logical vector length n_model(x) exactly one TRUE, character value (selection name, model's label). n_model(x)==1, model selected default. ... Arguments passed methods. use_cv_info Logical: Whether set preferred iteration according results cross-validation (present). Relevant iteratively fitted models (ifm).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extraction of a model and multimodel — extract_model","text":"extract_model() returns model, extract_multimodel() returns multimodel.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/extract_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extraction of a model and multimodel — extract_model","text":"","code":"mm_swiss <- c(model(lm(Fertility ~ Education, swiss)),               model(lm(Fertility ~ Education + I(Education^2) , swiss))) cv_swiss <- cv(mm_swiss)  extract_model(mm_swiss, 1) # a model #> --- A “model” object --- #>   label:          model #>   model class:    lm #>   formula:        Fertility ~ Education #>   data:           data.frame [47 x 6],  #>                   input as: ‘data = swiss’ #>   response_type:  continuous #>   call:           lm(formula = Fertility ~ Education, data = data) #>   fit:            Object of class ‘lm’ subset(mm_swiss, 1)        # a multimodel #> --- A “multimodel” object containing 1 model --- #>  #> ‘model’: #>   model class:  lm #>   formula:      Fertility ~ Education #>   data:         data.frame [47 x 6],  #>                 input as: ‘data = swiss’ #>   call:         lm(formula = Fertility ~ Education, data = data)  extract_model(cv_swiss, 1)      # a model #> --- A “model” object --- #>   label:          model #>   model class:    lm #>   formula:        Fertility ~ Education #>   data:           data.frame [47 x 6],  #>                   input as: ‘data = swiss’ #>   response_type:  continuous #>   call:           lm(formula = Fertility ~ Education, data = data) #>   fit:            Object of class ‘lm’ extract_multimodel(cv_swiss, 1) # a multimodel #> --- A “multimodel” object containing 2 models --- #>  #> ‘model’: #>   model class:  lm #>   formula:      Fertility ~ Education #>   data:         data.frame [47 x 6],  #>                 input as: ‘data = swiss’ #>   call:         lm(formula = Fertility ~ Education, data = data) #>  #> ‘model1’: #>   model class:  lm #>   formula:      Fertility ~ Education + I(Education^2) #>   data:         data.frame [47 x 6],  #>                 input as: ‘data = swiss’ #>   call:         lm(formula = Fertility ~ Education + I(Education^2),  #>                     data = data) subset(cv_swiss, 1)             # a cv #> --- A “cv” object containing 1 validated model --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:   47 #>   Number of test sets:     10 #>   Size of test sets:       ~5 #>   Size of training sets:  ~42 #>  #> Model: #>  #> ‘model’: #>   model class:  lm #>   formula:      Fertility ~ Education #>   metric:       rmse"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-fit a model object using the complete model data — fit","title":"Re-fit a model object using the complete model data — fit","text":"Fits fitted model (lm) expressed “model” object using complete model data. way, fit() inverse operation model(). add_fit() adds model fit “model” object, component fit (already present). methods classes “multimodel”  “cv” similarly add fitted models included models. has_fit() generic function discerns whether (multi-)model contains corresponding fitted model(s).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-fit a model object using the complete model data — fit","text":"","code":"fit(x, ...)  # S3 method for model fit(   x,   eval = TRUE,   use_original_args = FALSE,   force = FALSE,   env = parent.frame(),   ... )  # S3 method for multimodel fit(   x,   eval = TRUE,   use_original_args = FALSE,   force = FALSE,   which,   env = parent.frame(),   ... )  # S3 method for cv fit(   x,   eval = TRUE,   use_original_args = FALSE,   force = FALSE,   which,   env = parent.frame(),   ... )  add_fit(x, ...)  has_fit(x)  # S3 method for model_fm_glmnet fit(x, iter, eval = TRUE, force = FALSE, ...)  # S3 method for model_fm_xgb fit(x, iter, eval = TRUE, force = FALSE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-fit a model object using the complete model data — fit","text":"x “model” object ... Passed model fitting function. eval Logical: FALSE, call model fitting function returned, executed. use_original_args Logical: FALSE, model generating call evaluated internally, using data (potential additional objects) saved x; TRUE, evaluation takes place calling environment fit(), using original input data. force Logical: FALSE fitted model present fit component model x, fit returned. force=TRUE, model re-fitted case. env environment. Used internal purposes. Selection one model: integer value logical vector length n_model(x) exactly one TRUE, character value (selection name, model's label). n_model(x)==1, model selected default. iter iteration","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-fit a model object using the complete model data — fit","text":"fit() returns fitted model. add_fit() returns object class “model”. has_fit() returns logical vector length n_model(x).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Re-fit a model object using the complete model data — fit","text":"fit() generic specific methods classes “model_fm_glmnet” “model_fm_xgb”. See fm_glmnet, fm_xgb examples . iteratively fitted models (ifms, currently classes  “fm_xgb” “fm_glmnet”), fit() executes set_pref_iter() internally. information preferred iteration (cross-validation) attached x, call model generating function thereby adjusted. suppress adjustment, run fit() iter=NULL. Another peculiarity fit(x) x IFM information preferred iterations comes play , addition, x model fit attached (.e. has_fit(x)==TRUE). case, fitted model partially adapted according preferred iteration. Specifically, pref_iter set fitted model call (parameters related stopping choice iteration predictions modified). model fit attached output improper sense differs result execute call (predictions ). default behavior can suppressed setting force=TRUE, consequently increases execution time time required fit model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Re-fit a model object using the complete model data — fit","text":"fit.model() converts “model” object x fitted model class x$class. fit.multimodel() fit.cv() extract single model x according argument (see extract_model()) applies fit.model() result. fit.model_fm_glmnet() fit.model_fm_xgb() specific methods two model classes. special feature methods goes action x contains results preferred iteration resulting cross-validation. case preferred iteration selected cross-validation results (see set_pref_iter()).","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-fit a model object using the complete model data — fit","text":"","code":"# Applying model() then fit() to a model returns the original model: mod <- model(lm(Sepal.Width ~ ., iris), label = \"lm\") mod #> --- A “model” object --- #>   label:          lm #>   model class:    lm #>   formula:        Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   call:           lm(formula = Sepal.Width ~ ., data = data) #>   fit:            Object of class ‘lm’ fit(mod) #>  #> Call: #> lm(formula = Sepal.Width ~ ., data = iris) #>  #> Coefficients: #>       (Intercept)       Sepal.Length       Petal.Length        Petal.Width   #>            1.6572             0.3778            -0.1876             0.6257   #> Speciesversicolor   Speciesvirginica   #>           -1.1603            -1.3983   #>   # Obtain the model call without executing it: fit(mod, eval = FALSE) #> lm(formula = Sepal.Width ~ ., data = data) # Note the generic 'data=data' in the result # In order to obtain the original call, do: fit(mod, eval = FALSE, use_original_args = TRUE) #> lm(formula = Sepal.Width ~ ., data = iris)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a constant model — fm_const","title":"Fitting a constant model — fm_const","text":"model fitting function usual arguments formula, data optionally weights, defining “constant model”. Model predictions equal result applying fun() response (left hand side variable formula) observations. Fitting model thus amounts evaluating fun(y), y denotes model response.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a constant model — fm_const","text":"","code":"fm_const(formula, data, fun = mean, weights = NULL, na.action = na.omit, ...)  # S3 method for fm_const print(x, abbreviate = TRUE, ...)  # S3 method for fm_const predict(object, newdata, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a constant model — fm_const","text":"formula formula. left hand side relevant. data data.frame. fun function defining location estimate. Takes numeric vector first argument, optionally argument weights, returns numeric value. weights Optional numeric vector, fitting weights. na.action function indicates happen response variable contains NAs. ... Arguments passed fun(). x, object Object class “fm_const”. abbreviate Logical. TRUE (default), long formulas calls printed abbreviated mode, usually fit 4 fewer output lines; otherwise printed entirely, matter long . newdata Data prediction.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a constant model — fm_const","text":"fm_const() returns list class “fm_glmnet” components estimate: estimated value; formula: formula; n: number rows data; rownames: rownames data; fun: fitting function fun(); weights: fitting weights; na.action: na.action used data preparation; call: matched call generating model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Fitting a constant model — fm_const","text":"print(fm_const): print() method predict(fm_const): predict() method","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_const.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a constant model — fm_const","text":"","code":"fm <- fm_const(Sepal.Width ~ 1, iris) fm #> fm_const-model (class ‘fm_knn’) #>   formula:   Sepal.Width ~ 1 #>   data:      iris #>   estimate:  3.057333 #>   fun:       function (x, ...)   unique(predict(fm)) # all equal values #> [1] 3.057333  # Weighted constant model wmean <- function(x, weights, ...) weighted.mean(x, w = weights, ...) w <- runif(150) fm_const(Sepal.Length ~ 1, iris, weights = w, fun = wmean) #> fm_const-model (class ‘fm_knn’) #>   formula:   Sepal.Length ~ 1 #>   data:      iris #>   estimate:  5.896345 #>   fun:       function (x, weights, ...)   #>   weights:   numeric [150]"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"formula-based wrapper for glmnet() — fm_glmnet","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"fm_glmnet() wrapper glmnet() (package glmnet) fits modeltuner framework. model specified arguments formula data. resulting models belong class -called iteratively fitted models, see ifm vignette(\"ifm\") information.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"","code":"fm_glmnet(   formula,   data,   weights = NULL,   family = c(\"gaussian\", \"binomial\", \"poisson\"),   pref_iter = NULL,   na.action = na.omit,   keep_x = TRUE,   ... )  # S3 method for fm_glmnet predict(   object,   newdata,   pref_iter = object$pref_iter,   s = tail(object$fit$lambda, 1),   ... )  # S3 method for fm_glmnet coef(object, s = tail(object$fit$lambda, 1), ...)  # S3 method for fm_glmnet plot(   x,   coefs = NULL,   intercept = FALSE,   plot_type = c(\"colors\", \"facets\"),   size = 0.6,   lwd = 0.5,   ...,   plot = TRUE,   zeroline = TRUE )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"formula formula. data data.frame weights weights family, ... Passed glmnet(). work properly: avoid argument settings change structure output glmnet()! plot.fm_glmnet(),  “...” passed geom_point() geom_line(). pref_iter integer, preferred iteration. iteration used default predictions model computed predict(). pref_iter=NULL, last iteration used. See ifm vignette(\"ifm\") information concepts iteratively fitted models preferred iterations. preferred iteration model can changed without re-fitting model, see set_pref_iter(). na.action function indicates happen data contain NAs. na.omit default, na.exclude na.fail useful alternative settings. keep_x Logical: Whether keep model matrix x component return value. object, x Object class “fm_glmnet”. newdata Data prediction. s Choice lambda. coefs Character vector: optional subset x variables' names included plot. default, included. intercept Logical: Whether include intercept's profile plot. plot_type character string, either colors (profiles coefficients shown facet distinguished colors) facet (profiles different coefficients appear separate facets). size Graphic detail: Size point. lwd Graphic detail: Line width interpolating line. plot Logical: TRUE, ggplot returned, FALSE data.frame. plot() first prepares data.frame draws ggplot using data, limited options customization. want design plot, can set plot=FALSE, use data.frame returned plot() create plot. zeroline Logical: Whether include horizontal reference line level 0.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"fm_glmnet() returns list class “fm_glmnet” components fit: fitted model, class “glmnet”; formula: formula; x: model matrix (resulting formula using model.matrix()); weights: fitting weights; xlevels: list levels factors included model; pref_iter: preferred iteration, integer (see argument pref_iter); na.action: na.action used data preparation; contrasts: contrasts used data preparation; call: matched call generating model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"family must one \"gaussian\", \"binomial\", \"poisson\". parameters x y passed glmnet() extracted formula data means model.frame, model.matrix model.response. Features cross-validation models generated fm_glmnet(): model class “fm_glmnet” belongs class -called iteratively fitted models; see ifm vignette(\"ifm\") information peculiarities cross-validating models. particular, note role parameter iter cv(). cv() executed keep_fits=TRUE, fitted models cross-validation stored result (returned extract_fits()) class “fm_glmnet”, class “glmnet”,","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"predict(fm_glmnet): predict() method coef(fm_glmnet): coef() method plot(fm_glmnet): plot() method. Produces coefficient profile plot.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_glmnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"formula-based wrapper for glmnet() — fm_glmnet","text":"","code":"d <- simuldat()   (mod1 <- fm_glmnet(Y ~., d)) #> Fitted model of class ‘fm_glmnet’  #>   formula:     Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 +  #>                    X10 + g - 1 #>   data:        d (500 rows) #>   call:        fm_glmnet(formula = Y ~ ., data = d) #>   iterations:  65 #>   pref_iter:   65 (mod2 <- fm_glmnet(Y ~.^2, d)) #> Fitted model of class ‘fm_glmnet’  #>   formula:     Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 +  #>                    X10 + g + X1:X2 + X1:X3 + X1:X4 + X1:X5 + X1:X6 +  #>                    X1:X7 + X1:X8 + X1:X9 + X1:X10 + X1:g + X2:X3 +  #>                    ... [formula cut off - 66 terms on rhs] #>   data:        d (500 rows) #>   call:        fm_glmnet(formula = Y ~ .^2, data = d) #>   iterations:  88 #>   pref_iter:   88  # Plot mod1: plot(mod1)  # Plot profiles for a subset of the coefficients' only and the intercept plot(mod1, coefs = paste0(\"X\", 1:10), intercept = TRUE)   # Cross-validate mycv <- cv(c(model(mod1, label = \"mod1\"),               model(mod2, label = \"mod2\")),             nfold = 5) mycv #> --- A “cv” object containing 2 validated models --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  500 #>   Number of test sets:      5 #>   Size of test sets:      100 #>   Size of training sets:  400 #>  #> Models: #>  #> ‘mod1’: #>   model class:  fm_glmnet #>   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 +  #>                     X10 + g - 1 #>   metric:       rmse #>  #> ‘mod2’: #>   model class:  fm_glmnet #>   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 +  #>                     X10 + g + X1:X2 + X1:X3 + X1:X4 + X1:X5 + X1:X6 +  #>                     X1:X7 + X1:X8 + X1:X9 + X1:X10 + X1:g + X2:X3 +  #>                     ... [formula cut off - 66 terms on rhs] #>   metric:       rmse #>  #> Preferred iterations: #>   model ‘mod1’:  min (iter=57) #>   model ‘mod2’:  min (iter=30)  # Plot cv_performance and evaluation_log: plot(cv_performance(mycv))  plot(evaluation_log(mycv))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":null,"dir":"Reference","previous_headings":"","what":"k-Nearest Neighbors model — fm_knn","title":"k-Nearest Neighbors model — fm_knn","text":"formula-based implementation k-Nearest Neighbor. fm_knn() “fits” model, essentially amounts saving reformatted copy model data. predict method finds nearest neighbors points newdata (using nn2() package RANN) returns averages.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-Nearest Neighbors model — fm_knn","text":"","code":"fm_knn(   formula,   data,   k = 5,   standardize = TRUE,   weights = NULL,   na.action = na.omit,   ... )  # S3 method for fm_knn predict(object, newdata, k = object$k, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-Nearest Neighbors model — fm_knn","text":"formula formula. data data.frame. k Either scalar integer, number neighbors, alternatively vector (typically decreasing) non-negative numeric values. latter case, model predictions weighted averages, k[1] used weight nearest neighbor, k[2] second nearest, etc. standardize Logical: Standardize columns x, design matrix? TRUE, distances calculated standardization using means standard deviations x matrix. weights Weights used averaging. used determination neighbors. na.action function indicates happen data contain NAs. na.omit default, na.exclude na.fail useful alternative settings. ... used fm_knn(). predict.fm_knn(): passed nn2(). object Object class “fm_knn”. newdata data.frame data predicted. missing, predictions model data returned.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-Nearest Neighbors model — fm_knn","text":"fm_knn() returns list class “fm_knn” components formula: formula; x: model matrix (resulting formula using model.matrix()); y: vector response values; k: parameter k, number neighbors; standardize: parameter standardize, logical value; weights: fitting weights; xlevels: list levels factors included model; na.action: na.action used data preparation; contrasts: contrasts used data preparation; call: matched call generating model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"k-Nearest Neighbors model — fm_knn","text":"“Fitting” model fm_knn() essentially amounts saving (possibly standardized) model data. Bindings distances currently handled clever way, predictions may depend order data. Combining argument k length >1 non-Null weights results mixture two types weights thus recommended.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"k-Nearest Neighbors model — fm_knn","text":"predict(fm_knn): predict method class “fm_knn”.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_knn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"k-Nearest Neighbors model — fm_knn","text":"","code":"d <- simuldat() nnmodel <- fm_knn(Y~ ., d) nnmodel #> k-nearest neighbors model (class ‘fm_knn’) #>   formula:      Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 +  #>                     X10 + g - 1 #>   data:         d #>   k:            5 #>   n:            500 #>   standardize:  TRUE #>   weighted:     FALSE  # Predictions for new observations  newd <- simuldat(n = 10) data.frame(newd[\"Y\"],             pred = predict(nnmodel, newdata = newd)) #>            Y     pred #> 1   1.166769 4.275125 #> 2  -0.382027 3.363760 #> 3   3.995346 3.319309 #> 4   2.147231 4.006339 #> 5  -1.104314 1.872762 #> 6   1.901924 2.373253 #> 7   1.163698 4.679739 #> 8   7.857975 2.994145 #> 9   3.015759 3.390070 #> 10  5.449470 4.267375"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothing spline model with formula-interface — fm_smooth_spline","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"simple wrapper smooth.spline() stats package.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"","code":"fm_smooth_spline(formula, data, weights = NULL, na.action = na.omit, ...)  # S3 method for fm_smooth_spline predict(object, newdata, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"formula formula one variable right hand side. data data.frame. weights Case weights. na.action function indicates happen data contain NAs. na.omit default, na.exclude na.fail useful alternative settings. ... Passed smooth.spline(). object Object class “fm_smooth_spline”. newdata data.frame data predicted. missing, predictions model data returned.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"fm_smooth_spline() returns list class “fm_smooth_spline” components smooth.spline: fitted spline, class “smooth.spline”; formula: formula; weights: fitting weights; na.action: na.action used data preparation; call: matched call generating model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"predict(fm_smooth_spline): predict method class “fm_smooth_spline”.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_smooth_spline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothing spline model with formula-interface — fm_smooth_spline","text":"","code":"(smooth <- fm_smooth_spline(dist ~ speed, data = cars)) #> Fitted model of class ‘fm_smooth_spline’  #>   formula:  dist ~ speed - 1 #>   data:     cars #>   call:     fm_smooth_spline(formula = dist ~ speed, data = cars) #>    #>   Smoothing Parameter  spar= 0.7801305  lambda= 0.1112206 (11 iterations) #>   Equivalent Degrees of Freedom (Df): 2.635278 #>   Penalized Criterion (RSS): 4187.776 #>   GCV: 244.1044 newd <- data.frame(speed = seq(min(cars$speed), max(cars$speed), length.out = 100)) plot(dist ~speed, cars, col = 4) lines(newd$speed, predict(smooth, newd), col = 2)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":null,"dir":"Reference","previous_headings":"","what":"formula-based wrapper for xgb.train() — fm_xgb","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"fm_xgb() convenience wrapper tree boosting xgb.train() (package xgboost) fits modeltuner framework. model specified arguments formula data. resulting models belong class -called iteratively fitted models, see ifm vignette(\"ifm\") information.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"","code":"fm_xgb(   formula,   data,   nrounds = 100,   early_stopping_rounds = 10,   weights = NULL,   na.action = na.pass,   verbose = interactive(),   monotone_constraints = 0,   interaction_constraints = NULL,   obj = NULL,   feval = NULL,   maximize = FALSE,   pref_iter = NULL,   keep_x = TRUE,   ... )  # S3 method for fm_xgb print(x, abbreviate = TRUE, ...)  # S3 method for fm_xgb predict(object, newdata, pref_iter = object$pref_iter, ...)  extract_booster(object)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"formula formula. data data.frame. nrounds, early_stopping_rounds, obj, feval, maximize Passed xgb.train (note default values different). weights Fitting weights. na.action function indicates happen data contain NAs. na.pass default, na.omit, na.exclude na.fail meaningful alternative settings. verbose Logical: Whether print information progress console. monotone_constraints Named vector values c(-1, 0, 1). Names identify features, 1 means increasing, -1 decreasing 0 constraint. Features appearing assigned 0 call xgb.train(). Default constraints. interaction_constraints List named character vectors defining interaction constraints. Default constraints. pref_iter integer, preferred iteration. iteration used default predictions model computed predict(). pref_iter=NULL, last iteration used. See ifm vignette(\"ifm\") information concepts iteratively fitted models preferred iterations. preferred iteration model can changed without re-fitting model, see set_pref_iter(). keep_x Logical: Whether keep model matrix x component return value. ... Passed params xgb.train(). x, object Object class “fm_xgb”. abbreviate Logical. TRUE (default), long formulas calls printed abbreviated mode, usually fit 4 fewer output lines; otherwise printed entirely, matter long . newdata Data prediction.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"fm_xgb() returns list class “fm_xgb” components booster: xgboost booster, class “xgb.Booster”; formula: formula; x: model matrix (resulting formula using model.matrix()); weights: fitting weights; xlevels: list levels factors included model; pref_iter: preferred iteration, integer (see argument pref_iter); na.action: na.action used data preparation; contrasts: contrasts used data preparation; call: matched call generating model. extract_booster() returns booster, class “xgb.Booster”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"parameters xgb.train() available fm_xgb(). particular, related console output (verbose, print_every_n), related saving result (save_period, save_name) callbacks passed xgb.train(). parameters x y passed xgb.train() extracted formula data means model.frame, model.matrix model.response. Features cross-validation models generated fm_xgb(): model class “fm_xgb” belongs class -called iteratively fitted models; see ifm vifnette(\"ifm\") information peculiarities cross-validating models. particular, note role parameter iter cv(). cv() executed keep_fits=TRUE, fitted models cross-validation stored result (returned extract_fits()) class “fm_xgb”, class “xgb.Booster”, Default metric: Currently, xgboost models generated fm_xgb() models default choice metric, rmse continuous response logLoss binary case. xgboost model eval_metric. specified explicitly user, metric automatically chosen depending objective call xgb.train() fm_xgb(). modeltuner, cv() applied, eval_metric taken default metric resulting \"cv\" object. (see default_metric()). extract_booster() returns booster, object class “xgb.Booster”, returned xgb.train().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"print(fm_xgb): print() method predict(fm_xgb): predict() method","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/fm_xgb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"formula-based wrapper for xgb.train() — fm_xgb","text":"","code":"# mtcars data xgb_cars <- fm_xgb(mpg ~ ., mtcars) # predict predict(xgb_cars, newdata = head(mtcars)) #>         Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive  #>          21.00058          20.99997          22.79976          21.39912  #> Hornet Sportabout           Valiant  #>          18.70015          18.10004   # iris data xgb_iris <- fm_xgb(Sepal.Width ~ ., iris) # cross-validate cv(xgb_iris) #> --- A “cv” object containing 1 validated model --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  150 #>   Number of test sets:     10 #>   Size of test sets:       15 #>   Size of training sets:  135 #>  #> Model: #>  #> ‘model’: #>   model class:  fm_xgb #>   formula:      Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                     Species - 1 #>   metric:       rmse #>  #> Preferred iterations: #>   model ‘model’:  min (iter=12) # Plot evaluation log plot(evaluation_log(last_cv()))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/hello.html","id":null,"dir":"Reference","previous_headings":"","what":"Hello, World! — hello","title":"Hello, World! — hello","text":"Prints 'Hello, world!'.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/hello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hello, World! — hello","text":"","code":"hello()"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/hello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hello, World! — hello","text":"","code":"hello() #> Error in hello(): could not find function \"hello\""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":null,"dir":"Reference","previous_headings":"","what":"Iteratively fitted models (IFM) and preferred iterations — ifm","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"topic covers concept iteratively fitted models (IFM) related selection mechanism preferred iterations. introduction application examples, refer vignette vignette(\"ifm\").","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":"iteratively-fitted-models","dir":"Reference","previous_headings":"","what":"Iteratively fitted models","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"use term iteratively fitted model classes models fitting process returns just one single model (model parameterization), rather sequence models (model parameterizations) increasing structural complexity. refer single models sequence (model) iteration. Prominent examples (currently two instances implemented package) : gradient boosting: fm_xgb() wrapper xgb.train() package xgboost. iterations arise successively adding trees current fitted model. Lasso regression elastic net models: fm_glmnet() wrapper glmnet() package glmnet. , iterations results successively lowering penalty parameter lambda. conceptual framework described , crucial predictions can computed iteration, iteration-wise training test errors can calculated, .","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":"evaluation-log","dir":"Reference","previous_headings":"","what":"Evaluation log","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"evaluation log essentially table one row per iteration including columns training /test error respective iteration. evaluation log “model” (fitted model) includes training error , evaluation log cross-validated model (object class “cv”) training test errors. modeltuner package function evaluation_log() computes evaluation logs models “cv” objects, plot method, plot.evaluation_log().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":"selection-criteria-for-iterations","dir":"Reference","previous_headings":"","what":"Selection criteria for iterations","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"function cv() mechanism specification preferred iterations. user specifies one several selection criteria parameter iter= call cv(). default (package startup), iteration minimal test error selected. default can however modified setting option \"cv_iter\" (see modeltuner_options). effect determining preference criterion application cv_performance() “cv” object show results (training test error) iteration selected based criterion. preferred iteration can altered specifying iter=criterion cv(), criterion selection rule applied internally cv's evaluation log, resulting choice preferred iteration. minimal test error rule corresponds setting iter=crit_min(); alternative selection criteria presented crit_iter. Multiple criteria can requested, crit_list(crit_min(), crit_1se()). case, cv_performance() show results related first criterion (listed first position crit_list(...)). “cv” object's selection criteria selected iterations displayed print . can extract information related iterations extract_pref_iter().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":"modifying-the-preference-criteria-of-a-cv-object","dir":"Reference","previous_headings":"","what":"Modifying the preference (criteria) of a “cv” object","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"set_pref_iter() expand_pref_iter() offer options change cv's preferences respect selection iterations subsequently. Note however certain analyses remain available iterations related criteria stated iter argument original call cv(). particular, case running cv_performance() alternative metrics. reason limitation full sets predictions cross-validation stored preferred iterations resulting originally stated criteria. Setting keep_fits=TRUE cv() option circumvent limitations (can excessively memory-consuming). case, model fits cross-validation stored resulting object, predictions iterations remain obtainable. particular, makes possible compute evaluation logs alternative metrics. See expand_pref_iter() set_metric() manipulations “cv” objects.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/ifm.html","id":"fitting-an-ifm-after-a-cross-validation","dir":"Reference","previous_headings":"","what":"Fitting an IFM after a cross-validation","title":"Iteratively fitted models (IFM) and preferred iterations — ifm","text":"“cv” object based IFM converted back model (tune() extract_model()), information preferred iterations stored attribute. Likewise, fit() used obtain resulting fitted model, model corresponding preferred iteration returned.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":null,"dir":"Reference","previous_headings":"","what":"Query or set model label(s) — label","title":"Query or set model label(s) — label","text":"label() extracts model label(s) x. replacement functions label<- set_label() used set model label(s) x. n_model() returns number models included object x.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query or set model label(s) — label","text":"","code":"label(x, which)  label(x, which) <- value  set_label(x, value, which = seq_along(label(x)))  n_model(x)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query or set model label(s) — label","text":"x Object class “model”, “multimodel”, “cv” “performance”. Optional integer index  - allows querying setting subset model labels. Must length value. Default: models x. value Labels attributed models.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query or set model label(s) — label","text":"label() returns character vector. set_label() returns input object x modified labels. n_model() returns integer.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query or set model label(s) — label","text":"functions generic methods classes “model”, “multimodel”, “cv”, “performance”, “evaluation_log”. n_model() just returns length(label(x)) thus available object appropriate label() method.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/label.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query or set model label(s) — label","text":"","code":"xvars <- names(iris)[-1] forms <- lapply(xvars, reformulate, response = names(iris)[1]) model0 <- model(lm(Sepal.Length~1, iris), label = \"intercept_only\") mm <- c(model0, multimodel(model0, formula = forms)) n_model(mm) #> [1] 5  label(mm)   #> [1] \"intercept_only\"  \"intercept_only1\" \"intercept_only2\" \"intercept_only3\" #> [5] \"intercept_only4\" label(mm, 2:5) <- xvars label(mm) #> [1] \"intercept_only\" \"Sepal.Width\"    \"Petal.Length\"   \"Petal.Width\"    #> [5] \"Species\"        mm #> --- A “multimodel” object containing 5 models --- #>  #> ‘intercept_only’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘Sepal.Width’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ Sepal.Width, data = data) #>  #> ‘Petal.Length’: #>   model class:  lm #>   formula:      Sepal.Length ~ Petal.Length #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ Petal.Length, data = data) #>  #> and 2 models more, labelled: #>   ‘Petal.Width’, ‘Species’ #>  #>  #> Parameter table: #>                                    formula #> intercept_only <unknown>                   #> Sepal.Width    Sepal.Length ~ Sepal.Width  #> Petal.Length   Sepal.Length ~ Petal.Length #> ... 2 rows omitted (nrow=5)  set_label(mm, paste0(\"model_number_\", 1:5)) #> --- A “multimodel” object containing 5 models --- #>  #> ‘model_number_1’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘model_number_2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ Sepal.Width, data = data) #>  #> ‘model_number_3’: #>   model class:  lm #>   formula:      Sepal.Length ~ Petal.Length #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ Petal.Length, data = data) #>  #> and 2 models more, labelled: #>   ‘model_number_4’, ‘model_number_5’ #>  #>  #> Parameter table: #>                                    formula #> model_number_1 <unknown>                   #> model_number_2 Sepal.Length ~ Sepal.Width  #> model_number_3 Sepal.Length ~ Petal.Length #> ... 2 rows omitted (nrow=5)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/last_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and set the last cv object — last_cv","title":"Get and set the last cv object — last_cv","text":"last_cv() returns last generated “cv” object. allows recovering cross-validation (example) used method cv_performance.multimodel() directly, case “cv” saved. set_last_cv(value) causes value returned last_cv().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/last_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and set the last cv object — last_cv","text":"","code":"last_cv()  set_last_cv(value)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/last_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and set the last cv object — last_cv","text":"value object class “cv”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/last_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get and set the last cv object — last_cv","text":"last_cv() returns cv object,","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/last_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get and set the last cv object — last_cv","text":"","code":"data(mcycle, package = \"MASS\") m <- lm(accel ~ times, mcycle) cv_performance(m)  # m %>% cv %>% cv_performance #> --- Performance table --- #> Metric: rmse #>       train_rmse test_rmse time_cv #> model     45.959    45.811   0.012 last_cv()      # recovers unsaved output from cv() in previous call #> --- A “cv” object containing 1 validated model --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:   133 #>   Number of test sets:      10 #>   Size of test sets:       ~13 #>   Size of training sets:  ~120 #>  #> Model: #>  #> ‘model’: #>   model class:  lm #>   formula:      accel ~ times #>   metric:       rmse"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Create folds (cross-validation groups) — make_folds","title":"Create folds (cross-validation groups) — make_folds","text":"Obtains test sets (“folds”) cross-validation procedures cv(). user inputs specifications test sets; respective complements taken training sets.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create folds (cross-validation groups) — make_folds","text":"","code":"make_folds(n, nfold = getOption(\"cv_nfold\"), folds = NULL, strata = NULL)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create folds (cross-validation groups) — make_folds","text":"n integer (corresponding number observations data) data.frame. nfold Either integer vector length 1 2, numeric value 0 1 (see “Details”). folds list integer vectors (optional), predetermined group structure. folds given, arguments nfold strata ignored. strata vector list vectors: Strata cross validation. specified accordance n, groups defined folds output, ignoring n nfold.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create folds (cross-validation groups) — make_folds","text":"list integer vectors defining test sets, subset 1:n (1:nrow(n) n data.frame), class “folds”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create folds (cross-validation groups) — make_folds","text":"three ways define number groups group sizes nfold: positive integer value: Complete nfold-fold cross-validation; 1:n partitioned nfold groups (nearly) equal size random. Two positive integer values, second smaller first: Incomplete nfold-fold cross-validation; 1:n partitioned nfold[1] groups (nearly) equal size random, nfold[2] kept. numeric value 0 1: Hold-validation; one test group contain approximately n*nfold indices 1:n.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/make_folds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create folds (cross-validation groups) — make_folds","text":"","code":"make_folds(100, 10)       # Complete 10-fold CV #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  100 #>   Number of test sets:     10 #>   Size of test sets:       10 #>   Size of training sets:   90 make_folds(100, c(10, 4)) # Incomplete 10-fold CV #> Validation procedure: Incomplete k-fold Cross-Validation #>   Number of obs in data:  100 #>   Number of test sets:      4 #>   Size of test sets:       10 #>   Size of training sets:   90 make_folds(100, 0.3)      # Hold-out Validation with 30% test data #> Validation procedure: Simple Hold-out Validation #>   Number of obs in data:  100 #>   Number of test sets:      1 #>   Size of test set:        30 #>   Size of training set:    70 make_folds(100, c(3, 1))  # Almost the same as make_folds(100, 1/3) #> Validation procedure: Incomplete k-fold Cross-Validation #>   Number of obs in data:  100 #>   Number of test sets:      1 #>   Size of test set:        34 #>   Size of training set:    66 make_folds(iris)          # data as input #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  150 #>   Number of test sets:     10 #>   Size of test sets:       15 #>   Size of training sets:  135 make_folds(100, folds = list(1:10, 11:40, 41:100))  # Unequal group sizes #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:    100 #>   Number of test sets:        3 #>   Size of test sets:      10-60 #>   Size of training sets:  40-90"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics — metrics","title":"Metrics — metrics","text":"metric function arguments actual, predicted optionally w (weights) returning non-negative real value. following metrics taken package MetricsWeighted included modeltuner: Metrics continuous response: rmse, mae, medae mse. Metrics binary response: logLoss classification_error.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metrics — metrics","text":"","code":"rmse(actual, predicted, w = NULL, ...)  mae(actual, predicted, w = NULL, ...)  medae(actual, predicted, w = NULL, ...)  mse(actual, predicted, w = NULL, ...)  logLoss(actual, predicted, w = NULL, ..., eps = .Machine$double.neg.eps)  classification_error(actual, predicted, w = NULL, ..., cut_value = 0.5)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metrics — metrics","text":"actual Observed values. predicted Predicted values. w Optional case weights. ... Passed functions methods. eps Adjustment value logLoss. cut_value Cut value binary classification.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metrics — metrics","text":"functions return numeric value.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metrics — metrics","text":"two metrics binary response slightly different MetricsWeighted counterparts: logLoss(): Values 0 1 predicted replaced eps 1-eps, respectively, applying MetricsWeighted::logLoss(). prevents errors case prediction values exactly 0 1. classification_error(): predicted replaced ifelse(predicted>=cut_value, 1, 0) applying MetricsWeighted::classification_error().","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metrics — metrics","text":"","code":"data(mcycle, package = \"MASS\") mod <- lm(accel ~ times, mcycle) actual <- mcycle$accel pred <- predict(mod) rmse(actual, pred) #> [1] 45.97677 medae(actual, pred) #> [1] 35.47474  # performance() uses these metrics: performance(mod) #> --- Performance table --- #> Metric: rmse #>       train_rmse test_rmse #> model     45.977        NA performance(mod, metric = \"medae\") #> --- Performance table --- #> Metric: medae #>       train_medae test_medae #> model      35.475         NA performance(mod, metric = list(med_abs_err = medae)) #> --- Performance table --- #> Metric: med_abs_err #>       train_med_abs_err test_med_abs_err #> model            35.475               NA"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Special methods of model() — model-methods","title":"Special methods of model() — model-methods","text":"methods account special features predict methods popular model types: glm (package stats), glmrob (package robustbase), gam (package mgcv), ranger (package ranger), lmer, glmer (package lme4). execute model.default() adjusted default value predict_function.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Special methods of model() — model-methods","text":"","code":"# S3 method for glm model(   x,   ...,   predict_function = function(object, ...) predict(object, ..., type = \"response\"),   env = parent.frame() )  # S3 method for glmrob model(   x,   ...,   predict_function = function(object, ...) predict(object, ..., type = \"response\"),   env = parent.frame() )  # S3 method for gam model(   x,   ...,   predict_function = function(object, ...) predict(object, ..., type = \"response\"),   env = parent.frame() )  # S3 method for ranger model(   x,   ...,   predict_function = function(object, ...) predict(object, ...)$predictions,   env = parent.frame() )  # S3 method for merMod model(   x,   ...,   predict_function = function(object, ..., type = \"response\", allow.new.levels = TRUE)     predict(object, ..., allow.new.levels = allow.new.levels),   env = parent.frame() )  # S3 method for lmerMod model(   x,   ...,   predict_function = function(object, ..., type = \"response\", allow.new.levels = TRUE)     predict(object, ..., allow.new.levels = allow.new.levels),   env = parent.frame() )  # S3 method for glmerMod model(   x,   ...,   predict_function = function(object, ..., type = \"response\", allow.new.levels = TRUE)     predict(object, ..., allow.new.levels = allow.new.levels),   env = parent.frame() )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Special methods of model() — model-methods","text":"x fitted model. ... Passed model.default(). predict_function model.default. env environment. Used internal purposes.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Special methods of model() — model-methods","text":"methods model() return model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Special methods of model() — model-methods","text":"","code":"# Simulate data d <- simuldat()  # ranger fitted model (random forest): if (require(ranger)){   ranger_fitted <- ranger(Y ~ ., d)   # Methods predict.ranger() returns a list:   str(predict(ranger_fitted, data = d))      # Method model.ranger() makes sure that a \"model\" object returns   # a vector, as required:   ranger_model <- model(ranger_fitted)   predict(ranger_model) } #> List of 5 #>  $ predictions              : num [1:500] 2.92 6.26 -1.35 2.76 6.09 ... #>  $ num.trees                : num 500 #>  $ num.independent.variables: num 11 #>  $ num.samples              : int 500 #>  $ treetype                 : chr \"Regression\" #>  - attr(*, \"class\")= chr \"ranger.prediction\" #>           1           2           3           4           5           6  #>  2.91631098  6.26134305 -1.34780870  2.76100755  6.09257025  4.42211470  #>           7           8           9          10          11          12  #>  6.78545610  7.33146115  4.14053750  1.17097194 -2.84093221  3.39374205  #>          13          14          15          16          17          18  #>  0.33780223  4.58553928  5.58182871  8.12603752  3.72604377  4.56215423  #>          19          20          21          22          23          24  #>  4.96627884  6.30760876  4.94196994  4.38367527  7.10772055  3.97831499  #>          25          26          27          28          29          30  #>  5.86480146  8.44237233  2.98875420  3.21152098  5.87508518  4.50926405  #>          31          32          33          34          35          36  #>  4.65584514  3.68389230  2.12183612  3.41618665  2.11476106  2.57904001  #>          37          38          39          40          41          42  #>  3.29527777  3.66304204  2.69351695  3.08974745  5.69446596  5.73572447  #>          43          44          45          46          47          48  #>  4.73120763  7.92816020  2.56899105  4.41101371  3.04676948  5.08871687  #>          49          50          51          52          53          54  #>  1.78658629  6.30525996  1.28558710  4.49212530  5.31736587  6.27955658  #>          55          56          57          58          59          60  #>  5.13352741  3.86483362  2.12919455  5.41657007  7.52815584  5.69844757  #>          61          62          63          64          65          66  #>  4.43919367  5.01851187  6.44574883  1.91884013  1.76946875  3.26919777  #>          67          68          69          70          71          72  #>  6.51161773  4.77641486  8.46678002  6.60230456  6.24928789 -2.23269471  #>          73          74          75          76          77          78  #>  5.92310844  5.76268576  2.89829650  4.43484215  4.35922348  2.16435021  #>          79          80          81          82          83          84  #>  6.40823754  3.84899619  3.40405079  1.93731925  5.66865715  3.99114018  #>          85          86          87          88          89          90  #>  6.07044507  4.98774369  2.60238842  4.07240134  1.87292015  4.01765390  #>          91          92          93          94          95          96  #>  3.50254838  4.82708541  2.80101398  6.38136677  2.04378731  6.11222030  #>          97          98          99         100         101         102  #>  4.34613332 -1.69144285  2.83133485  7.54631918  1.83290046  1.27700285  #>         103         104         105         106         107         108  #>  7.00848829  4.29107640  5.54136269  4.69688307  3.02178322  8.98761683  #>         109         110         111         112         113         114  #>  2.06902910  1.37973583  4.62967358  2.30298310  7.17993543  4.23408099  #>         115         116         117         118         119         120  #>  4.94599346  2.86228994 -0.44324822  6.41408755  5.09070133  5.40694922  #>         121         122         123         124         125         126  #>  2.96586088  3.14094370  8.26596186 -0.20062942  5.54577576  0.96037158  #>         127         128         129         130         131         132  #>  5.52839672  6.72168986  3.23478807  3.88216140  1.52751880  3.45972785  #>         133         134         135         136         137         138  #>  6.59809893  3.33458081  8.29455687  4.49673712  3.87842837  6.83636309  #>         139         140         141         142         143         144  #>  1.08801775 -1.08917412  5.93583786  5.94901419  3.77277060  1.99488492  #>         145         146         147         148         149         150  #>  3.61117486  1.47451818  4.95003547  4.20954477  5.31712485  0.42640919  #>         151         152         153         154         155         156  #>  6.23509448  3.32537831  4.31329505  3.63117266 11.44642826  0.51997242  #>         157         158         159         160         161         162  #>  4.81176455  7.72329750  4.06251850  5.97439404  0.50064504  0.40197567  #>         163         164         165         166         167         168  #>  3.04359664 -0.43138400  1.78486781  7.66478534  0.22444857  1.24971914  #>         169         170         171         172         173         174  #>  1.08783464  4.98442039  6.12099881  2.64717103  5.86062651  3.68045282  #>         175         176         177         178         179         180  #>  1.42412017  7.26484374  4.03144279  4.62841225  5.32358453  1.12251471  #>         181         182         183         184         185         186  #>  6.71904749  2.11701290  2.37191763  5.99872002  3.24736589  5.13766190  #>         187         188         189         190         191         192  #>  3.14707656  4.04452210  5.53162629  3.00628350  3.49735253  0.75033643  #>         193         194         195         196         197         198  #>  6.60747359  6.09751195  2.76793444  4.75113178  0.44164274  5.59499761  #>         199         200         201         202         203         204  #>  2.34349542  3.78747390  4.54312663  4.54971143  1.03481154  7.22276430  #>         205         206         207         208         209         210  #>  6.58579971  5.12623672  2.83270088  4.18302873  2.30582237  4.11913245  #>         211         212         213         214         215         216  #>  7.39957406  8.96719837  4.59464952  1.58300805  1.64558215  2.86836308  #>         217         218         219         220         221         222  #>  4.23779549  4.71156141  1.95325141  5.47944108  2.10302701  6.67901401  #>         223         224         225         226         227         228  #>  1.93735897  3.32752710  0.70859749  7.39005732  2.56560830  6.02207548  #>         229         230         231         232         233         234  #>  9.39154723  6.86663707  4.41232455  8.58459585  3.92256379  6.64115797  #>         235         236         237         238         239         240  #>  6.32744418  2.68269303  5.00982899  2.70813360  1.64662670  5.57640601  #>         241         242         243         244         245         246  #>  4.13061151  7.37637345  0.14841804  4.59352065  2.20526565  4.34205936  #>         247         248         249         250         251         252  #>  2.21627003  5.60468915  2.95570230  5.43273092  5.06193653  0.58308015  #>         253         254         255         256         257         258  #>  5.35506452  3.50584520  6.99735693  6.25140785  5.53627706  3.48093558  #>         259         260         261         262         263         264  #>  3.89512774  3.37914568  2.19157366  3.77809251  2.47163367  8.70604724  #>         265         266         267         268         269         270  #>  3.97418655  4.31452349  6.39983471  5.26516658  6.20690055  4.11630281  #>         271         272         273         274         275         276  #>  6.23398524  3.58559906  4.50007914  7.61936407  4.43939341  3.15279348  #>         277         278         279         280         281         282  #>  4.20865971 -1.03206011  9.08279909  3.23320288  6.56471246  5.47482481  #>         283         284         285         286         287         288  #>  4.72032775  1.73601771  5.54436211  4.55897796  3.07213435 -0.21475534  #>         289         290         291         292         293         294  #>  6.20498485  5.65724415  4.27453569  7.33228653  1.13409235  2.31536166  #>         295         296         297         298         299         300  #>  4.63057719  3.70253915  8.45966174  1.23745477  4.90110013  0.61415672  #>         301         302         303         304         305         306  #>  2.68360540  3.28334324  0.75979428  3.67773141  7.27572970  7.22967797  #>         307         308         309         310         311         312  #>  4.54270622  6.04970120  4.81150978  8.68081333  7.34166850  4.04374686  #>         313         314         315         316         317         318  #>  4.07353908  3.67318554  2.01724514  5.72654292  4.02426731  5.84777468  #>         319         320         321         322         323         324  #>  3.61122027  5.41094020  7.94185502  5.06218191  8.16730182  4.87721427  #>         325         326         327         328         329         330  #>  2.90691496  5.90000920  6.21134980  6.11094641  4.25882061  4.63535827  #>         331         332         333         334         335         336  #>  3.80220969  3.40934887  1.01361685  5.40544932  2.91173868  2.25656858  #>         337         338         339         340         341         342  #>  6.02398431  2.65980381  2.59007977  6.42324254  6.68840896  3.74938730  #>         343         344         345         346         347         348  #>  3.26284761  2.12687481  1.56788377  6.14683082  4.22269089  1.02570759  #>         349         350         351         352         353         354  #>  5.38701645  3.67168964  6.71666944  6.66425253  4.37137560  3.34453796  #>         355         356         357         358         359         360  #>  5.25398081  1.26070193  7.27646535  4.49036848  1.51371191  4.23857828  #>         361         362         363         364         365         366  #> -0.69665834  1.98604236  2.42548387  5.68727523  2.82628530  6.31981781  #>         367         368         369         370         371         372  #>  1.69837590  6.81035611  7.57950732  3.75879235  5.68589178  2.03280450  #>         373         374         375         376         377         378  #>  3.48847810  7.09617989  3.31343059  8.09563852  2.09313166  5.06863326  #>         379         380         381         382         383         384  #>  5.93289137  2.70876708  5.92240837 -0.25745600  4.15732373  1.34024476  #>         385         386         387         388         389         390  #>  1.29422776  0.04056416  4.99953383  5.51428665  3.18066711  4.17121504  #>         391         392         393         394         395         396  #>  0.72469716  6.18808701  5.03562990  2.31041355  5.22205671  7.65438539  #>         397         398         399         400         401         402  #>  1.81286088 -0.22198274  4.78915715  8.00895631  2.66218748  0.91373529  #>         403         404         405         406         407         408  #>  2.17260899  2.74548157  6.65124691  3.72753964  1.37979317  5.62181869  #>         409         410         411         412         413         414  #>  5.42688868  2.50120895  1.37018777  1.71975225  7.49634109  2.53320041  #>         415         416         417         418         419         420  #>  4.09990751  5.83460296  3.72070428  6.59719572  2.39746710  5.51498683  #>         421         422         423         424         425         426  #>  4.30574046  2.22250821  5.03907441  5.29197922  5.37888705  4.41969614  #>         427         428         429         430         431         432  #>  1.57583400  7.62275972  3.67160690  5.70304311  3.93307354  6.65054615  #>         433         434         435         436         437         438  #>  3.84039255  3.15814219  3.15302074  3.24332759  2.82569270  5.92007441  #>         439         440         441         442         443         444  #>  3.75862471  3.38365969  0.34502271  2.68942939  0.01067636  3.04535935  #>         445         446         447         448         449         450  #>  3.13720785  3.37998571  4.80023514  2.15332031  0.79666048  5.66739420  #>         451         452         453         454         455         456  #>  4.26253637  4.45426566  3.91968503  7.31406769  3.52516962  3.54675270  #>         457         458         459         460         461         462  #>  6.49504534  6.06883986  6.00230067  5.18343276  2.46664108  1.43101271  #>         463         464         465         466         467         468  #>  2.96636915  2.32116336  3.15934747  3.31547923  2.10178055 -0.76393641  #>         469         470         471         472         473         474  #>  3.48492600  4.91009052  6.44697292  4.48537400  0.24221103  3.85614813  #>         475         476         477         478         479         480  #>  4.82795795  6.20075939  4.12066100  1.10844694  5.37623813  4.23414625  #>         481         482         483         484         485         486  #>  4.18021021  9.39753490  3.42141044  7.34665714  5.52553029  7.79488010  #>         487         488         489         490         491         492  #>  3.96068717  4.67981222  4.99659705  3.40434779  4.05707817  3.43648895  #>         493         494         495         496         497         498  #>  2.65624452  2.45385811  6.55673350  3.58396092  6.30268046  3.43461812  #>         499         500  #>  3.04277400  5.95528571"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a model object — model","title":"Create a model object — model","text":"model() takes fitted statistical model x, e.g. lm, returns output class “model”, R object containing model's structure, data optionally fitting weights. “model” object necessarily contain model fit, information needed refit model, possibly making changes generating call. model() works fitted models created model fitting function formula data argument. model() applicable many popular model classes lm, lmrob, rpart, lmer many .","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a model object — model","text":"","code":"model(x, ...)  # S3 method for default model(   x,   label = \"model\",   class = attr(x, \"class\"),   add_fit = TRUE,   response_type = NULL,   predict_function = predict,   env = parent.frame(),   ... )  # S3 method for call model(x, label = \"model\", class, add_fit = FALSE, env = parent.frame(), ...)  # S3 method for character model(x, ..., label = \"model\", class, add_fit = FALSE, env = parent.frame())  # S3 method for model model(x, ...)  # S3 method for model print(   x,   what = c(\"label\", \"class\", \"formula\", \"data\", \"response_type\", \"weights\", \"call\",     \"fit\"),   abbreviate = TRUE,   width = getOption(\"width\"),   indent = \"\",   ... )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a model object — model","text":"x fitted model meeting formal requirements described “Details” section. Alternatively, unevaluated call model fitting function; case, model class must provided argument class (see examples). ... Arguments passed methods. used default method. label Character string: label attributed model. class Class model object. required x fitted model. add_fit Logical: Save fitted object component result? response_type Character string, \"continuous\" \"binary\". Default: \"binary\" response values (converted numeric) 0 1, else \"continuous\". predict_function Predict function, often predict - see “Details”. env environment. Used internal purposes. print: Either character vector subset {\"label\", \"formula\", \"data\", \"call\", \"response_type\", \"response\", \"fit\", \"predict_function\", \"saved_objects\", \"class\", \"weights\"} TRUE, meaning elements. abbreviate Logical. TRUE (default), long formulas calls printed abbreviated mode, usually fit 4 fewer output lines; otherwise printed entirely, matter long . width Integer: Width printed output. indent Used internally .","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a model object — model","text":"model() returns list class attribute c(paste0(\"model_\", class), \"model\") following elements: label, character string used identifier model; formula, formula defining model's structure; data, data.frame; call, call fitting model; response_type, character string, \"continuous\" \"binary\"; response, character string containing variable name expression defining response; fit (optional), fitted object class class; predict_function, real valued function two arguments: model data structure data; saved_objects, list objects appearing call part data; class, class fitted model; weights, optional vector fitting weights.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a model object — model","text":"Model classes suited model() must meet following requirements: model fitting function must formal arguments formula data, accepting formula data.frame, respectively. case binary response, response must numeric values 0 1. getCall(x) x model class question must return call generating x. usually predict method class x returning vector length nrow(data). Alternatively, real valued function two arguments, model data.frame, can specified predict_function. weighted fitting required, model fitting function must argument weights. case, appropriate weights method class class returning either NULL vector non-negative values length nrow(data). However, model class supporting weighted fitting work long specify weights model(). model generating call saved output object partially generic mode. Specifically, arguments data weights (present) given generic values data=data weights=weights, respectively. convenient cross-validation cv(), model generating call repeatedly adapted executed internally, using data weights stored “model” object. See also argument use_original_args fit(), related reformulation model generating call.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create a model object — model","text":"current settings options na.action contrasts (options) potentially change behavior model fitting function, changing options analysis involving type model must avoided.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Create a model object — model","text":"model.call() model.character() allow creating “model” object  without fit corresponding model. See examples. Specifying  class mandatory , can queried input x. method model.model() returns input x unchanged.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a model object — model","text":"","code":"# lm fitted <- lm(Sepal.Width ~ ., iris) mod1 <- model(fitted, label = \"LinearModel\") mod1 #> --- A “model” object --- #>   label:          LinearModel #>   model class:    lm #>   formula:        Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   call:           lm(formula = Sepal.Width ~ ., data = data) #>   fit:            Object of class ‘lm’  # weighted lm model(lm(Sepal.Width ~ ., iris, weights = runif(nrow(iris))),        label = \"weightedLm\") #> --- A “model” object --- #>   label:          weightedLm #>   model class:    lm #>   formula:        Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   weights:        numeric [150],  #>                   input as: ‘weights = runif(nrow(iris))’ #>   call:           lm(formula = Sepal.Width ~ ., data = data, weights = weights) #>   fit:            Object of class ‘lm’  # print.model print(mod1, what = TRUE) #> --- A “model” object --- #>   label:             LinearModel #>   model class:       lm #>   formula:           Sepal.Width ~ Sepal.Length + Petal.Length +  #>                          Petal.Width + Species #>   data:              data.frame [150 x 5],  #>                      input as: ‘data = iris’ #>   response_type:     continuous #>   response:          Sepal.Width #>   call:              lm(formula = Sepal.Width ~ ., data = data) #>   predict_function:  function (object, ...)   #>   fit:               Object of class ‘lm’ print(mod1, what = c(\"label\", \"call\", \"class\")) #> --- A “model” object --- #>   label:        LinearModel #>   model class:  lm #>   call:         lm(formula = Sepal.Width ~ ., data = data) print(mod1, what = NULL) #> --- A “model” object ---  # model() applied to an unevaluated call: lm_call <- quote(lm(Sepal.Width~., iris)) model(lm_call, class = \"lm\") #> --- A “model” object --- #>   label:          model #>   model class:    lm #>   formula:        Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   call:           lm(formula = Sepal.Width ~ ., data = data) # Same using the method model.character(): model(\"lm\", Sepal.Width~., iris, class = \"lm\") #> --- A “model” object --- #>   label:          model #>   model class:    lm #>   formula:        Sepal.Width ~ Sepal.Length + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   call:           lm(formula = Sepal.Width ~ ., data = data)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/models.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine several fitted models in a multimodel — models","title":"Combine several fitted models in a multimodel — models","text":"function models() general version c.model(). latter expects arguments inheriting classes “model” “multimodel” “...” arguments, former also accepts fitted models (e.g. “lm”).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine several fitted models in a multimodel — models","text":"","code":"models(..., .env = parent.frame())"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine several fitted models in a multimodel — models","text":"... Passed c.model(), application model() fitted models list “...” arguments. .env internal use.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine several fitted models in a multimodel — models","text":"multimodel.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine several fitted models in a multimodel — models","text":"","code":"mm <- models(   lm = lm(Sepal.Length ~ ., iris),   rpart = model(rpart::rpart(Sepal.Length ~ ., iris)),   xgboost = tune(fm_xgb(Sepal.Length ~ ., iris)) ) #> set_pref_iter(), model ‘model’, modifications made in call: #>   pref_iter=14, nrounds=14, early_stopping_rounds=NULL mm #> --- A “multimodel” object containing 3 models --- #>  #> ‘lm’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘rpart’: #>   model class:  rpart #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         rpart::rpart(formula = Sepal.Length ~ ., data = data) #>  #> ‘xgboost’: #>   model class:  fm_xgb #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species - 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         fm_xgb(formula = Sepal.Length ~ ., data = data,  #>                     nrounds = 14L, early_stopping_rounds = NULL,  #>                     pref_iter = 14L) cv_performance(mm) #> --- Performance table --- #> Metric: rmse #>         train_rmse test_rmse iteration time_cv #> lm         0.29963   0.31478        NA   0.023 #> rpart      0.31432   0.39094        NA   0.040 #> xgboost    0.18173   0.32602        14   0.078"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal functions in package modeltuner — add_cv_info","title":"Internal functions in package modeltuner — add_cv_info","text":"functions mainly internal purposes normally called directly user.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal functions in package modeltuner — add_cv_info","text":"","code":"add_cv_info(x, cvobj, ...)  prnt_cv_info(x, ...)  eval_crit(crit, x, ...)  has_cv_fits(x)  oos_indices(folds)  cv_simple(x, folds, metric, iter, keep_fits, verbose, ...)  evlog_int(classObj, x, metric, eval_weights, na.rm, ...)  extract(x, i)  cb_xgb_iteration(period = 1, prefix = \"\", keep_final_msg = FALSE)  get_xy(object, data, weights = NULL, ...)  get_xy2(data, weights = NULL, ...)  prnt_compact(x, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal functions in package modeltuner — add_cv_info","text":"add_cv_info() generic auxiliary function adding info cv model. Apply model, returns model. eval_crit() generic auxiliary function evaluating preference criteria given ifms. has_cv_fits() generic auxiliary function discerns whether cv contains cross-validation fits . oos_indices() identifies --sample indices predictions matrix. cv_simple() generic function performing cross-validation one model. evlog_int() generic function performing internal calculations evaluation_log(). extract() generic extraction function used internally. cb_xgb_iteration() callback function used xgboost model cross-validated verbose=TRUE. reduced version cb.print.evaluation get_xy() generic taking formula data, returns list x matrix, y vector terms object. Designed internal use formula-interface wrappers. get_xy2() generic dispatching second argument, data. prnt_compact() prnt_cv_info() generic utility functions used print methods.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modeltuner package overview — modeltuner-package","title":"modeltuner package overview — modeltuner-package","text":"modeltuner package designed evaluation predictive performance statistical models hyperparameter tuning based cross-validation. current version package supports models continuous binary (0/1) response. help topic, main conceptual elements package introduced explained. package also offers particularly attractive tools handling called iteratively fitted models (IFM) . model, fitting process returns just one single model (model parameterization), rather range models (model parameterizations) increasing structural complexity. Prominent examples (currently instances implemented package) gradient boosting (implemented package xgboost) Lasso regression elastic nets (available package glmnet). Refer dedicated help topic (ifm) vignette (vignette(\"ifm\")) information.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"overview-and-workflow","dir":"Reference","previous_headings":"","what":"Overview and workflow","title":"modeltuner package overview — modeltuner-package","text":"package's key concept class “model”. fitted model called myfm, say,  (e.g., linear model), convert “model” object simply typing mymodel<-model(myfm), gives access world modeltuner. model() designed model classes based formula/data interface. analysis typically comprise following successive steps: First, set base model, several. done using function model(). output, object class “model”, includes formula, data, call model fitting function, optionally fitting weights, components. contains information needed repeatedly refit model slightly modified conditions, done cross-validation. necessarily contain actual fit model. Properly distinguishing fitted models (e.g., “lm”) objects class “model” crucial good understanding functions modeltuner package work. many applications, just considering single model, want study compare predictive performance several candidate models, /want find optimal values certain hyperparameters. order , combine several models model parameterizations multimodel. “multimodel” essentially generalization class “model” one model. Next, run cross-validation procedure, applying function cv() model multimodel, thus obtaining object class “cv”. time-consuming part analysis. key function evaluate display contents “cv” object cv_performance(), computes training test errors model(s) investigation. extract best-performing model cv-object, may use tune(). Alternatively, might prefer pick favorite model manually. , use extract_model(). Finally may use fit() convert selected model (object class “model”) back fitted model, e.g. “lm” object, thereby leaving modeltuner world. steps required every analysis, steps may executed repeatedly achieving satisfaction. modeltuner comes number utility functions helpful inspection basic manipulations object classes “model”, “multimodel”, “cv” : label(), n_model(), extract_model(), subset(), sort_models(). S3 generic functions specific methods classes. complement , package wrappers number model fitting functions packages, notably glmnet() xgb.train(), based formula/data interface, resulting classes can easily handled modeltuner framework. See help topics ?fm_glmnet, ?fm_xgb, ?fm_knn, ?fm_smooth_spline, ?fm_const.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"models-and-multimodels","dir":"Reference","previous_headings":"","what":"Models and multimodels","title":"modeltuner package overview — modeltuner-package","text":"model(x, ...) S3 generic function. default method converts fitted model, “lm”, object class “model”. original fitted model x must meet certain formal requirements, e.g. fitting function must formal arguments formula data, must call component. exact requirements described detail ?model, well structure “model” object. multimodel combines several models one object. two ways create multimodel. Either combine different “model” objects call c(...), c(model1, model2, model3), run (generic) function multimodel(x, ...), x “model” fitted model “...” specify alternative values one several (hyper-)parameters model-fitting function. Models combined multimodel must identical responses. See ?multimodel information examples.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"folds","dir":"Reference","previous_headings":"","what":"Folds","title":"modeltuner package overview — modeltuner-package","text":"set “folds” part every model validation procedure executed cv(). defines grouping pattern procedure. Technically, object class “folds”, created function make_folds(), list integer vectors special attributes. vectors defines test set observations model data. validation procedures, complement test set used corresponding training set. Three (cross-)validation patterns implemented: Complete n-fold cross-validation, incomplete n-fold cross-validation, simple hold-validation. See ?make_folds details.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"cv-and-cv-performance-","dir":"Reference","previous_headings":"","what":"cv() and cv_performance()","title":"modeltuner package overview — modeltuner-package","text":"function cv() executes validation procedure. two main inputs object class “model” “multimodel” set folds -- result object class “cv”. default, model fits cross-validation saved part output, predictions saved used evaluation. main evaluation function “cv” object cv_performance(). Among parameters metric (formal argument metric) evaluation weights (eval_weights).: Metrics: default metric rmse() continuous response logLoss() binary response. modeltuner, use metrics package MetricsWeighted. See section “Metrics” ?metrics. Evaluation weights: distinguish fitting weights --action cross-validation executed-- evaluation weights, parameter evaluation cross-validation. See section “Evaluation weights” later help topic. executing cv(), default metric eval_weights chose automatically saved separately model. thus necessarily models multimodel. However, execution cv_performance() uses common metric common eval_weights. help topic ?cv details, particular structure object class “cv”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"evaluation-and-metrics","dir":"Reference","previous_headings":"","what":"Evaluation and Metrics","title":"modeltuner package overview — modeltuner-package","text":"cv_performance() reports training (-sample) test (--sample) predictive performance models included “cv” object evaluating metric. returns performance table, object class “performance”, data.frame additional attributes convenient print() method. Roughly speaking, first accuracy (training test) predictions evaluated fold separately results averaged. help topic ?cv_performance details. set evaluation metrics package MetricsWeighted used package: Metrics continuous response: rmse, mse, mae, medae; Modified metrics binary response: logLoss, classification_error. two metrics binary response slightly modified order make convenient use context modeltuner. functions formal arguments actual, predicted , optionally, weights. Alternative metrics may used must formal arguments, . can use metric weights argument, evaluation work eval_weights NULL. See ?metrics details metrics.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"evaluation-weights","dir":"Reference","previous_headings":"","what":"Evaluation weights","title":"modeltuner package overview — modeltuner-package","text":"default, model's fitting weights chosen default eval_weights. “model” objects included “cv” object can different fitting evaluation weights. case, cv_performance() use eval_weights=NULL default. default can overridden argument eval_weights.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner-package.html","id":"tune-and-fit","dir":"Reference","previous_headings":"","what":"Tune and fit","title":"modeltuner package overview — modeltuner-package","text":"tune() selects best-performing model among included “cv” object, fit() converts “model” back fitted model, using complete model data fit. See ?tune ?fit.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_cheatsheet.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","title":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","text":"modeltuner_cheatsheet() opens pdf file (“cheatsheet”) summarizing important concepts functions modeltuner package.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_cheatsheet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","text":"","code":"modeltuner_cheatsheet(open = TRUE)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_cheatsheet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","text":"open Logical: TRUE, cheatsheet pdf format opened (via shell command); FALSE, path pdf file returned character string.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_cheatsheet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","text":"Path cheatsheet pdf format","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_cheatsheet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open a modeltuner cheatsheet — modeltuner_cheatsheet","text":"","code":"if (FALSE) modeltuner_cheatsheet()  # Display path to pdf: modeltuner_cheatsheet(open = FALSE) #> [1] \"\""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_options.html","id":null,"dir":"Reference","previous_headings":"","what":"List all options defined in package “modeltuner” — modeltuner_options","title":"List all options defined in package “modeltuner” — modeltuner_options","text":"modeltuner_options() displays current values options set package. options define default values certain function parameters.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all options defined in package “modeltuner” — modeltuner_options","text":"","code":"modeltuner_options()"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all options defined in package “modeltuner” — modeltuner_options","text":"Returns list option settings.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List all options defined in package “modeltuner” — modeltuner_options","text":"cv_nfold (value package startup: =10): Default value argument nfold cv(), tune() stepwise functions. cv_verbose  (=interactive() startup): Default value argument verbose cv(), cv_show_se (=FALSE startup): Default value argument se print.performance() print.evaluation_log() default errorbars plot.evaluation_log(), cv_iter (=crit_min() startup): Default value argument iter cv() applied models class “fm_xgb” “fm_glmnet”, expand_max_model  (=30 startup): Default value argument max_n_model multimodel.model() tune.model(), print_max_model (=3 startup): Default value n print.multimodel(), print.cv() print.evaluation_log(), print_max_row (=30 startup): Default value n print.performance() print.extract_pref_iter(), print_rows_evaluation_log (=6 startup): Default value n_row print.evaluation_log().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/modeltuner_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all options defined in package “modeltuner” — modeltuner_options","text":"","code":"modeltuner_options() #> $cv_nfold #> [1] 10 #>  #> $cv_verbose #> [1] FALSE #>  #> $cv_show_se #> [1] FALSE #>  #> $cv_iter #> Preference criterion for an iteratively fitted model: #>   criterion:     crit_min() #>   label suffix:  “min” #>   Selects the iteration with minimal test error. #>  #> $expand_max_model #> [1] 30 #>  #> $print_max_model #> [1] 3 #>  #> $print_max_row #> [1] 30 #>  #> $print_rows_evaluation_log #> [1] 6 #>"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a multimodel object — multimodel","title":"Create a multimodel object — multimodel","text":"multimodel combines several models identical response one object. two ways create multimodel: multimodel(x, ...) takes object class “model” fitted model input x generates number variations model, one several parameters varying according specification “...”. c.model(...) c.multimodel(...) take number models multimodels “...” arguments combine object class “multimodel”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a multimodel object — multimodel","text":"","code":"multimodel(x, ...)  # S3 method for model multimodel(   x,   ...,   prefix = label(x),   expand = TRUE,   max_n_model = getOption(\"expand_max_model\"),   param = TRUE,   simplify = TRUE )  # S3 method for default multimodel(   x,   ...,   prefix = \"model\",   expand = TRUE,   param = TRUE,   simplify = TRUE )  # S3 method for multimodel multimodel(x, ...)  # S3 method for multimodel print(   x,   what = c(\"class\", \"formula\", \"data\", \"weights\", \"call\", \"cv_info\"),   abbreviate = TRUE,   n = getOption(\"print_max_model\"),   param = TRUE,   width = getOption(\"width\"),   ... )  # S3 method for model c(..., param = TRUE, simplify = TRUE)  # S3 method for multimodel c(..., param = TRUE, simplify = TRUE)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a multimodel object — multimodel","text":"x object class “model” fitted model. ... multimodel(): named parameters expanded; c.(multi)model: one several arguments class “model” “multimodel”. prefix Prefix use model label. expand Logical: Expand “...” arguments (default) join element-wise? expand=TRUE, vectors “...” expanded, number models equal product lengths “...” arguments; otherwise, “...” arguments must equal lengths, number models equal common length. max_n_model Maximal number models included. number specified models greater max_n_model, subset selected random. param Logical: Keep print parameter table? simplify Logical: Simplify multimodel comprising one model model? elements multimodel printed? See print.model. abbreviate Logical. TRUE (default), long formulas calls printed abbreviated mode, usually fit 4 fewer output lines; otherwise printed entirely, matter long . n Integer: Model details printed first n models. width Integer: Width printed output.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a multimodel object — multimodel","text":"multimodel() c.(multi)model() return object class “multimodel”, list following elements: models: list model objects. param: table parameter values resulting multimodel(). included varying parameters param = TRUE","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a multimodel object — multimodel","text":"multimodel()  (S3-)generic function. core method multimodel.model(), methods essentially wrappers core method described section “Methods” . vectors “...” expanded joined, according argument expand. Extraction values single calls done “[[” rather “[”. multimodel() executes update.model() repeatedly, helper functions absent(), unchanged() null() can used call multimodel() exactly within update.model(). formula one arguments “...” formula dot, used update original model formula. Enclose formula () order replace original formula instead. See example update.model. output multimodel(...) default includes parameter table element param, containing values parameters specified “...”. data.frame additional class “param_table”. c.(multi)model: call c(...) can include “model” “multimodel” objects (fitted models) “...”. Using models() instead c-methods flexible also accepts fitted models. “model”s specified named arguments call argument name taken label. Argument names multimodels ignored -- labels already present multimodel used instead. Duplicate labels output adjusted using make.unique().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Create a multimodel object — multimodel","text":"multimodel.model() described “Details” section. default method expects fitted model x executes x %>% model %>% multimodel(...). multimodel.multimodel() returns input x unchanged.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/multimodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a multimodel object — multimodel","text":"","code":"m1 <- model(lm(Sepal.Length ~ 1 , iris), label = \"intercept\") m2 <- model(lm(Sepal.Length ~ . , iris), label = \"linear\") m3 <- model(lm(Sepal.Length ~ .^2 , iris), label = \"order2\")  # without Species on rhs  # Combine models with c(...) mm1 <- c(m1, m2, m3)  mm1 #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘order2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data)  # Specify elements to print: print(mm1, what = c(\"class\", \"data\")) #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept’: #>   model class:  lm #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>  #> ‘linear’: #>   model class:  lm #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>  #> ‘order2’: #>   model class:  lm #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ print(mm1, what = TRUE) #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept’: #>   label:             intercept #>   model class:       lm #>   formula:           Sepal.Length ~ 1 #>   data:              data.frame [150 x 5],  #>                      input as: ‘data = iris’ #>   response_type:     continuous #>   response:          Sepal.Length #>   call:              lm(formula = Sepal.Length ~ 1, data = data) #>   predict_function:  function (object, ...)   #>   fit:               Object of class ‘lm’ #>  #> ‘linear’: #>   label:             linear #>   model class:       lm #>   formula:           Sepal.Length ~ Sepal.Width + Petal.Length +  #>                          Petal.Width + Species #>   data:              data.frame [150 x 5],  #>                      input as: ‘data = iris’ #>   response_type:     continuous #>   response:          Sepal.Length #>   call:              lm(formula = Sepal.Length ~ ., data = data) #>   predict_function:  function (object, ...)   #>   fit:               Object of class ‘lm’ #>  #> ‘order2’: #>   label:             order2 #>   model class:       lm #>   formula:           Sepal.Length ~ Sepal.Width + Petal.Length +  #>                          Petal.Width + Species + Sepal.Width:Petal.Length +  #>                          Sepal.Width:Petal.Width + Sepal.Width:Species +  #>                          ... [formula cut off - 10 terms on rhs] #>   data:              data.frame [150 x 5],  #>                      input as: ‘data = iris’ #>   response_type:     continuous #>   response:          Sepal.Length #>   call:              lm(formula = Sepal.Length ~ .^2, data = data) #>   predict_function:  function (object, ...)   #>   fit:               Object of class ‘lm’  # Expand a model with multimodel(): random forests with different max.depth: if (require(ranger)){   mod_ranger <- model(ranger(Sepal.Length ~ ., iris), label = \"ranger\")   multimodel(mod_ranger, max.depth = 1:10) } #> --- A “multimodel” object containing 10 models --- #>  #> ‘ranger1’: #>   model class:  ranger #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         ranger(formula = Sepal.Length ~ ., data = data,  #>                     max.depth = 1L) #>  #> ‘ranger2’: #>   model class:  ranger #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         ranger(formula = Sepal.Length ~ ., data = data,  #>                     max.depth = 2L) #>  #> ‘ranger3’: #>   model class:  ranger #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         ranger(formula = Sepal.Length ~ ., data = data,  #>                     max.depth = 3L) #>  #> and 7 models more, labelled: #>   ‘ranger4’, ‘ranger5’, ‘ranger6’, ‘ranger7’, ‘ranger8’,  #>   ‘ranger9’, ‘ranger10’ #>  #>  #> Parameter table: #>          max.depth #> ranger1          1 #> ranger2          2 #> ranger3          3 #> ... 7 rows omitted (nrow=10)  #' # Expand a model with multimodel(...) # Joining models with three formulas may not give the expected result: mm2 <- multimodel(m1, formula = list(Sepal.Length ~ 1, Sepal.Length ~ ., Sepal.Length ~ .^2)) mm2  #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept1’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘intercept2’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘intercept3’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> Parameter table: #>                       formula #> intercept1 Sepal.Length ~ 1   #> intercept2 Sepal.Length ~ .   #> intercept3 Sepal.Length ~ .^2 # The reason is that the formulas in the call above are used to *update* the existing one.  # To *replace* the formula, use `I()` as in the call below: mm3 <- multimodel(m1, formula = list(Sepal.Length ~ 1, I(Sepal.Length ~ .), I(Sepal.Length ~ .^2))) mm3 #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept1’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘intercept2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘intercept3’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) #>  #> Parameter table: #>                       formula #> intercept1 Sepal.Length ~ 1   #> intercept2 Sepal.Length ~ .   #> intercept3 Sepal.Length ~ .^2 # Also note the difference in the printed outputs of mm1 and mm2: # The parameter table only contains parameters that were passed as '...' in multimodel().  # Three ways to attribute labels to models: # 1) Use named arguments in c.model(): c(constant = m1, linear = m2, order2 = m3)  #> --- A “multimodel” object containing 3 models --- #>  #> ‘constant’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘order2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) # 2) replacement function label<- mm1_lbls <- mm1 label(mm1_lbls) <- c(\"m1\", \"m2\", \"m3\") mm1_lbls #> --- A “multimodel” object containing 3 models --- #>  #> ‘m1’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘m2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘m3’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) # 3) set_labels() set_label(mm1, c(\"m1\", \"m2\", \"m3\")) #> --- A “multimodel” object containing 3 models --- #>  #> ‘m1’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘m2’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘m3’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data)  # Combine mm1 and mm3: print(c(mm1, mm3), what = \"formula\", n = 6) #> --- A “multimodel” object containing 6 models --- #>  #> ‘intercept’: #>   formula:  Sepal.Length ~ 1 #>  #> ‘linear’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species #>  #> ‘order2’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                 Sepal.Width:Species + Petal.Length:Petal.Width +  #>                 Petal.Length:Species + Petal.Width:Species #>  #> ‘intercept1’: #>   formula:  Sepal.Length ~ 1 #>  #> ‘intercept2’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species #>  #> ‘intercept3’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                 Sepal.Width:Species + Petal.Length:Petal.Width +  #>                 Petal.Length:Species + Petal.Width:Species #>  #> Parameter table: #>                       formula #> intercept  <unknown>          #> linear     <unknown>          #> order2     <unknown>          #> intercept1 Sepal.Length ~ 1   #> intercept2 Sepal.Length ~ .   #> intercept3 Sepal.Length ~ .^2  # Unweighted and weighted model: w <- runif(150) mm3 <- multimodel(m1, weights = list(absent(), w)) label(mm3) <- c(\"unweighted\", \"weighted\") mm3 #> --- A “multimodel” object containing 2 models --- #>  #> ‘unweighted’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) #>  #> ‘weighted’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   weights:      numeric [150], input as: ‘weights = w’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data, weights = weights) #>  #> Parameter table: #>               weights #> unweighted   <absent> #> weighted   <num>[150]"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/null_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"“Null formula” of a model — null_formula","title":"“Null formula” of a model — null_formula","text":"Returns formula intercept-model (. ~ 1) original formula x contains intercept constant zero-model formula (. ~ 0) otherwise.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/null_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"“Null formula” of a model — null_formula","text":"","code":"null_formula(x)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/null_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"“Null formula” of a model — null_formula","text":"x object formula method update method accepting updating formula second argument.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/null_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"“Null formula” of a model — null_formula","text":"Returns simple (“null”) formula.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/null_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"“Null formula” of a model — null_formula","text":"","code":"null_formula(lm(Sepal.Length ~ ., iris)) #> Sepal.Length ~ 1 #> <environment: 0x559ab0c90780>"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Table format with informative print method. — param_table","title":"Table format with informative print method. — param_table","text":"param_table() creates table inheriting class “param_table”, generalizing class “data.frame” informative print() method list columns. designed internal usage modeltuner package. parameter table (multi)model (element param)  “param_table”, output cv_performance() performance(), .","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Table format with informative print method. — param_table","text":"","code":"param_table(x, nms = rownames(x))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Table format with informative print method. — param_table","text":"x data.frame. nms Row names attributed output table.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Table format with informative print method. — param_table","text":"parameter table.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Table format with informative print method. — param_table","text":"class “param_table” print-method often informative print.data.frame(). similarities tibble regarding rendering list columns, differs list elements length 1 displayed informative way (see examples). class “param_table” additional methods cbind(), rbind() .data.frame().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/param_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Table format with informative print method. — param_table","text":"","code":"# Create a data.frame with a list as its single column tbl <- data.frame(row.names = 1:4) tbl$mixed_list <- list(pi, \"anything\", y~x, 1:10)  # print as data.frame: tbl #>                      mixed_list #> 1                      3.141593 #> 2                      anything #> 3                         y ~ x #> 4 1, 2, 3, 4, 5, 6, 7, 8, 9, 10  if (require(tibble)){   # print as tibble:   tibble(tbl) } #> Loading required package: tibble #> # A tibble: 4 × 1 #>   mixed_list #>   <list>     #> 1 <dbl [1]>  #> 2 <chr [1]>  #> 3 <formula>  #> 4 <int [10]>     # print as param_table: param_table(tbl) #>   mixed_list #> 1  3.1416    #> 2  anything  #> 3  y ~ x     #> 4  <int>[10]"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the model performance of a model — performance","title":"Evaluate the model performance of a model — performance","text":"performance() fits model(s) x calculates performance table, .e. type output cv_performance(). reported training error refers full model data, test error error data provided newdata argument. Test error NA newdata specified.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the model performance of a model — performance","text":"","code":"performance(x, ...)  # S3 method for model performance(   x,   newdata = NULL,   metric = NULL,   eval_weights = x$weights,   newweights = NULL,   na.rm = FALSE,   ... )  # S3 method for model_fm_xgb performance(   x,   newdata = NULL,   metric = NULL,   eval_weights = x$weights,   newweights = NULL,   na.rm = FALSE,   ... )  # S3 method for default performance(   x,   newdata = NULL,   metric = NULL,   eval_weights = x$weights,   newweights = NULL,   na.rm = FALSE,   ... )  # S3 method for multimodel performance(   x,   newdata = NULL,   metric = NULL,   eval_weights = \"default\",   newweights = NULL,   na.rm = FALSE,   param = TRUE,   ... )  # S3 method for cv performance(x, newdata = NULL, metric = x$metric[1], ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the model performance of a model — performance","text":"x model, object. ... Passed metric function. newdata Additional data --sample evaluation metric metric (see metrics), specified either character string (name metric function), named list length 1, list(rmse = rmse). metric=NULL selects default metric, see default_metric. eval_weights, newweights Evaluation weights training test data, respectively. na.rm Logical: Whether NA values excluded computations. param Logical: Keep parameters parameter table output?","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the model performance of a model — performance","text":"performance() returns performance table. param_table additional class “performance” additional information attributes.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Evaluate the model performance of a model — performance","text":"performance.model() core method. performance.default(x, ...) executes x %>% model %>% performance(...), x fitted model. performance.multimodel(x, ...) runs performance.model() models included x combines results performance table n_model(x) rows. uses metric = default_metric(x) default. performance.cv() extracts multimodel “cv” object applies performance.multimodel(), using first cross-validated model's metric default metric.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/performance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the model performance of a model — performance","text":"","code":"even_ind <- seq(150)%%2 == 0 mylm <- lm(Sepal.Length ~., iris[even_ind, ])  # using half of the data to train performance(mylm) #> --- Performance table --- #> Metric: rmse #>       train_rmse test_rmse #> model    0.26229        NA performance(mylm, newdata = iris[!even_ind, ]) # test set is complement of model data #> --- Performance table --- #> Metric: rmse #>       train_rmse test_rmse #> model    0.26229   0.34786"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for class “evaluation_log” — plot.evaluation_log","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"Draws line plots training test errors evaluation log, available.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"","code":"# S3 method for evaluation_log plot(   x,   errorbars = getOption(\"cv_show_se\"),   plot = TRUE,   size = 2,   lwd = 1,   lwd_errorbars = 0.5,   zeroline = TRUE,   ... )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"x object class evaluation_log. errorbars Logical: Whether add error bars plots. plot Logical: TRUE, ggplot returned, FALSE data.frame. plot() first prepares data.frame draws ggplot using data, limited options customization. want design plot, can set plot=FALSE, use data.frame returned plot() create plot. size Graphic detail: Size point. lwd Graphic detail: Line width interpolating line. lwd_errorbars Graphic detail: Line width errorbars. zeroline Logical: Whether include horizontal reference line level 0. ... Currently used.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"plot.evaluation_log() returns either ggplot , plot=FALSE, data.frame.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"lengths errorbars corresponds +/-1 standard error.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.evaluation_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for class “evaluation_log” — plot.evaluation_log","text":"","code":"# Evaluation log of a 'fm_xgb' model fitted_xgb <- fm_xgb(Sepal.Length ~ ., iris, max_depth = 2) evaluation_log(fitted_xgb)    # evaluation log of a model has no  #> ‘evaluation_log’, 1 model: #>  #> Model ‘fitted_xgb’: #>   model class: fm_xgb #>  iter train_rmse test_rmse #>     1      3.823        NA #>    21      0.258        NA #>    41      0.227        NA #>    60      0.209        NA #>    80      0.197        NA #>   100      0.188        NA plot(evaluation_log(fitted_xgb)) #> Warning: Removed 100 rows containing missing values (`geom_point()`). #> Warning: Removed 100 rows containing missing values (`geom_line()`).   # Evaluation log of cross-validated 'fm_xgb' model cv_xgb <- cv(model(fitted_xgb, label = \"xgb_depth2\")) evaluation_log(cv_xgb)  #> ‘evaluation_log’, 1 cross-validated model: #>  #> Model ‘xgb_depth2’: #>   model class: fm_xgb #>  iter train_rmse test_rmse criterion #>     1      3.825     3.821           #>     8      0.472     0.500           #>    14      0.280     0.337           #>    21      0.250     0.325           #>    24      0.244     0.322       min #>    27      0.238     0.323           #>    34      0.227     0.325           plot(evaluation_log(cv_xgb))   # Evaluation log of several cross-validated models mydata <- simuldat() fitted_glmnet <- fm_glmnet(Y ~ ., mydata) cv_glmnet <- cv(multimodel(fitted_glmnet, prefix = \"glmnet\", alpha = 0:1)) label(cv_glmnet) <- c(\"ridge\", \"lasso\") evaluation_log(cv_glmnet) #> ‘evaluation_log’, 2 cross-validated models: #>  #> Model ‘ridge’: #>   model class: fm_glmnet #>  iter   lambda train_rmse test_rmse criterion #>     1 1039.726       2.76      2.75           #>    21  161.748       2.74      2.73           #>    41   25.163       2.62      2.62           #>    60    4.296       2.25      2.30           #>    80    0.668       1.93      2.04           #>    92    0.219       1.90      2.03       min #>   100    0.104       1.89      2.03           #>  #> Model ‘lasso’: #>   model class: fm_glmnet #>  iter  lambda train_rmse test_rmse criterion #>     1 1.03973       2.76      2.76           #>    14 0.31022       2.18      2.20           #>    27 0.09256       1.95      2.05           #>    40 0.02762       1.90      2.03           #>    44 0.01903       1.90      2.03       min #>    53 0.00824       1.89      2.03           #>    66 0.00246       1.89      2.03           plot(evaluation_log(cv_glmnet))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"plot.model() plot.multimodel() fit model(s) x draw scatter plot(s) actual response values versus fitted values case continuous response. binary response, violin plot fitted values versus response variable produced (using geom_violin()). plot.cv creates similar plot, using predictions resulting cross-validation (generated cv_predict) fitted values.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"","code":"# S3 method for model plot(x, plot = TRUE, n_max = 5000, ...)  # S3 method for multimodel plot(x, plot = TRUE, n_max = 5000, ...)  # S3 method for cv plot(x, plot = TRUE, n_max = 5000, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"x Object appropriate class. plot Logical: TRUE, ggplot returned, FALSE data.frame. plot() first prepares data.frame draws ggplot using data, limited options customization. want design plot, can set plot=FALSE, use data.frame returned plot() create plot. n_max Integer: Maximal number points draw scatter plot. size data larger n_max, random sample displayed. ... Passed geom_point() geom_violin() (case binary response), respectively.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"plot() methods return either ggplot , plot=FALSE, data.frame.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"lengths errorbars corresponds +/-1 standard error.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/plot.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot methods for classes “model”, “multimodel” and “cv” — plot.model","text":"","code":"# Simulate data  set.seed(1) n <- 50 x <- rnorm(n) y <- 3*x + rnorm(n) mymodel <- model(lm(y~x)) # Plot in-sample and out-of-sample predictions: if (require(ggplot2) && require(gridExtra)){   plot(gridExtra::arrangeGrob(        plot(mymodel) + ggtitle(\"response vs. in-sample predictions\"),        plot(cv(mymodel)) + ggtitle(\"response vs. out-of-sample predictions\"),         nrow = 1)) }    #> Loading required package: ggplot2 #> Loading required package: gridExtra   # Binary response: binomial response # Simulate data  n <- 100 p <- 10 x <- matrix(rnorm(p*n), nrow = n) y <- (0.1 * rowSums(x) + rnorm(n)) > 0 mymodel <- model(glm(y~x, family = binomial)) # Plot in-sample and out-of-sample predictions: if (require(ggplot2) && require(gridExtra)){   plot(gridExtra::arrangeGrob(        plot(mymodel) + ggtitle(\"response vs. in-sample predictions\"),        plot(cv(mymodel)) + ggtitle(\"response vs. out-of-sample predictions\"),         nrow = 1)) }"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/predict.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions and residuals from a (multi-)model — predict.model","title":"Predictions and residuals from a (multi-)model — predict.model","text":"predict.model() residuals.model() fit model extract -sample predictions residuals, respectively.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/predict.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions and residuals from a (multi-)model — predict.model","text":"","code":"# S3 method for model predict(object, newdata = object$data, ...)  # S3 method for model residuals(object, ...)  # S3 method for multimodel predict(object, newdata, ...)  # S3 method for multimodel residuals(object, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/predict.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions and residuals from a (multi-)model — predict.model","text":"object model multimodel. newdata newdata ... Passed fit.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/predict.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions and residuals from a (multi-)model — predict.model","text":"vector object “model”, matrix “multimodel” “cv” containing several models.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/predict.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions and residuals from a (multi-)model — predict.model","text":"","code":"mod <- model(lm(Sepal.Length ~ .,  iris),               label = \"lm_iris\") predict(mod) #>        1        2        3        4        5        6        7        8  #> 5.004788 4.756844 4.773097 4.889357 5.054377 5.388886 4.923684 5.038124  #>        9       10       11       12       13       14       15       16  #> 4.707255 4.920872 5.186890 5.121048 4.788359 4.539586 5.086884 5.470981  #>       17       18       19       20       21       22       23       24  #> 5.057188 4.973273 5.370812 5.204964 5.203972 5.123859 4.722679 5.059837  #>       25       26       27       28       29       30       31       32  #> 5.369821 4.922692 5.058017 5.087712 4.955199 5.021870 4.972281 4.975092  #>       33       34       35       36       37       38       39       40  #> 5.416761 5.351910 4.889357 4.690173 4.921864 5.085892 4.673919 5.038124  #>       41       42       43       44       45       46       47       48  #> 4.890348 4.295281 4.773097 5.044575 5.505146 4.725328 5.319403 4.856021  #>       49       50       51       52       53       54       55       56  #> 5.186890 4.905610 6.490778 6.293414 6.575522 5.495523 6.177983 6.158089  #>       57       58       59       60       61       62       63       64  #> 6.477336 5.059188 6.290603 5.579438 5.026681 5.945463 5.540480 6.342011  #>       65       66       67       68       69       70       71       72  #> 5.461359 6.192416 6.194236 5.871349 5.797525 5.574807 6.447640 5.743467  #>       73       74       75       76       77       78       79       80  #> 6.277989 6.355454 6.041829 6.142827 6.375347 6.545827 6.144647 5.324214  #>       81       82       83       84       85       86       87       88  #> 5.442294 5.390885 5.642470 6.511500 6.194236 6.361076 6.409674 5.827220  #>       89       90       91       92       93       94       95       96  #> 5.925569 5.594701 6.007503 6.308676 5.675805 5.009599 5.859727 6.040009  #>       97       98       99      100      101      102      103      104  #> 5.958905 6.041829 4.828488 5.826392 6.971778 6.117018 6.866149 6.662333  #>      105      106      107      108      109      110      111      112  #> 6.751709 7.446619 5.583325 7.242804 6.629826 7.203469 6.333447 6.282867  #>      113      114      115      116      117      118      119      120  #> 6.534451 5.903400 6.009029 6.404749 6.628997 7.894739 7.434006 5.912211  #>      121      122      123      124      125      126      127      128  #> 6.736446 5.969242 7.461881 5.982684 6.849066 7.142797 5.949349 6.131451  #>      129      130      131      132      133      134      135      136  #> 6.518198 6.940802 6.995851 7.708997 6.486682 6.292669 6.639628 6.968966  #>      137      138      139      140      141      142      143      144  #> 6.721184 6.678586 6.048527 6.501115 6.572418 6.189311 6.117018 6.902295  #>      145      146      147      148      149      150  #> 6.723004 6.222647 5.934916 6.317193 6.586851 6.297300  residuals(mod) #>            1            2            3            4            5            6  #>  0.095211981  0.143156450 -0.073096946 -0.289356835 -0.054376913  0.011114267  #>            7            8            9           10           11           12  #> -0.323683608 -0.038123516 -0.307254656 -0.020872352  0.213109802 -0.321047908  #>           13           14           15           16           17           18  #>  0.011640933 -0.239585893  0.713116294  0.229018580  0.342811832  0.126727498  #>           19           20           21           22           23           24  #>  0.329187643 -0.104963574  0.196027701 -0.023859163 -0.122679348  0.040163147  #>           25           26           27           28           29           30  #> -0.569821081  0.077307668 -0.058016873  0.112287590  0.244800875 -0.321870120  #>           31           32           33           34           35           36  #> -0.172281226  0.424907518 -0.216761291  0.148089724  0.010643165  0.309827445  #>           37           38           39           40           41           42  #>  0.578136372 -0.185892430 -0.273919159  0.061876484  0.109651890  0.204718616  #>           43           44           45           46           47           48  #> -0.373096946 -0.044574732 -0.405145622  0.074671968 -0.219403483 -0.256021337  #>           49           50           51           52           53           54  #>  0.113109802  0.094389769  0.509221918  0.106586218  0.324477547  0.004477184  #>           55           56           57           58           59           60  #>  0.322017402 -0.458089242 -0.177335941 -0.159187524  0.309397473 -0.379438483  #>           61           62           63           64           65           66  #> -0.026680731 -0.045462821  0.459519526 -0.242011401  0.138641386  0.507583985  #>           67           68           69           70           71           72  #> -0.594235995 -0.071349335  0.402475156  0.025192753 -0.547640404  0.356532715  #>           73           74           75           76           77           78  #>  0.022010910 -0.255453541  0.358170647  0.457172879  0.424653102  0.154173084  #>           79           80           81           82           83           84  #> -0.144647101  0.375785906  0.057706038  0.109114912  0.157530482 -0.511500143  #>           85           86           87           88           89           90  #> -0.794235995 -0.361076053  0.290326329  0.472779619 -0.325569464 -0.094700604  #>           91           92           93           94           95           96  #> -0.507502580 -0.208675903  0.124194985 -0.009598630 -0.259727174 -0.340009373  #>           97           98           99          100          101          102  #> -0.258904962  0.158170647  0.271512274 -0.126391677 -0.671777514 -0.317017734  #>          103          104          105          106          107          108  #>  0.233851489 -0.362332996 -0.251708602  0.153380750 -0.683324634  0.057196266  #>          109          110          111          112          113          114  #>  0.070173797 -0.003468587  0.166553314  0.117133483  0.265549054 -0.203400038  #>          115          116          117          118          119          120  #> -0.209029042 -0.004748917 -0.128997498 -0.194739274  0.265994187  0.087789057  #>          121          122          123          124          125          126  #>  0.163553518 -0.369242328  0.238118630  0.317315531 -0.149066410  0.057202758  #>          127          128          129          130          131          132  #>  0.250651028 -0.031451151 -0.118197550  0.259198294  0.404149460  0.191002865  #>          133          134          135          136          137          138  #> -0.086682032  0.007331302 -0.539628383  0.731033741 -0.421184361 -0.278586392  #>          139          140          141          142          143          144  #> -0.048526760  0.398884551  0.127582321  0.710688760 -0.317017734 -0.102295264  #>          145          146          147          148          149          150  #> -0.023004341  0.477353262  0.365084445  0.182806710 -0.386851096 -0.397299933"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the values of the model response from an object — response","title":"Extract the values of the model response from an object — response","text":"Extract values model response object class “model”, “multimodel”, “cv” fitted model.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the values of the model response from an object — response","text":"","code":"response(object, ...)  # S3 method for model response(object, ...)  # S3 method for default response(object, ...)  # S3 method for multimodel response(object, ...)  # S3 method for cv response(object, complete = FALSE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the values of the model response from an object — response","text":"object object class “model”, “multimodel” “cv” fitted model. ... Currently used. complete Logical: FALSE, output includes observations featuring exactly folds (sorted position model data); otherwise, returns full vector.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the values of the model response from an object — response","text":"vector containing values model^s response variable.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the values of the model response from an object — response","text":"default method applies response.model() model(object, ...). method class “cv” complete=FALSE returns vector length cv_predict.cv(x) cv_resid.cv(x).","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/response.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the values of the model response from an object — response","text":"","code":"response(lm(mpg ~., mtcars)) #>  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 #> [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 #> [31] 15.0 21.4"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","title":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","text":"set_iter() modifies “cv” object altering preferences respect iterations, without re-running cross-validation. extract_iter() extracts information preferred iterations “cv” object. expand_iter() converts “cv” object multiple preferred iterations “cv” object several (identical) models, different preferred iterations.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","text":"","code":"set_iter(x, iter, ...)  # S3 method for cv set_iter(   x,   iter,   which = label.cv(x),   label = label.cv(x),   keep_all = TRUE,   ... )  extract_iter(x, ...)  expand_iter(x, iter = NULL, which = label.cv(x))  # S3 method for model set_iter(x, ...)  # S3 method for model_fm_xgb set_iter(x, iter, verbose = TRUE, warn = TRUE, ...)  # S3 method for model_fm_glmnet set_iter(x, iter, lambda = NULL, verbose = TRUE, warn = TRUE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","text":"x cross-validated model, class “cv”, based iteratively fitted model (IFM, see ifm). set_iter(), x can also model based IFM. iter x “cv”: criterion (see crit_iter, multiple criteria allowed). x “model”: integer value; model cross-validation information, iter required preferred iteration selected; otherwise iter required. ... Arguments passed methods. Character, integer logical vector specifying cross-validated models modified expanded. label label output object. keep_all Logical: TRUE, preference criteria kept, FALSE, selected one (relevant one preference criterion). verbose Logical: Show information modified arguments? warn Logical: Whether issue warning information parameter setting possible. lambda Vector lambda (decreasing numeric values) pass glmnet().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","text":"modified object class x, “model” “cv” object.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_iter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set, extract and expand preference criteria for a “cv” object for iteratively fitted models — set_iter","text":"","code":"d <- simuldat(n = 5000) m <- model(\"fm_xgb\", Y ~ ., d, nrounds = 200, class = \"fm_xgb\",             label = \"xgb\") cvm <- cv(m, iter = c(crit_min(), crit_last(), crit_overfit(.5)),            nfold = .3) print(cvm, what = \"call\")            #> --- A “cv” object containing 1 validated model --- #>  #> Validation procedure: Simple Hold-out Validation #>   Number of obs in data:  5000 #>   Number of test sets:       1 #>   Size of test set:       1500 #>   Size of training set:   3500 #>  #> Model: #>  #> ‘xgb’: #>   metric:  rmse #>   call:    fm_xgb(formula = Y ~ ., data = data, nrounds = 200) #>  #> Preferred iterations: #>   model ‘xgb’:  min (iter=68), last (iter=78),  #>                 overfit0.5 (iter=38) extract_iter(cvm) #> Error in extract_iter(cvm): could not find function \"extract_iter\" cv_performance(cvm) #> --- Performance table --- #> Metric: rmse #>     train_rmse test_rmse iteration time_cv #> xgb    0.49601    1.3836        68   0.554 plot(evaluation_log(cvm))   # set_iter cvm_last <- set_iter(cvm, crit_last(), label = \"xgb_last\") #> Error in set_iter(cvm, crit_last(), label = \"xgb_last\"): could not find function \"set_iter\" cv_performance(c(cvm, cvm_last)) #> Error in eval(expr, envir, enclos): object 'cvm_last' not found  # expand_iter cvm_expanded <- expand_iter(cvm) #> Error in expand_iter(cvm): could not find function \"expand_iter\" print(cvm_expanded, what = c(\"call\")) #> Error in eval(expr, envir, enclos): object 'cvm_expanded' not found cv_performance(cvm_expanded)        #> Error in eval(expr, envir, enclos): object 'cvm_expanded' not found plot(evaluation_log(cvm_expanded)) #> Error in eval(expr, envir, enclos): object 'cvm_expanded' not found"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Change the default metric of a cv object — set_metric","title":"Change the default metric of a cv object — set_metric","text":"set_metric applied object x class “cv” including one several cross-validated models. changes default metric models x.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change the default metric of a cv object — set_metric","text":"","code":"set_metric(x, ...)  # S3 method for cv set_metric(x, metric = x$metric[1], eval_weights = \"default\", ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change the default metric of a cv object — set_metric","text":"x object class “cv”. ... Passed metric function. metric metric (see metrics). eval_weights Evaluation weights; see “Evaluation weights” “Details” section ?modeltuner. \"eval_weights=default means “use fitting weights” \"eval_weights=NULL means unweighted evaluation.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change the default metric of a cv object — set_metric","text":"(modified) object class cv, adapted metric.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change the default metric of a cv object — set_metric","text":"Changing metric useful applied models based iteratively fitted model (see ifm). case, evaluation log recalculated new metric preference criteria evaluated based updated log. computations possible input “cv” object contains cross-validation model fits, requires generated call cv(..., keep_fits = TRUE).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change the default metric of a cv object — set_metric","text":"","code":"m <- model(fm_xgb(Sepal.Length ~., iris), max_depth = 2,             label = \"xgb_model\") cvm <- cv(m, keep_fits = TRUE)  # keep_fits=TRUE is required here cv_performance(cvm) #> --- Performance table --- #> Metric: rmse #>           train_rmse test_rmse iteration time_cv #> xgb_model    0.23375   0.33137        30   0.101 # change the metric cvm_medae <- set_metric(cvm, \"medae\") cv_performance(cvm_medae) #> --- Performance table --- #> Metric: medae #>           train_medae test_medae iteration time_cv #> xgb_model     0.17884    0.23323        23   0.101"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"set_pref_iter() modifies model cross-validated model (usually iteratively fitted model/ifm) altering preferences respect iterations, without re-fitting model re-running cross-validation, respectively. generic function action varies depending class object modified. See “Details” section . extract_pref_iter() extracts information preferred iterations “cv” object. expand_pref_iter() converts “cv” object multiple preferred iterations “cv” object several (identical) models, different preferred iterations.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"","code":"set_pref_iter(x, iter, ...)  # S3 method for model set_pref_iter(x, ...)  # S3 method for model_fm_xgb set_pref_iter(x, iter, verbose = TRUE, warn = TRUE, ...)  # S3 method for model_fm_glmnet set_pref_iter(x, iter, lambda = NULL, verbose = TRUE, warn = TRUE, ...)  # S3 method for cv set_pref_iter(   x,   iter,   which = label.cv(x),   label = label.cv(x),   keep_all = TRUE,   ... )  extract_pref_iter(x, ...)  expand_pref_iter(x, iter = NULL, which = label.cv(x))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"x cross-validated model, class “cv”, usually based iteratively fitted model (IFM, see ifm). set_pref_iter(), x can also model fitted model. iter Usually integer value. x “cv”, can also preference criterion (see crit_iter) -- multiple criteria allowed. x “model” cross-validation information, iter can omitted preferred iteration cross-validation selected. ... Arguments passed methods. verbose Logical: Show information modification arguments model generating call? warn Logical: Whether issue warning required information preferred iterations available. lambda Vector lambda (decreasing numeric values) pass glmnet(). Character, integer logical vector specifying cross-validated models modified expanded. label label output object. keep_all Logical: TRUE, preference criteria kept, FALSE, selected one. keep_all relevant one preference criterion.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"modified object class x.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"set_pref_iter() varies classes: x fitted model, iter required argument must positive integer. pref_iter component fitted object set equal iter, call adjusted. adjustment call consists setting pref_iter making changes vary model classes. actual model “fm_xgb”, nrounds early_stopping_rounds adjusted, case “fm_glmnet”, value gamma changed. changes predict() return predictions iterth iteration execution adjusted call generates model shares behavior stops fitting process immediately iteration. x object class “model”, call element adjusted, exactly described fitted models. x model fit attached (.e. has_fit(x) returns TRUE), fitted model adjusted, . x model IFM, returned unchanged. x cross-validated model (class “cv”), information preferred iterations (stored part component extras) modified “model” adapted, . currently method set_pref_iter.multimodel().","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/set_pref_iter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract set, and expand preference criteria for a “cv” object for iteratively fitted models — set_pref_iter","text":"","code":"d <- simuldat(n = 5000) m <- model(\"fm_xgb\", Y ~ ., d, nrounds = 200, class = \"fm_xgb\",             label = \"xgb\") cvm <- cv(m, iter = c(crit_min(), crit_last(), crit_overfit(.5)),            nfold = .3) print(cvm, what = \"call\")            #> --- A “cv” object containing 1 validated model --- #>  #> Validation procedure: Simple Hold-out Validation #>   Number of obs in data:  5000 #>   Number of test sets:       1 #>   Size of test set:       1500 #>   Size of training set:   3500 #>  #> Model: #>  #> ‘xgb’: #>   metric:  rmse #>   call:    fm_xgb(formula = Y ~ ., data = data, nrounds = 200) #>  #> Preferred iterations: #>   model ‘xgb’:  min (iter=81), last (iter=91),  #>                 overfit0.5 (iter=38) extract_pref_iter(cvm) #> Preferred iterations: #>   model ‘xgb’:  min (iter=81), last (iter=91),  #>                 overfit0.5 (iter=38) cv_performance(cvm) #> --- Performance table --- #> Metric: rmse #>     train_rmse test_rmse iteration time_cv #> xgb    0.47056    1.4696        81   0.632 plot(evaluation_log(cvm))   # set_pref_iter cvm_last <- set_pref_iter(cvm, crit_last(), label = \"xgb_last\") cv_performance(c(cvm, cvm_last)) #> --- Performance table --- #> Metric: rmse #>          train_rmse test_rmse iteration time_cv #> xgb         0.47056    1.4696        81   0.632 #> xgb_last    0.42818    1.4714        91   0.632  # expand_pref_iter cvm_expanded <- expand_pref_iter(cvm) print(cvm_expanded, what = c(\"call\")) #> --- A “cv” object containing 3 validated models --- #>  #> Validation procedure: Simple Hold-out Validation #>   Number of obs in data:  5000 #>   Number of test sets:       1 #>   Size of test set:       1500 #>   Size of training set:   3500 #>  #> Models: #>  #> ‘xgb_min’: #>   metric:  rmse #>   call:    fm_xgb(formula = Y ~ ., data = data, nrounds = 200) #>  #> ‘xgb_last’: #>   metric:  rmse #>   call:    fm_xgb(formula = Y ~ ., data = data, nrounds = 200) #>  #> ‘xgb_overfit0.5’: #>   metric:  rmse #>   call:    fm_xgb(formula = Y ~ ., data = data, nrounds = 200) #>  #> Preferred iterations: #>   model ‘xgb_min’:         min (iter=81) #>   model ‘xgb_last’:        last (iter=91) #>   model ‘xgb_overfit0.5’:  overfit0.5 (iter=38) cv_performance(cvm_expanded)        #> --- Performance table --- #> Metric: rmse #>                train_rmse test_rmse iteration time_cv #> xgb_min           0.47056    1.4696        81   0.632 #> xgb_last          0.42818    1.4714        91   0.632 #> xgb_overfit0.5    0.77827    1.5454        38   0.632 plot(evaluation_log(cvm_expanded))"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/simuldat.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data — simuldat","title":"Simulate data — simuldat","text":"Simulates data.frame n rows 12 columns: X1, ..., X10, random standard normal vectors. g, factor ngroup levels, assigned random. Y, response, generated additive combination linear effect X1 (randomly generated) intercepts slopes varying groups g, linear effects X1, X2 X3. non-linear effects X6 X7. non-linear three-way interaction X3, X4 X5 residuals normal t distributions df degrees freedom (df=Inf normal).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/simuldat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data — simuldat","text":"","code":"simuldat(n = 500, ngroup = 20, df = Inf, b = 1, weights = NULL)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/simuldat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data — simuldat","text":"n Number observations ngroup Number groups g. df Number degrees freedom t distribution simulation residuals. Default Inf generates normal residuals. b Numeric vector length 4 (shorter expanded length 4): multiplicators 4 effects, weights NULL vector n non-negative values: NULL, simulated residuals divided 1/sqrt(weights).","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/simuldat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data — simuldat","text":"simuldat() returns data.frame.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/simuldat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data — simuldat","text":"","code":"# Simluate data d <- simuldat()  # Fit the \"true\" model if (require(lme4)){   form <- Y ~ (X1|g) + X2 + X3 + abs(X3+X4+X5) + I(exp(2*X6)/(1+exp(2*X6))) + dnorm(X7, sd = 0.5)   (truemodel <- lmer(form, d))   confint(truemodel) } #> Loading required package: lme4 #> Loading required package: Matrix #> Computing profile confidence intervals ... #>                                       2.5 %    97.5 % #> .sig01                            0.5748288 1.1216261 #> .sig02                           -0.5576754 0.5542210 #> .sig03                            0.9171461 1.7428126 #> .sigma                            0.9021777 1.0266916 #> (Intercept)                      -0.4091333 0.7009398 #> X2                                0.9448369 1.1092397 #> X3                                0.9079008 1.0841421 #> abs(X3 + X4 + X5)                 0.9138392 1.0888350 #> I(exp(2 * X6)/(1 + exp(2 * X6)))  2.6666406 3.2292266 #> dnorm(X7, sd = 0.5)               2.7170187 3.3400138  # Data set with a purely random response str(simuldat(b = 0)) #> 'data.frame':\t500 obs. of  12 variables: #>  $ X1 : num  -1.415 -0.906 -2.739 -0.29 -1.805 ... #>  $ X2 : num  0.988 0.519 -1.492 0.564 -0.121 ... #>  $ X3 : num  0.114 0.827 -1.099 -1.227 0.13 ... #>  $ X4 : num  1.144 -1.392 0.493 1.339 1.186 ... #>  $ X5 : num  1.248 1.812 -1.295 -0.152 -0.078 ... #>  $ X6 : num  -0.503 -0.257 -0.868 1.339 -0.972 ... #>  $ X7 : num  0.192 -1.388 0.536 -1.444 -1.637 ... #>  $ X8 : num  -1.3023 -0.0473 -1.0888 -0.5516 0.545 ... #>  $ X9 : num  -1.984 -0.739 0.413 0.583 0.385 ... #>  $ X10: num  0.475 1.331 -1.922 0.389 0.22 ... #>  $ g  : Factor w/ 20 levels \"g1\",\"g10\",\"g11\",..: 20 17 1 5 14 5 12 1 6 11 ... #>  $ Y  : num  -0.8366 0.0548 -2.5393 0.9834 -1.1004 ..."},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/sort_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","title":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","text":"Models reordered according argument order. order shorter number models, models specified order appear mentioned appended. methods classes “cv” “performance” can sorted order model performance using argument .","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/sort_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","text":"","code":"sort_models(x, ...)  # S3 method for model sort_models(x, ...)  # S3 method for multimodel sort_models(x, order, ...)  # S3 method for cv sort_models(x, order, by = NULL, decreasing = FALSE, ...)  # S3 method for performance sort_models(x, order, by = NULL, decreasing = FALSE, ...)  # S3 method for evaluation_log sort_models(x, order, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/sort_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","text":"x multimodel cv ... Currently used. order vector model labels integer indices. complete, remaining elements appended. Example: 4 models, order=c(4, 2), output units order c(4,2,1,3). Sort value column performance table (methods classes “cv” “performance”: Character string specifying column table. Partial matching accepted, \"test\" sufficient sort test error metric. decreasing Logical: Sort decreasing order variable?","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/sort_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","text":"sort_models() returns input x rearranged models.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/sort_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorder models in an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — sort_models","text":"","code":"mm <- models(   intercept = lm(Sepal.Length ~ 1 , iris),   linear = lm(Sepal.Length ~ . , iris),    full = lm(Sepal.Length ~ .^2 , iris)) print(mm, what = \"formula\") #> --- A “multimodel” object containing 3 models --- #>  #> ‘intercept’: #>   formula:  Sepal.Length ~ 1 #>  #> ‘linear’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species #>  #> ‘full’: #>   formula:  Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                 Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                 Sepal.Width:Species + Petal.Length:Petal.Width +  #>                 Petal.Length:Species + Petal.Width:Species  sort_models(mm, 3:1) #> --- A “multimodel” object containing 3 models --- #>  #> ‘full’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘intercept’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) sort_models(mm, c(3:2)) #> --- A “multimodel” object containing 3 models --- #>  #> ‘full’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘intercept’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data) sort_models(mm, c(\"full\", \"linear\")) #> --- A “multimodel” object containing 3 models --- #>  #> ‘full’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species + Sepal.Width:Petal.Length + Sepal.Width:Petal.Width +  #>                     Sepal.Width:Species + Petal.Length:Petal.Width +  #>                     Petal.Length:Species + Petal.Width:Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ .^2, data = data) #>  #> ‘linear’: #>   model class:  lm #>   formula:      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                     Species #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ ., data = data) #>  #> ‘intercept’: #>   model class:  lm #>   formula:      Sepal.Length ~ 1 #>   data:         data.frame [150 x 5],  #>                 input as: ‘data = iris’ #>   call:         lm(formula = Sepal.Length ~ 1, data = data)  # Sort by test performance cvperf <- cv_performance(mm) sort_models(cvperf, by = \"test\") #> --- Performance table --- #> Metric: rmse #>           train_rmse test_rmse time_cv #> linear       0.29995   0.30610   0.036 #> full         0.28146   0.31870   0.025 #> intercept    0.82463   0.82749   0.010"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"step_extend() combines models resulting adding one variable base model multimodel subjects cv(). step_forward() applies step_extend() repeatedly, selecting best model respect test error step, thus performing forward selection variables. step_reduce() combines models resulting removing one variable full model multimodel subjects cv(). step_backward() applies step_reduce() repeatedly, selecting best model w.r.t. test error step, thus performing backward  elimination variables. best_subset() combines submodels full model multimodel subjects cv(). desired range model sizes (number effects) include specified parameter nvars.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"","code":"step_extend(x, ...)  # S3 method for model step_extend(   x,   formula1 = null_formula(x),   formula2 = formula(x),   steps = 1L,   include_full = FALSE,   include_base = FALSE,   cv = TRUE,   ... )  # S3 method for default step_extend(x, ...)  step_forward(x, ...)  # S3 method for model step_forward(   x,   formula1 = null_formula(x),   formula2 = formula(x),   max_step = 10,   include_base = TRUE,   include_full = FALSE,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   verbose = getOption(\"cv_verbose\"),   ... )  # S3 method for default step_forward(x, ...)  step_reduce(x, ...)  # S3 method for model step_reduce(   x,   formula1 = null_formula(x),   formula2 = formula(x),   steps = 1L,   include_full = FALSE,   include_base = FALSE,   cv = TRUE,   ... )  # S3 method for default step_reduce(x, ...)  step_backward(x, ...)  # S3 method for model step_backward(   x,   formula1 = null_formula(x),   formula2 = formula(x),   max_step = 10,   include_full = TRUE,   include_base = FALSE,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   verbose = getOption(\"cv_verbose\"),   ... )  # S3 method for default step_backward(x, ...)  best_subset(x, ...)  # S3 method for model best_subset(   x,   formula1 = null_formula(x),   formula2 = formula(x),   nvars = 1:5,   include_base = any(nvars == 0),   include_full = FALSE,   cv = TRUE,   ... )  # S3 method for default best_subset(x, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"x Object class “model” fitted model. ... Dots go cv() step_extend() step_reduce() (provided cv=TRUE), tune() step_forward() step_backward(). formula1, formula2 Two nested model formulas defining range models considered. larger two taken full model, simpler base model. See “Details” section. steps (step_extend, step_reduce) Integer: Number variables add/remove. Default: 1. include_full Logical: Whether include full model output. include_base Logical: Whether include base model output. cv (step_extend, step_reduce, best_subset) Logical: Run cv just return multimodel? max_step (step_forward, step_backward) Integer: Maximal number steps. nfold, folds Passed make_folds. verbose Logical: Output information execution progress console? nvars (best_subset) Integer vector defining number variables.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"functions return object class “cv”.\"","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"formula1 formula2 must nested model formulas, .e. one two formulas must include terms present . define range models considered: larger two defines full model, taken base model. default, formula1 formula2 used update original model formula. Enclose formula () replace model's formula. distinction relevant whenever specify formula including dot. See “Details” section examples ?update.model.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/stepwise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate and cross-validate models resulting from adding or removing variables and stepwise procedures — stepwise","text":"","code":"mod <- model(lm(Sepal.Length ~ ., iris),               label = \"sepLen\")               # Add variables to base model oneVarModels <- step_extend(mod) cv_performance(oneVarModels) #> --- Performance table --- #> Metric: rmse #>                                   formula train_rmse test_rmse time_cv #> +Sepal.Width  Sepal.Length ~ Sepal.Width     0.81900   0.82112   0.016 #> +Petal.Length Sepal.Length ~ Petal.Length    0.40397   0.40408   0.014 #> +Petal.Width  Sepal.Length ~ Petal.Width     0.47444   0.47490   0.013 #> +Species      Sepal.Length ~ Species         0.50910   0.50879   0.019  # step_forwamrd cv_fwd <- step_forward(mod) cv_performance(cv_fwd) #> --- Performance table --- #> Metric: rmse #>                                                                         formula train_rmse test_rmse time_cv #> base          Sepal.Length ~ 1                                                     0.82495   0.82754   0.010 #> +Petal.Length Sepal.Length ~ Petal.Length                                          0.40411   0.40112   0.013 #> +Sepal.Width  Sepal.Length ~ Petal.Length + Sepal.Width                            0.32964   0.33242   0.015 #> +Species      Sepal.Length ~ Petal.Length + Sepal.Width + Species                  0.30452   0.31152   0.022 #> +Petal.Width  Sepal.Length ~ Petal.Length + Sepal.Width + Species + Petal.Width    0.29982   0.31182   0.023  # Remove variables from full model mod |> step_reduce() |> cv_performance() #> --- Performance table --- #> Metric: rmse #>                                                               formula train_rmse test_rmse time_cv #> -Sepal.Width  Sepal.Length ~ Petal.Length + Petal.Width + Species        0.33292   0.34217   0.023 #> -Petal.Length Sepal.Length ~ Sepal.Width + Petal.Width + Species         0.42614   0.43159   0.022 #> -Petal.Width  Sepal.Length ~ Sepal.Width + Petal.Length + Species        0.30472   0.31020   0.021 #> -Species      Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width    0.30987   0.31636   0.026 mod |> step_backward() |> cv_performance() #> --- Performance table --- #> Metric: rmse #>                                                                         formula train_rmse test_rmse time_cv #> full          Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width + Species    0.29997   0.30733   0.023 #> -Petal.Width  Sepal.Length ~ Sepal.Width + Petal.Length + Species                  0.30458   0.30994   0.021 #> -Sepal.Width  Sepal.Length ~ Petal.Length + Species                                0.33310   0.33483   0.020 #> -Species      Sepal.Length ~ Petal.Length                                          0.40395   0.40443   0.012 #> -Petal.Length Sepal.Length ~ 1                                                     0.82491   0.82660   0.010  # best subset mod |> best_subset(nvar = 2:3) |> cv_performance() #> --- Performance table --- #> Metric: rmse #>                                                                                       formula train_rmse test_rmse time_cv #> +Sepal.Width+Petal.Length             Sepal.Length ~ Sepal.Width + Petal.Length                  0.32968   0.32828   0.014 #> +Sepal.Width+Petal.Width              Sepal.Length ~ Sepal.Width + Petal.Width                   0.44610   0.44742   0.015 #> +Sepal.Width+Species                  Sepal.Length ~ Sepal.Width + Species                       0.43135   0.43892   0.021 #> +Petal.Length+Petal.Width             Sepal.Length ~ Petal.Length + Petal.Width                  0.39853   0.40469   0.014 #> +Petal.Length+Species                 Sepal.Length ~ Petal.Length + Species                      0.33298   0.33959   0.028 #> +Petal.Width+Species                  Sepal.Length ~ Petal.Width + Species                       0.47358   0.48623   0.024 #> +Sepal.Width+Petal.Length+Petal.Width Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width    0.30986   0.31502   0.016 #> +Sepal.Width+Petal.Length+Species     Sepal.Length ~ Sepal.Width + Petal.Length + Species        0.30451   0.31187   0.022 #> +Sepal.Width+Petal.Width+Species      Sepal.Length ~ Sepal.Width + Petal.Width + Species         0.42594   0.43815   0.022 #> +Petal.Length+Petal.Width+Species     Sepal.Length ~ Petal.Length + Petal.Width + Species        0.33278   0.34349   0.022"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","title":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","text":"subset() methods classes “multimodel”, “cv” “performance”.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","text":"","code":"# S3 method for multimodel subset(x, subset = TRUE, ...)  # S3 method for cv subset(x, subset = TRUE, ...)  # S3 method for performance subset(x, subset = TRUE, ...)  # S3 method for evaluation_log subset(x, subset = TRUE, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","text":"x multimodel cv object. subset Selection models: integer vector logical vector appropriate length, character vector model labels. ... used.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/subset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","text":"Object class x.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset an object of class “multimodel”, “cv”, “performance” or “evaluation_log” — subset","text":"","code":"mm <- c(speed_lm = model(lm(dist ~ speed, cars)),         speed_loess = model(loess(dist ~ speed, cars,                                   control = loess.control(surface = \"direct\"))),         speed_rpart = model(rpart::rpart(dist ~ speed, cars))) # subset.multimodel: subset(mm, 1:2) #> --- A “multimodel” object containing 2 models --- #>  #> ‘speed_lm’: #>   model class:  lm #>   formula:      dist ~ speed #>   data:         data.frame [50 x 2],  #>                 input as: ‘data = cars’ #>   call:         lm(formula = dist ~ speed, data = data) #>  #> ‘speed_loess’: #>   model class:  loess #>   formula:      dist ~ speed #>   data:         data.frame [50 x 2],  #>                 input as: ‘data = cars’ #>   call:         loess(formula = dist ~ speed, data = data, control = loess.control(surface = \"direct\")) # subset.cv: cv_mm <- cv(mm) subset(cv_mm, 3:2) #> --- A “cv” object containing 2 validated models --- #>  #> Validation procedure: Complete k-fold Cross-Validation #>   Number of obs in data:  50 #>   Number of test sets:    10 #>   Size of test sets:       5 #>   Size of training sets:  45 #>  #> Models: #>  #> ‘speed_rpart’: #>   model class:  rpart #>   formula:      dist ~ speed #>   metric:       rmse #>  #> ‘speed_loess’: #>   model class:  loess #>   formula:      dist ~ speed #>   metric:       rmse # subset.performance: cv_perf <- cv_performance(cv_mm) subset(cv_perf, c(1, 3)) #> --- Performance table --- #> Metric: rmse #>             train_rmse test_rmse time_cv #> speed_lm        14.990    14.783   0.012 #> speed_rpart     16.261    16.627   0.026"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":null,"dir":"Reference","previous_headings":"","what":"Selection of the best-performing model in a “cv” object — tune","title":"Selection of the best-performing model in a “cv” object — tune","text":"tune() picks “best” model set models, model smallest test error.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selection of the best-performing model in a “cv” object — tune","text":"","code":"tune(x, ...)  # S3 method for cv tune(x, metric = x$metric[1], label = NULL, ...)  # S3 method for multimodel tune(   x,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   metric = NULL,   label = NULL,   ... )  # S3 method for model tune(   x,   ...,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   metric = NULL,   expand = TRUE,   max_n_model = getOption(\"expand_max_model\"),   label = NULL,   verbose = getOption(\"cv_verbose\") )  # S3 method for default tune(   x,   ...,   nfold = getOption(\"cv_nfold\"),   folds = NULL,   metric = NULL,   expand = TRUE,   max_n_model = getOption(\"expand_max_model\"),   verbose = getOption(\"cv_verbose\"),   use_original_args = FALSE,   force = FALSE )"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selection of the best-performing model in a “cv” object — tune","text":"x object class “cv”, object can transformed cv. ... See “Details” “Methods”. metric metric (see metrics), specified either character string (name metric function), named list length 1, list(rmse = rmse). metric=NULL selects default metric, see default_metric. label character string: label output model. NULL, selected model's current label kept. nfold, folds Passed make_folds(). expand Logical: Expand “...” arguments (default) join element-wise? expand=TRUE, vectors “...” expanded, number models equal product lengths “...” arguments; otherwise, “...” arguments must equal lengths, number models equal common length. max_n_model Maximal number models included. number specified models greater max_n_model, subset selected random. verbose Passed cv(). use_original_args, force Arguments passed fit().","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Selection of the best-performing model in a “cv” object — tune","text":"methods return object class “model”, except tune.default(), returns fitted model class input x.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Selection of the best-performing model in a “cv” object — tune","text":"core method tune.cv(x), selects model included x lowest test error (terms metric). methods run tune.cv() preprocessing steps -- see section “Methods”. iteratively fitted models (ifm, classes “fm_xgb” “fm_glmnet”), tune(x) without additional arguments returns model corresponding preferred iteration, thus tuning parameter nrounds lambda, respectively. models, tune(x) simply returns x. Note different role “...” arguments different methods: tune.cv() tune.multimodel() passed cv_performance(), allowing specification eval_weights; tune.model() tune.default(), passed multimodel(). allows expanding selection alternative parameterizations, smallest test error finally returned. Selecting best-performing parameterization thus reduces one simple line code: tune(mymodel, hyperparms=candidate_values)","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Selection of the best-performing model in a “cv” object — tune","text":"tune.cv: Executes cv_performance(x, ...), finds model minimal test error extracts model (using extract_model). tune.multimodel(x, ...) essentially runs x %>% cv %>% tune(...). tune.model(x, ...) essentially runs x %>% multimodel(...) %>% cv %>% tune. tune.default(x, ...) applied fitted model x essentially runs x %>% model %>% multimodel(...) %>% cv %>% tune %>% fit.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/tune.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Selection of the best-performing model in a “cv” object — tune","text":"","code":"options(nfold = 1/3)  # accelerates cross-validations  # Tune xgboost parameter: model_xgb <- model(\"fm_xgb\", Sepal.Length~., iris, class = \"fm_xgb\") mm_xgb <- multimodel(model_xgb, max_depth = 1:5) cv_xgb <- cv(mm_xgb) plot(cv_performance(cv_xgb),       xvar = \"max_depth\", zeroline = FALSE)   # tune() automatically selects the best-performing model: tuned1 <- tune(mm_xgb, max_depth = 1:5, label = \"tuned_model_1\") tuned1 #> --- A “model” object --- #>   label:          tuned_model_1 #>   model class:    fm_xgb #>   formula:        Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>                       Species #>   data:           data.frame [150 x 5],  #>                   input as: ‘data = iris’ #>   response_type:  continuous #>   call:           fm_xgb(formula = Sepal.Length ~ ., data = data,  #>                       max_depth = 3L) #> Preferred iteration from cv:  iter=21 # \\donttest{ # Several tuning steps in a pipe: tuned2 <- tuned1 |>    tune(learning_rate = c(0.1, 0.3, 1)) |>    tune(min_child_weight = c(5, 10, 20), label = \"tuned_model_2\") fit(tuned2, eval = FALSE, use_original_args = TRUE)  # extract selected model #> set_pref_iter(), model ‘tuned_model_2’, modifications made in call: #>   pref_iter=70, nrounds=70, early_stopping_rounds=NULL #> fm_xgb(formula = Sepal.Length ~ ., data = iris, nrounds = 70L,  #>     early_stopping_rounds = NULL, pref_iter = 70L, max_depth = 3L,  #>     learning_rate = 0.1, min_child_weight = 5) # } # Alternatively test a number of random parameterizations tuned3 <- tune(tuned1, learning_rate = c(0.1, 0.3, 1),                 min_child_weight = c(5, 10, 20),                 label = \"tuned_model_3\") fit(tuned3, eval = FALSE, use_original_args = TRUE)  # extract selected model #> set_pref_iter(), model ‘tuned_model_3’, modifications made in call: #>   pref_iter=67, nrounds=67, early_stopping_rounds=NULL #> fm_xgb(formula = Sepal.Length ~ ., data = iris, nrounds = 67L,  #>     early_stopping_rounds = NULL, pref_iter = 67L, max_depth = 3L,  #>     learning_rate = 0.1, min_child_weight = 5)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an object of class “model” or “multimodel” — update.model","title":"Update an object of class “model” or “multimodel” — update.model","text":"method update.model() allows updating selected arguments original call model fitting function, particular formula, data. Changing model fitting function possible, however. update.multimodel() apply update.model() models. absent(), unchanged() null() auxiliary functions designed usage update.model() multimodel(). absent() states removal/absence argument model fitting call, unchanged() leaves argument unchanged, null() attributes explicit NULL formal parameter. Find usage functions “Details” section examples.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an object of class “model” or “multimodel” — update.model","text":"","code":"# S3 method for model update(   object,   ...,   label = label.model(object),   add_fit = FALSE,   ignore_changes_in_arg = NULL )  # S3 method for multimodel update(object, ...)  absent()  null()  unchanged()"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an object of class “model” or “multimodel” — update.model","text":"object “model” “multimodel”. ... Arguments updated. label Character string: label attributed model. add_fit Logical: Save fitted object component result? ignore_changes_in_arg Parameter internal use.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update an object of class “model” or “multimodel” — update.model","text":"udpate.model() returns modified model. “...” empty, x changed. Otherwise, output contain model fit.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update an object of class “model” or “multimodel” — update.model","text":"update(model, parameter=NULL) ambiguous -- clearer use null() absent(). Using dot formula can ambiguous, . update(model, formula=new_formula) updates model's original formula new_formula (using update.formula). order replace existing formula different one containing dot, use update(model, formula=(new_formula)). See examples. absent(), unchanged() null() can also used multimodel(), uses update.model() internally. example, multimodel(lm(y~x), weights = list(w, absent())) return multimodel containing two model definitions based calls lm(y~x, weights = w) lm(y~x). Always enclose absent(), unchanged() null() list()  several alternative model parameterizations proposed multimodel()! example work properly c(w, absent()) instead list(w, absent())!","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/update.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update an object of class “model” or “multimodel” — update.model","text":"","code":"if (require(lme4)){   # Simluate data   d <- simuldat()   (mixmod <- lmer(Y ~ (X1|g) + X2 + X3, d, REML = TRUE))      # update.model   m_REML <- model(mixmod, label = \"REML\")   # update parater \"REML\"   m_ML <- update(m_REML, REML = FALSE, label = \"ML\")      # absent(), unchanged(), null()   update(m_REML, REML = absent())$call   update(m_REML, REML = unchanged())$call   update(m_REML, REML = null())$call # Note: not meaningful - fit() will fail      # update.multimodel   mm <- multimodel(m_REML, REML = c(TRUE, FALSE))   w <- runif(nrow(d))   update(mm, weights = w)      # Dots in formula:    update(m_REML, formula = . ~ . - X2)      # Updating vs replacing a formula:   update(m_REML, formula = exp(Y) ~ .)    # updates the formula   update(m_REML, formula = I(exp(Y) ~ .)) # replaces the formula      # Usage of unchanged() in multimodel()   multimodel(m_REML, REML = list(unchanged(), FALSE)) } #> --- A “multimodel” object containing 2 models --- #>  #> ‘REML1’: #>   model class:  lmerMod #>   formula:      Y ~ (X1 | g) + X2 + X3 #>   data:         data.frame [500 x 12],  #>                 input as: ‘data = d’ #>   call:         lmer(formula = Y ~ (X1 | g) + X2 + X3, data = data,  #>                     REML = TRUE) #>  #> ‘REML2’: #>   model class:  lmerMod #>   formula:      Y ~ (X1 | g) + X2 + X3 #>   data:         data.frame [500 x 12],  #>                 input as: ‘data = d’ #>   call:         lmer(formula = Y ~ (X1 | g) + X2 + X3, data = data,  #>                     REML = FALSE) #>  #> Parameter table: #>        REML #> REML1  TRUE #> REML2 FALSE"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/weights.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the (fitting) weights from a “model” object — weights.model","title":"Extract the (fitting) weights from a “model” object — weights.model","text":"Extract (fitting) weights “model” object","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/weights.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the (fitting) weights from a “model” object — weights.model","text":"","code":"# S3 method for model weights(object, ...)"},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/weights.model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the (fitting) weights from a “model” object — weights.model","text":"object “model” object. ... Currently used.","code":""},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/weights.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the (fitting) weights from a “model” object — weights.model","text":"Returns either vector weights NULL.","code":""},{"path":[]},{"path":"https://mathiasambuehl.github.io/modeltuner/reference/weights.model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the (fitting) weights from a “model” object — weights.model","text":"","code":"# Simulate data set.seed(314159) n <- 50 x <- rnorm(n) w <- runif(n) y <- x + rnorm(n)/sqrt(w)  # Weighted lm mymodel <- model(lm(y~x, weights = w))  # Extract weights weights(mymodel) #>  [1] 0.616979080 0.448061164 0.339249190 0.765733340 0.902529915 0.170293750 #>  [7] 0.215506481 0.708476310 0.658423500 0.106406077 0.699817682 0.336702210 #> [13] 0.971562987 0.738613351 0.188098839 0.807358315 0.108103753 0.639530915 #> [19] 0.929791097 0.260112991 0.432363673 0.437570636 0.138395336 0.679279183 #> [25] 0.955625676 0.851648425 0.614217912 0.167567696 0.138068559 0.939057660 #> [31] 0.519199798 0.702348737 0.473862721 0.001528634 0.440513609 0.545426817 #> [37] 0.090390960 0.091366257 0.591672173 0.130695508 0.639025257 0.945186972 #> [43] 0.525592272 0.701906522 0.020342527 0.230885630 0.985840238 0.597736365 #> [49] 0.210308769 0.251103677"}]
