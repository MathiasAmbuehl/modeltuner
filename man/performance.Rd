% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performance.R
\name{performance}
\alias{performance}
\alias{performance.model}
\alias{performance.model_fm_xgb}
\alias{performance.default}
\alias{performance.multimodel}
\alias{performance.cv}
\title{Evaluate the model performance of a model}
\usage{
performance(x, ...)

\method{performance}{model}(
  x,
  newdata = NULL,
  metric = NULL,
  eval_weights = x$weights,
  newweights = NULL,
  na.rm = FALSE,
  ...
)

\method{performance}{model_fm_xgb}(
  x,
  newdata = NULL,
  metric = NULL,
  eval_weights = x$weights,
  newweights = NULL,
  na.rm = FALSE,
  ...
)

\method{performance}{default}(
  x,
  newdata = NULL,
  metric = NULL,
  eval_weights = x$weights,
  newweights = NULL,
  na.rm = FALSE,
  ...
)

\method{performance}{multimodel}(
  x,
  newdata = NULL,
  metric = NULL,
  eval_weights = "default",
  newweights = NULL,
  na.rm = FALSE,
  param = TRUE,
  ...
)

\method{performance}{cv}(x, newdata = NULL, metric = x$metric[1], ...)
}
\arguments{
\item{x}{A model, or other object.}

\item{...}{Passed to the \code{metric} function.}

\item{newdata}{Additional data for out-of-sample evaluation}

\item{metric}{A metric (see \code{\link{metrics}}), specified either as a character string (name of the metric function),
or as a named list of length 1, as in \code{list(rmse = rmse)}.
\code{metric=NULL} selects the default metric, see \code{\link{default_metric}}.}

\item{eval_weights, newweights}{Evaluation weights for training and test data, respectively.}

\item{na.rm}{Logical: Whether NA values should be excluded from computations.}

\item{param}{Logical: Keep parameters from the parameter table in the output?}
}
\value{
\code{performance()} returns a performance table.
This is a \link{param_table} with additional class \dQuote{performance}
having additional information in its attributes.
}
\description{
\code{performance()} \code{\link{fit}s} the model(s) in \code{x} and calculates a \emph{performance table},
i.e. the same type of output as \code{\link{cv_performance}()}.
The reported training error refers to the full model data, while test error is the error for
the data provided in the \code{newdata} argument.
Test error is \code{NA} if no \code{newdata} is specified.
}
\section{Methods}{

\itemize{
\item{\code{performance.model()} is the core method.}
\item{\code{performance.default(x, ...)} executes \code{x \%>\% model \%>\% performance(...)}, where \code{x} is a fitted model.}
\item{\code{performance.multimodel(x, ...)} runs \code{performance.model()} for the models included in \code{x}
and combines the results in performance table with \code{n_model(x)} rows.
It uses \code{metric = \link{default_metric}(x)} by default.}
\item{\code{performance.cv()} extracts the multimodel from the \dQuote{cv} object and then applies \code{performance.multimodel()},
using the first cross-validated model's metric as default \code{metric}.}
}
}

\examples{
even_ind <- seq(150)\%\%2 == 0
mylm <- lm(Sepal.Length ~., iris[even_ind, ])  # using half of the data to train
performance(mylm)
performance(mylm, newdata = iris[!even_ind, ]) # test set is complement of model data

}
\seealso{
\code{\link{cv_performance}}
}
